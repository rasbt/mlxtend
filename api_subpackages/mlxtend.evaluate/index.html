<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Sebastian Raschka">
        <link rel="canonical" href="https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.evaluate/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Mlxtend.evaluate - mlxtend</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/color-brewer.min.css">
        <link href="../../cinder/css/base.css" rel="stylesheet">
        <link href="../../cinder/css/bootstrap-custom.css" rel="stylesheet">
        <link href="../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../cinder/css/cinder.css" rel="stylesheet">
        <link href="../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../../cinder/css/highlight.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', "UA-38457794-2", "rasbt.github.io/mlxtend/");
            ga('send', 'pageview');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">mlxtend</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../USER_GUIDE_INDEX/" class="dropdown-item">User Guide Index</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">classifier</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/classifier/Adaline/" class="dropdown-item">Adaline: Adaptive Linear Neuron Classifier</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/EnsembleVoteClassifier/" class="dropdown-item">EnsembleVoteClassifier: A majority voting classifier</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/LogisticRegression/" class="dropdown-item">LogisticRegression: A binary classifier</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/MultiLayerPerceptron/" class="dropdown-item">MultilayerPerceptron: A simple multilayer neural network</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/OneRClassifier/" class="dropdown-item">OneRClassifier: One Rule (OneR) method for classfication</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/Perceptron/" class="dropdown-item">Perceptron: A simple binary classifier</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/SoftmaxRegression/" class="dropdown-item">SoftmaxRegression: Multiclass version of logistic regression</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/StackingClassifier/" class="dropdown-item">StackingClassifier: Simple stacking</a>
</li>
            
<li>
    <a href="../../user_guide/classifier/StackingCVClassifier/" class="dropdown-item">StackingCVClassifier: Stacking with cross-validation</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">cluster</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/cluster/Kmeans/" class="dropdown-item">Kmeans: k-means clustering</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">data</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/data/autompg_data/" class="dropdown-item">autompg_data: The Auto-MPG dataset for regression</a>
</li>
            
<li>
    <a href="../../user_guide/data/boston_housing_data/" class="dropdown-item">boston_housing_data: The Boston housing dataset for regression</a>
</li>
            
<li>
    <a href="../../user_guide/data/iris_data/" class="dropdown-item">iris_data: The 3-class iris dataset for classification</a>
</li>
            
<li>
    <a href="../../user_guide/data/loadlocal_mnist/" class="dropdown-item">loadlocal_mnist: A function for loading MNIST from the original ubyte files</a>
</li>
            
<li>
    <a href="../../user_guide/data/make_multiplexer_dataset/" class="dropdown-item">make_multiplexer_dataset: A function for creating multiplexer data</a>
</li>
            
<li>
    <a href="../../user_guide/data/mnist_data/" class="dropdown-item">mnist_data: A subset of the MNIST dataset for classification</a>
</li>
            
<li>
    <a href="../../user_guide/data/three_blobs_data/" class="dropdown-item">three_blobs_data: The synthetic blobs for classification</a>
</li>
            
<li>
    <a href="../../user_guide/data/wine_data/" class="dropdown-item">wine_data: A 3-class wine dataset for classification</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">evaluate</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/evaluate/accuracy_score/" class="dropdown-item">accuracy_score: Computing standard, balanced, and per-class accuracy</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/bias_variance_decomp/" class="dropdown-item">bias_variance_decomp: Bias-variance decomposition for classification and regression losses</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/bootstrap/" class="dropdown-item">bootstrap: The ordinary nonparametric boostrap for arbitrary parameters</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/bootstrap_point632_score/" class="dropdown-item">bootstrap_point632_score: The .632 and .632+ boostrap for classifier evaluation</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/BootstrapOutOfBag/" class="dropdown-item">BootstrapOutOfBag: A scikit-learn compatible version of the out-of-bag bootstrap</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/cochrans_q/" class="dropdown-item">cochrans_q: Cochran's Q test for comparing multiple classifiers</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/combined_ftest_5x2cv/" class="dropdown-item">combined_ftest_5x2cv: 5x2cv combined F test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/confusion_matrix/" class="dropdown-item">confusion_matrix: creating a confusion matrix for model evaluation</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/create_counterfactual/" class="dropdown-item">create_counterfactual: Interpreting models via counterfactuals</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/feature_importance_permutation/" class="dropdown-item">feature_importance_permutation: Estimate feature importance via feature permutation.</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/ftest/" class="dropdown-item">ftest: F-test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/GroupTimeSeriesSplit/" class="dropdown-item">GroupTimeSeriesSplit: A scikit-learn compatible version of the time series validation with groups</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/lift_score/" class="dropdown-item">lift_score: Lift score for classification and association rule mining</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/mcnemar_table/" class="dropdown-item">mcnemar_table: Contingency table for McNemar's test</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/mcnemar_tables/" class="dropdown-item">mcnemar_tables: contingency tables for McNemar's test and Cochran's Q test</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/mcnemar/" class="dropdown-item">mcnemar: McNemar's test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/paired_ttest_5x2cv/" class="dropdown-item">paired_ttest_5x2cv: 5x2cv paired t test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/paired_ttest_kfold_cv/" class="dropdown-item">paired_ttest_kfold_cv: K-fold cross-validated paired t test</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/paired_ttest_resampled/" class="dropdown-item">paired_ttest_resample: Resampled paired t test</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/permutation_test/" class="dropdown-item">permutation_test: Permutation test for hypothesis testing</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/PredefinedHoldoutSplit/" class="dropdown-item">PredefinedHoldoutSplit: Utility for the holdout method compatible with scikit-learn</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/RandomHoldoutSplit/" class="dropdown-item">RandomHoldoutSplit: split a dataset into a train and validation subset for validation</a>
</li>
            
<li>
    <a href="../../user_guide/evaluate/scoring/" class="dropdown-item">scoring: computing various performance metrics</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">feature_extraction</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/feature_extraction/LinearDiscriminantAnalysis/" class="dropdown-item">LinearDiscriminantAnalysis: Linear discriminant analysis for dimensionality reduction</a>
</li>
            
<li>
    <a href="../../user_guide/feature_extraction/PrincipalComponentAnalysis/" class="dropdown-item">PrincipalComponentAnalysis: Principal component analysis (PCA) for dimensionality reduction</a>
</li>
            
<li>
    <a href="../../user_guide/feature_extraction/RBFKernelPCA/" class="dropdown-item">RBFKernelPCA</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">feature_selection</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/feature_selection/ColumnSelector/" class="dropdown-item">ColumnSelector: Scikit-learn utility function to select specific columns in a pipeline</a>
</li>
            
<li>
    <a href="../../user_guide/feature_selection/ExhaustiveFeatureSelector/" class="dropdown-item">ExhaustiveFeatureSelector: Optimal feature sets by considering all possible feature combinations</a>
</li>
            
<li>
    <a href="../../user_guide/feature_selection/SequentialFeatureSelector/" class="dropdown-item">SequentialFeatureSelector: The popular forward and backward feature selection approaches (including floating variants)</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">file_io</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/file_io/find_filegroups/" class="dropdown-item">find_filegroups: Find files that only differ via their file extensions</a>
</li>
            
<li>
    <a href="../../user_guide/file_io/find_files/" class="dropdown-item">find_files: Find files based on substring matches</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">frequent_patterns</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/frequent_patterns/apriori/" class="dropdown-item">Apriori</a>
</li>
            
<li>
    <a href="../../user_guide/frequent_patterns/association_rules/" class="dropdown-item">Association rules</a>
</li>
            
<li>
    <a href="../../user_guide/frequent_patterns/fpgrowth/" class="dropdown-item">Fpgrowth</a>
</li>
            
<li>
    <a href="../../user_guide/frequent_patterns/fpmax/" class="dropdown-item">Fpmax</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">math</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/math/num_combinations/" class="dropdown-item">num_combinations: combinations for creating subsequences of k elements</a>
</li>
            
<li>
    <a href="../../user_guide/math/num_permutations/" class="dropdown-item">num_permutations: number of permutations for creating subsequences of k elements</a>
</li>
            
<li>
    <a href="../../user_guide/math/vectorspace_dimensionality/" class="dropdown-item">vectorspace_dimensionality: compute the number of dimensions that a set of vectors spans</a>
</li>
            
<li>
    <a href="../../user_guide/math/vectorspace_orthonormalization/" class="dropdown-item">vectorspace_orthonormalization: Converts a set of linearly independent vectors to a set of orthonormal basis vectors</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">plotting</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/plotting/category_scatter/" class="dropdown-item">Scategory_scatter: Create a scatterplot with categories in different colors</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/checkerboard_plot/" class="dropdown-item">checkerboard_plot: Create a checkerboard plot in matplotlib</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/plot_pca_correlation_graph/" class="dropdown-item">plot_pca_correlation_graph: plot correlations between original features and principal components</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/ecdf/" class="dropdown-item">ecdf: Create an empirical cumulative distribution function plot</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/enrichment_plot/" class="dropdown-item">enrichment_plot: create an enrichment plot for cumulative counts</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/heatmap/" class="dropdown-item">heatmap: Create a heatmap in matplotlib</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/plot_confusion_matrix/" class="dropdown-item">plot_confusion_matrix: Visualize confusion matrices</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/plot_decision_regions/" class="dropdown-item">plot_decision_regions: Visualize the decision regions of a classifier</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/plot_learning_curves/" class="dropdown-item">plot_learning_curves: Plot learning curves from training and test sets</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/plot_linear_regression/" class="dropdown-item">plot_linear_regression: A quick way for plotting linear regression fits</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/plot_sequential_feature_selection/" class="dropdown-item">plot_sequential_feature_selection: Visualize selected feature subset performances from the SequentialFeatureSelector</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/scatterplotmatrix/" class="dropdown-item">scatterplotmatrix: visualize datasets via a scatter plot matrix</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/scatter_hist/" class="dropdown-item">scatter_hist: create a scatter histogram plot</a>
</li>
            
<li>
    <a href="../../user_guide/plotting/stacked_barplot/" class="dropdown-item">stacked_barplot: Plot stacked bar plots in matplotlib</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">preprocessing</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/preprocessing/CopyTransformer/" class="dropdown-item">CopyTransformer: A function that creates a copy of the input array in a scikit-learn pipeline</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/DenseTransformer/" class="dropdown-item">DenseTransformer: Transforms a sparse into a dense NumPy array, e.g., in a scikit-learn pipeline</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/MeanCenterer/" class="dropdown-item">MeanCenterer: column-based mean centering on a NumPy array</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/minmax_scaling/" class="dropdown-item">MinMaxScaling: Min-max scaling fpr pandas DataFrames and NumPy arrays</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/one-hot_encoding/" class="dropdown-item">One hot encoding</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/shuffle_arrays_unison/" class="dropdown-item">shuffle_arrays_unison: shuffle arrays in a consistent fashion</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/standardize/" class="dropdown-item">standardize: A function to standardize columns in a 2D NumPy array</a>
</li>
            
<li>
    <a href="../../user_guide/preprocessing/TransactionEncoder/" class="dropdown-item">TransactionEncoder</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">regressor</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/regressor/LinearRegression/" class="dropdown-item">LinearRegression: An implementation of ordinary least-squares linear regression</a>
</li>
            
<li>
    <a href="../../user_guide/regressor/StackingCVRegressor/" class="dropdown-item">StackingCVRegressor: stacking with cross-validation for regression</a>
</li>
            
<li>
    <a href="../../user_guide/regressor/StackingRegressor/" class="dropdown-item">StackingRegressor: a simple stacking implementation for regression</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">text</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/text/generalize_names/" class="dropdown-item">generalize_names: convert names into a generalized format</a>
</li>
            
<li>
    <a href="../../user_guide/text/generalize_names_duplcheck/" class="dropdown-item">generalize_names_duplcheck: Generalize names while preventing duplicates among different names</a>
</li>
            
<li>
    <a href="../../user_guide/text/tokenizer/" class="dropdown-item">tokenizer_emoticons: tokenizers for emoticons</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">utils</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../user_guide/utils/Counter/" class="dropdown-item">Counter: A simple progress counter</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../mlxtend.classifier/" class="dropdown-item">Mlxtend.classifier</a>
</li>
                                    
<li>
    <a href="../mlxtend.cluster/" class="dropdown-item">Mlxtend.cluster</a>
</li>
                                    
<li>
    <a href="../mlxtend.data/" class="dropdown-item">Mlxtend.data</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">Mlxtend.evaluate</a>
</li>
                                    
<li>
    <a href="../mlxtend.feature_extraction/" class="dropdown-item">Mlxtend.feature extraction</a>
</li>
                                    
<li>
    <a href="../mlxtend.feature_selection/" class="dropdown-item">Mlxtend.feature selection</a>
</li>
                                    
<li>
    <a href="../mlxtend.file_io/" class="dropdown-item">Mlxtend.file io</a>
</li>
                                    
<li>
    <a href="../mlxtend.frequent_patterns/" class="dropdown-item">Mlxtend.frequent patterns</a>
</li>
                                    
<li>
    <a href="../mlxtend.plotting/" class="dropdown-item">Mlxtend.plotting</a>
</li>
                                    
<li>
    <a href="../mlxtend.preprocessing/" class="dropdown-item">Mlxtend.preprocessing</a>
</li>
                                    
<li>
    <a href="../mlxtend.regressor/" class="dropdown-item">Mlxtend.regressor</a>
</li>
                                    
<li>
    <a href="../mlxtend.text/" class="dropdown-item">Mlxtend.text</a>
</li>
                                    
<li>
    <a href="../mlxtend.utils/" class="dropdown-item">Mlxtend.utils</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="../../installation/" class="nav-link">Installation</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../CHANGELOG/" class="dropdown-item">Release Notes</a>
</li>
                                    
<li>
    <a href="../../Code-of-Conduct/" class="dropdown-item">Code of Conduct</a>
</li>
                                    
<li>
    <a href="../../CONTRIBUTING/" class="dropdown-item">How To Contribute</a>
</li>
                                    
<li>
    <a href="../../contributors/" class="dropdown-item">Contributors</a>
</li>
                                    
<li>
    <a href="../../license/" class="dropdown-item">License</a>
</li>
                                    
<li>
    <a href="../../cite/" class="dropdown-item">Citing Mlxtend</a>
</li>
                                    
<li>
    <a href="../../discuss/" class="dropdown-item">Discuss</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../mlxtend.data/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../mlxtend.feature_extraction/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/rasbt/mlxtend/tree/master/docs/sources/api_subpackages/mlxtend.evaluate.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#bootstrapoutofbag" class="nav-link">BootstrapOutOfBag</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#grouptimeseriessplit" class="nav-link">GroupTimeSeriesSplit</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#predefinedholdoutsplit" class="nav-link">PredefinedHoldoutSplit</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#randomholdoutsplit" class="nav-link">RandomHoldoutSplit</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#accuracy_score" class="nav-link">accuracy_score</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#bias_variance_decomp" class="nav-link">bias_variance_decomp</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#bootstrap" class="nav-link">bootstrap</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#cochrans_q" class="nav-link">cochrans_q</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#combined_ftest_5x2cv" class="nav-link">combined_ftest_5x2cv</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#confusion_matrix" class="nav-link">confusion_matrix</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#create_counterfactual" class="nav-link">create_counterfactual</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#feature_importance_permutation" class="nav-link">feature_importance_permutation</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#ftest" class="nav-link">ftest</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#lift_score" class="nav-link">lift_score</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#mcnemar" class="nav-link">mcnemar</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#mcnemar_table" class="nav-link">mcnemar_table</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#mcnemar_tables" class="nav-link">mcnemar_tables</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#paired_ttest_5x2cv" class="nav-link">paired_ttest_5x2cv</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#paired_ttest_kfold_cv" class="nav-link">paired_ttest_kfold_cv</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#paired_ttest_resampled" class="nav-link">paired_ttest_resampled</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#permutation_test" class="nav-link">permutation_test</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#proportion_difference" class="nav-link">proportion_difference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#scoring" class="nav-link">scoring</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p>mlxtend version: 0.23.4 </p>
<h2 id="bootstrapoutofbag">BootstrapOutOfBag</h2>
<p><em>BootstrapOutOfBag(n_splits=200, random_seed=None)</em></p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>n_splits</code> : int (default=200)</p>
<p>Number of bootstrap iterations.
Must be larger than 1.</p>
</li>
<li>
<p><code>random_seed</code> : int (default=None)</p>
<p>If int, random_seed is the seed used by
the random number generator.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>train_idx</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>test_idx</code> : ndarray</p>
<p>The testing set indices for that split.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/BootstrapOutOfBag/</p>
<h3 id="methods">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility with scikit-learn.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility with scikit-learn.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility with scikit-learn.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : int</p>
<p>Returns the number of splitting iterations in the cross-validator.</p>
</li>
</ul>
<hr>

<p><em>split(X, y=None, groups=None)</em></p>
<p>y : array-like or None (default: None)
    Argument is not used and only included as parameter
    for compatibility, similar to <code>KFold</code> in scikit-learn.</p>
<ul>
<li>
<p><code>groups</code> : array-like or None (default: None)</p>
<p>Argument is not used and only included as parameter
for compatibility, similar to <code>KFold</code> in scikit-learn.</p>
</li>
</ul>
<h2 id="grouptimeseriessplit">GroupTimeSeriesSplit</h2>
<p><em>GroupTimeSeriesSplit(test_size, train_size=None, n_splits=None, gap_size=0, shift_size=1, window_type='rolling')</em></p>
<p>Group time series cross-validator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>test_size</code> : int</p>
<p>Size of test dataset.</p>
</li>
<li>
<p><code>train_size</code> : int (default=None)</p>
<p>Size of train dataset.</p>
</li>
<li>
<p><code>n_splits</code> : int (default=None)</p>
<p>Number of the splits.</p>
</li>
<li>
<p><code>gap_size</code> : int (default=0)</p>
<p>Gap size between train and test datasets.</p>
</li>
<li>
<p><code>shift_size</code> : int (default=1)</p>
<p>Step to shift for the next fold.</p>
</li>
<li>
<p><code>window_type</code> : str (default="rolling")</p>
<p>Type of the window. Possible values: "rolling", "expanding".</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/GroupTimeSeriesSplit/</p>
<h3 id="methods_1">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : int</p>
<p>Returns the number of splitting iterations in the cross-validator.</p>
</li>
</ul>
<hr>

<p><em>split(X, y=None, groups=None)</em></p>
<p>Generate indices to split data into training and test set.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like</p>
<p>Training data.</p>
</li>
<li>
<p><code>y</code> : array-like (default=None)</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>groups</code> : array-like (default=None)</p>
<p>Array with group names or sequence numbers.</p>
</li>
</ul>
<p><strong>Yields</strong></p>
<ul>
<li>
<p><code>train</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>test</code> : ndarray</p>
<p>The testing set indices for that split.</p>
</li>
</ul>
<h2 id="predefinedholdoutsplit">PredefinedHoldoutSplit</h2>
<p><em>PredefinedHoldoutSplit(valid_indices)</em></p>
<p>Train/Validation set splitter for sklearn's GridSearchCV etc.</p>
<pre><code>Uses user-specified train/validation set indices to split a dataset
into train/validation sets using user-defined or random
indices.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>valid_indices</code> : array-like, shape (num_examples,)</p>
<p>Indices of the training examples in the training set
to be used for validation. All other indices in the
training set are used to for a training subset
for model fitting.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/PredefinedHoldoutSplit/</p>
<h3 id="methods_2">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : 1</p>
<p>Returns the number of splitting iterations in the cross-validator.
Always returns 1.</p>
</li>
</ul>
<hr>

<p><em>split(X, y, groups=None)</em></p>
<p>Generate indices to split data into training and test set.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape (num_examples, num_features)</p>
<p>Training data, where num_examples is the number of examples
and num_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape (num_examples,)</p>
<p>The target variable for supervised learning problems.
Stratification is done based on the y labels.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Yields</strong></p>
<ul>
<li>
<p><code>train_index</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>valid_index</code> : ndarray</p>
<p>The validation set indices for that split.</p>
</li>
</ul>
<h2 id="randomholdoutsplit">RandomHoldoutSplit</h2>
<p><em>RandomHoldoutSplit(valid_size=0.5, random_seed=None, stratify=False)</em></p>
<p>Train/Validation set splitter for sklearn's GridSearchCV etc.</p>
<pre><code>Provides train/validation set indices to split a dataset
into train/validation sets using random indices.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>valid_size</code> : float (default: 0.5)</p>
<p>Proportion of examples that being assigned as
validation examples. 1-<code>valid_size</code> will then automatically
be assigned as training set examples.</p>
</li>
<li>
<p><code>random_seed</code> : int (default: None)</p>
<p>The random seed for splitting the data
into training and validation set partitions.</p>
</li>
<li>
<p><code>stratify</code> : bool (default: False)</p>
<p>True or False, whether to perform a stratified
split or not</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/RandomHoldoutSplit/</p>
<h3 id="methods_3">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : 1</p>
<p>Returns the number of splitting iterations in the cross-validator.
Always returns 1.</p>
</li>
</ul>
<hr>

<p><em>split(X, y, groups=None)</em></p>
<p>Generate indices to split data into training and test set.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape (num_examples, num_features)</p>
<p>Training data, where num_examples is the number of
training examples and num_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape (num_examples,)</p>
<p>The target variable for supervised learning problems.
Stratification is done based on the y labels.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Yields</strong></p>
<ul>
<li>
<p><code>train_index</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>valid_index</code> : ndarray</p>
<p>The validation set indices for that split.</p>
</li>
</ul>
<h2 id="accuracy_score">accuracy_score</h2>
<p><em>accuracy_score(y_target, y_predicted, method='standard', pos_label=1, normalize=True)</em></p>
<p>General accuracy function for supervised learning.
<strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_values]</p>
<p>True class labels or target values.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_values]</p>
<p>Predicted class labels or target values.</p>
</li>
<li>
<p><code>method</code> : str, 'standard' by default.</p>
<p>The chosen method for accuracy computation.
If set to 'standard', computes overall accuracy.
If set to 'binary', computes accuracy for class pos_label.
If set to 'average', computes average per-class (balanced) accuracy.
If set to 'balanced', computes the scikit-learn-style balanced accuracy.</p>
</li>
<li>
<p><code>pos_label</code> : str or int, 1 by default.</p>
<p>The class whose accuracy score is to be reported.
Used only when <code>method</code> is set to 'binary'</p>
</li>
<li>
<p><code>normalize</code> : bool, True by default.</p>
<p>If True, returns fraction of correctly classified samples.
If False, returns number of correctly classified samples.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>score: float</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/accuracy_score/</p>
<h2 id="bias_variance_decomp">bias_variance_decomp</h2>
<p><em>bias_variance_decomp(estimator, X_train, y_train, X_test, y_test, loss='0-1_loss', num_rounds=200, random_seed=None, </em><em>fit_params)</em></p>
<p>estimator : object
    A classifier or regressor object or class implementing both a
    <code>fit</code> and <code>predict</code> method similar to the scikit-learn API.</p>
<ul>
<li>
<p><code>X_train</code> : array-like, shape=(num_examples, num_features)</p>
<p>A training dataset for drawing the bootstrap samples to carry
out the bias-variance decomposition.</p>
</li>
<li>
<p><code>y_train</code> : array-like, shape=(num_examples)</p>
<p>Targets (class labels, continuous values in case of regression)
associated with the <code>X_train</code> examples.</p>
</li>
<li>
<p><code>X_test</code> : array-like, shape=(num_examples, num_features)</p>
<p>The test dataset for computing the average loss, bias,
and variance.</p>
</li>
<li>
<p><code>y_test</code> : array-like, shape=(num_examples)</p>
<p>Targets (class labels, continuous values in case of regression)
associated with the <code>X_test</code> examples.</p>
</li>
<li>
<p><code>loss</code> : str (default='0-1_loss')</p>
<p>Loss function for performing the bias-variance decomposition.
Currently allowed values are '0-1_loss' and 'mse'.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default=200)</p>
<p>Number of bootstrap rounds (sampling from the training set)
for performing the bias-variance decomposition. Each bootstrap
sample has the same size as the original training set.</p>
</li>
<li>
<p><code>random_seed</code> : int (default=None)</p>
<p>Random seed for the bootstrap sampling used for the
bias-variance decomposition.</p>
</li>
<li>
<p><code>fit_params</code> : additional parameters</p>
<p>Additional parameters to be passed to the .fit() function of the
estimator when it is fit to the bootstrap samples.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>avg_expected_loss, avg_bias, avg_var</code> : returns the average expected</p>
<p>average bias, and average bias (all floats), where the average
is computed over the data points in the test set.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/</p>
<h2 id="bootstrap">bootstrap</h2>
<p><em>bootstrap(x, func, num_rounds=1000, ci=0.95, ddof=1, seed=None)</em></p>
<p>Implements the ordinary nonparametric bootstrap</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>x</code> : NumPy array, shape=(n_samples, [n_columns])</p>
<p>An one or multidimensional array of data records</p>
</li>
<li>
<p><code>func</code> : <func></p>
<p>A function which computes a statistic that is used
to compute the bootstrap replicates (the statistic computed
from the bootstrap samples). This function must return a
scalar value. For example, <code>np.mean</code> or <code>np.median</code> would be
an acceptable argument for <code>func</code> if <code>x</code> is a 1-dimensional array
or vector.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default=1000)</p>
<p>The number of bootstrap samples to draw where each
bootstrap sample has the same number of records as the
original dataset.</p>
</li>
<li>
<p><code>ci</code> : int (default=0.95)</p>
<p>An integer in the range (0, 1) that represents the
confidence level for computing the confidence interval.
For example, <code>ci=0.95</code> (default)
will compute the 95% confidence
interval from the bootstrap replicates.</p>
</li>
<li>
<p><code>ddof</code> : int</p>
<p>The delta degrees of freedom used when computing the
standard error.</p>
</li>
<li>
<p><code>seed</code> : int or None (default=None)</p>
<p>Random seed for generating bootstrap samples.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>original, standard_error, (lower_ci, upper_ci)</code> : tuple</p>
<p>Returns the statistic of the original sample (<code>original</code>),
the standard error of the estimate, and the
respective confidence interval bounds.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>```
&gt;&gt;&gt; from mlxtend.evaluate import bootstrap
&gt;&gt;&gt; rng = np.random.RandomState(123)
&gt;&gt;&gt; x = rng.normal(loc=5., size=100)
&gt;&gt;&gt; original, std_err, ci_bounds = bootstrap(x,
...                                          num_rounds=1000,
...                                          func=np.mean,
...                                          ci=0.95,
...                                          seed=123)
&gt;&gt;&gt; print('Mean: %.2f, SE: +/- %.2f, CI95: [%.2f, %.2f]' % (original,
...                                                         std_err,
...                                                         ci_bounds[0],
...                                                         ci_bounds[1]))
Mean: 5.03, SE: +/- 0.11, CI95: [4.80, 5.26]
&gt;&gt;&gt;

For more usage examples, please see
https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap/
</code></pre>
<pre><code>



## bootstrap_point632_score

*bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, predict_proba=False, random_seed=None, clone_estimator=True, **fit_params)*

Implementation of the .632 [1] and .632+ [2] bootstrap
    for supervised learning

    References:

    - [1] Efron, Bradley. 1983. &quot;Estimating the Error Rate
    of a Prediction Rule: Improvement on Cross-Validation.&quot;
    Journal of the American Statistical Association
    78 (382): 316. doi:10.2307/2288636.
    - [2] Efron, Bradley, and Robert Tibshirani. 1997.
    &quot;Improvements on Cross-Validation: The .632+ Bootstrap Method.&quot;
    Journal of the American Statistical Association
    92 (438): 548. doi:10.2307/2965703.

**Parameters**

- `estimator` : object

    An estimator for classification or regression that
    follows the scikit-learn API and implements &quot;fit&quot; and &quot;predict&quot;
    methods.


- `X` : array-like

    The data to fit. Can be, for example a list, or an array at least 2d.


- `y` : array-like, optional, default: None

    The target variable to try to predict in the case of
    supervised learning.


- `n_splits` : int (default=200)

    Number of bootstrap iterations.
    Must be larger than 1.


- `method` : str (default='.632')

    The bootstrap method, which can be either
    - 1) '.632' bootstrap (default)
    - 2) '.632+' bootstrap
    - 3) 'oob' (regular out-of-bag, no weighting)
    for comparison studies.


- `scoring_func` : callable,

    Score function (or loss function) with signature
``scoring_func(y, y_pred, **kwargs)``.
    If none, uses classification accuracy if the

estimator is a classifier and mean squared error
    if the estimator is a regressor.


- `predict_proba` : bool

    Whether to use the `predict_proba` function for the
    `estimator` argument. This is to be used in conjunction
    with `scoring_func` which takes in probability values
    instead of actual predictions.
    For example, if the scoring_func is
    :meth:`sklearn.metrics.roc_auc_score`, then use
    `predict_proba=True`.
    Note that this requires `estimator` to have
    `predict_proba` method implemented.


- `random_seed` : int (default=None)

    If int, random_seed is the seed used by
    the random number generator.


- `clone_estimator` : bool (default=True)

    Clones the estimator if true, otherwise fits
    the original.


- `fit_params` : additional parameters

    Additional parameters to be passed to the .fit() function of the
    estimator when it is fit to the bootstrap samples.


**Returns**

- `scores` : array of float, shape=(len(list(n_splits)),)

    Array of scores of the estimator for each bootstrap
    replicate.

**Examples**

</code></pre>
<pre><code>&gt;&gt;&gt; from sklearn import datasets, linear_model
&gt;&gt;&gt; from mlxtend.evaluate import bootstrap_point632_score
&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; X = iris.data
&gt;&gt;&gt; y = iris.target
&gt;&gt;&gt; lr = linear_model.LogisticRegression()
&gt;&gt;&gt; scores = bootstrap_point632_score(lr, X, y)
&gt;&gt;&gt; acc = np.mean(scores)
&gt;&gt;&gt; print('Accuracy:', acc)
0.953023146884
&gt;&gt;&gt; lower = np.percentile(scores, 2.5)
&gt;&gt;&gt; upper = np.percentile(scores, 97.5)
&gt;&gt;&gt; print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))
95% Confidence interval: [0.90, 0.98]

For more usage examples, please see
https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/
</code></pre>
<p>```</p>
<h2 id="cochrans_q">cochrans_q</h2>
<p><em>cochrans_q(y_target, </em>y_model_predictions)*</p>
<p>Cochran's Q test to compare 2 or more models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>*y_model_predictions</code> : array-likes, shape=[n_samples]</p>
<p>Variable number of 2 or more arrays that
contain the predicted class labels
from models as 1D NumPy array.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>q, p</code> : float or None, float</p>
<p>Returns the Q (chi-squared) value and the p-value</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/cochrans_q/</p>
<h2 id="combined_ftest_5x2cv">combined_ftest_5x2cv</h2>
<p><em>combined_ftest_5x2cv(estimator1, estimator2, X, y, scoring=None, random_seed=None)</em></p>
<p>Implements the 5x2cv combined F test proposed
    by Alpaydin 1999,
    to compare the performance of two models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for creating the test/train splits.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>f</code> : float</p>
<p>The F-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/combined_ftest_5x2cv/</p>
<h2 id="confusion_matrix">confusion_matrix</h2>
<p><em>confusion_matrix(y_target, y_predicted, binary=False, positive_label=1)</em></p>
<p>Compute a confusion matrix/contingency table.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels.</p>
</li>
<li>
<p><code>binary</code> : bool (default: False)</p>
<p>Maps a multi-class problem onto a
binary confusion matrix, where
the positive class is 1 and
all other classes are 0.</p>
</li>
<li>
<p><code>positive_label</code> : int (default: 1)</p>
<p>Class label of the positive class.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>mat</code> : array-like, shape=[n_classes, n_classes]</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix/</p>
<h2 id="create_counterfactual">create_counterfactual</h2>
<p><em>create_counterfactual(x_reference, y_desired, model, X_dataset, y_desired_proba=None, lammbda=0.1, random_seed=None)</em></p>
<p>Implementation of the counterfactual method by Wachter et al. 2017</p>
<pre><code>References:

- Wachter, S., Mittelstadt, B., &amp; Russell, C. (2017).
Counterfactual explanations without opening the black box:
Automated decisions and the GDPR. Harv. JL &amp; Tech., 31, 841.,
https://arxiv.org/abs/1711.00399
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>x_reference</code> : array-like, shape=[m_features]</p>
<p>The data instance (training example) to be explained.</p>
</li>
<li>
<p><code>y_desired</code> : int</p>
<p>The desired class label for <code>x_reference</code>.</p>
</li>
<li>
<p><code>model</code> : estimator</p>
<p>A (scikit-learn) estimator implementing <code>.predict()</code> and/or
<code>predict_proba()</code>.
- If <code>model</code> supports <code>predict_proba()</code>, then this is used by
default for the first loss term,
<code>(lambda * model.predict[_proba](x_counterfact) - y_desired[_proba])^2</code>
- Otherwise, method will fall back to <code>predict</code>.</p>
</li>
<li>
<p><code>X_dataset</code> : array-like, shape=[n_examples, m_features]</p>
<p>A (training) dataset for picking the initial counterfactual
as initial value for starting the optimization procedure.</p>
</li>
<li>
<p><code>y_desired_proba</code> : float (default: None)</p>
<p>A float within the range [0, 1] designating the desired
class probability for <code>y_desired</code>.
- If <code>y_desired_proba=None</code> (default), the first loss term
is <code>(lambda * model(x_counterfact) - y_desired)^2</code> where <code>y_desired</code>
is a class label
- If <code>y_desired_proba</code> is not None, the first loss term
is <code>(lambda * model(x_counterfact) - y_desired_proba)^2</code></p>
</li>
<li>
<p><code>lammbda</code> : Weighting parameter for the first loss term,</p>
<p><code>(lambda * model(x_counterfact) - y_desired[_proba])^2</code></p>
</li>
<li>
<p><code>random_seed</code> : int (default=None)</p>
<p>If int, random_seed is the seed used by
the random number generator for selecting the inital counterfactual
from <code>X_dataset</code>.</p>
</li>
</ul>
<h2 id="feature_importance_permutation">feature_importance_permutation</h2>
<p><em>feature_importance_permutation(X, y, predict_method, metric, num_rounds=1, feature_groups=None, seed=None)</em></p>
<p>Feature importance imputation via permutation importance</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : NumPy array, shape = [n_samples, n_features]</p>
<p>Dataset, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : NumPy array, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>predict_method</code> : prediction function</p>
<p>A callable function that predicts the target values
from X.</p>
</li>
<li>
<p><code>metric</code> : str, callable</p>
<p>The metric for evaluating the feature importance through
permutation. By default, the strings 'accuracy' is
recommended for classifiers and the string 'r2' is
recommended for regressors. Optionally, a custom
scoring function (e.g., <code>metric=scoring_func</code>) that
accepts two arguments, y_true and y_pred, which have
similar shape to the <code>y</code> array.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default=1)</p>
<p>Number of rounds the feature columns are permuted to
compute the permutation importance.</p>
</li>
<li>
<p><code>feature_groups</code> : list or None (default=None)</p>
<p>Optional argument for treating certain features as a group.
For example <code>[1, 2, [3, 4, 5]]</code>, which can be useful for
interpretability, for example, if features 3, 4, 5 are one-hot
encoded features.</p>
</li>
<li>
<p><code>seed</code> : int or None (default=None)</p>
<p>Random seed for permuting the feature columns.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>mean_importance_vals, all_importance_vals</code> : NumPy arrays.</p>
<p>The first array, mean_importance_vals has shape [n_features, ] and
contains the importance values for all features.
The shape of the second array is [n_features, num_rounds] and contains
the feature importance for each repetition. If num_rounds=1,
it contains the same values as the first array, mean_importance_vals.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/feature_importance_permutation/</p>
<h2 id="ftest">ftest</h2>
<p><em>ftest(y_target, </em>y_model_predictions)*</p>
<p>F-Test test to compare 2 or more models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>*y_model_predictions</code> : array-likes, shape=[n_samples]</p>
<p>Variable number of 2 or more arrays that
contain the predicted class labels
from models as 1D NumPy array.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>f, p</code> : float or None, float</p>
<p>Returns the F-value and the p-value</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/ftest/</p>
<h2 id="lift_score">lift_score</h2>
<p><em>lift_score(y_target, y_predicted, binary=True, positive_label=1)</em></p>
<p>Lift measures the degree to which the predictions of a
    classification model are better than randomly-generated predictions.</p>
<pre><code>The in terms of True Positives (TP), True Negatives (TN),
False Positives (FP), and False Negatives (FN), the lift score is
computed as:
[ TP / (TP+FP) ] / [ (TP+FN) / (TP+TN+FP+FN) ]
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels.</p>
</li>
<li>
<p><code>binary</code> : bool (default: True)</p>
<p>Maps a multi-class problem onto a
binary, where
the positive class is 1 and
all other classes are 0.</p>
</li>
<li>
<p><code>positive_label</code> : int (default: 0)</p>
<p>Class label of the positive class.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>score</code> : float</p>
<p>Lift score in the range [0, infinity]</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/lift_score/</p>
<h2 id="mcnemar">mcnemar</h2>
<p><em>mcnemar(ary, corrected=True, exact=False)</em></p>
<p>McNemar test for paired nominal data</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>ary</code> : array-like, shape=[2, 2]</p>
<p>2 x 2 contigency table (as returned by evaluate.mcnemar_table),
where
a: ary[0, 0]: # of samples that both models predicted correctly
b: ary[0, 1]: # of samples that model 1 got right and model 2 got wrong
c: ary[1, 0]: # of samples that model 2 got right and model 1 got wrong
d: aryCell [1, 1]: # of samples that both models predicted incorrectly</p>
</li>
<li>
<p><code>corrected</code> : array-like, shape=[n_samples] (default: True)</p>
<p>Uses Edward's continuity correction for chi-squared if <code>True</code></p>
</li>
<li>
<p><code>exact</code> : bool, (default: False)</p>
<p>If <code>True</code>, uses an exact binomial test comparing b to
a binomial distribution with n = b + c and p = 0.5.
It is highly recommended to use <code>exact=True</code> for sample sizes &lt; 25
since chi-squared is not well-approximated
by the chi-squared distribution!</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>chi2, p</code> : float or None, float</p>
<p>Returns the chi-squared value and the p-value;
if <code>exact=True</code> (default: <code>False</code>), <code>chi2</code> is <code>None</code></p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>For usage examples, please see
https://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar/
</code></pre>
<h2 id="mcnemar_table">mcnemar_table</h2>
<p><em>mcnemar_table(y_target, y_model1, y_model2)</em></p>
<p>Compute a 2x2 contigency table for McNemar's test.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>y_model1</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels from model as 1D NumPy array.</p>
</li>
<li>
<p><code>y_model2</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels from model 2 as 1D NumPy array.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>tb</code> : array-like, shape=[2, 2]</p>
<p>2x2 contingency table with the following contents:
a: tb[0, 0]: # of samples that both models predicted correctly
b: tb[0, 1]: # of samples that model 1 got right and model 2 got wrong
c: tb[1, 0]: # of samples that model 2 got right and model 1 got wrong
d: tb[1, 1]: # of samples that both models predicted incorrectly</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar_table/</p>
<h2 id="mcnemar_tables">mcnemar_tables</h2>
<p><em>mcnemar_tables(y_target, </em>y_model_predictions)*</p>
<p>Compute multiple 2x2 contigency tables for McNemar's
    test or Cochran's Q test.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>y_model_predictions</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels for a model.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>tables</code> : dict</p>
<p>Dictionary of NumPy arrays with shape=[2, 2]. Each dictionary
key names the two models to be compared based on the order the
models were passed as <code>*y_model_predictions</code>. The number of
dictionary entries is equal to the number of pairwise combinations
between the m models, i.e., "m choose 2."</p>
<p>For example the following target array (containing the true labels)
and 3 models</p>
<ul>
<li>y_true = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])</li>
<li>y_mod0 = np.array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0])</li>
<li>y_mod1 = np.array([0, 0, 1, 1, 0, 1, 1, 0, 0, 0])</li>
<li>y_mod2 = np.array([0, 1, 1, 1, 0, 1, 0, 0, 0, 0])</li>
</ul>
<p>would result in the following dictionary:</p>
<p>{'model_0 vs model_1': array([[ 4.,  1.],
[ 2.,  3.]]),
'model_0 vs model_2': array([[ 3.,  0.],
[ 3.,  4.]]),
'model_1 vs model_2': array([[ 3.,  0.],
[ 2.,  5.]])}</p>
<p>Each array is structured in the following way:</p>
<ul>
<li>tb[0, 0]: # of samples that both models predicted correctly</li>
<li>tb[0, 1]: # of samples that model a got right and model b got wrong</li>
<li>tb[1, 0]: # of samples that model b got right and model a got wrong</li>
<li>tb[1, 1]: # of samples that both models predicted incorrectly</li>
</ul>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>For usage examples, please see
https://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar_tables/
</code></pre>
<h2 id="paired_ttest_5x2cv">paired_ttest_5x2cv</h2>
<p><em>paired_ttest_5x2cv(estimator1, estimator2, X, y, scoring=None, random_seed=None)</em></p>
<p>Implements the 5x2cv paired t test proposed
    by Dieterrich (1998)
    to compare the performance of two models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for creating the test/train splits.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>t</code> : float</p>
<p>The t-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/</p>
<h2 id="paired_ttest_kfold_cv">paired_ttest_kfold_cv</h2>
<p><em>paired_ttest_kfold_cv(estimator1, estimator2, X, y, cv=10, scoring=None, shuffle=False, random_seed=None)</em></p>
<p>Implements the k-fold paired t test procedure
    to compare the performance of two models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>cv</code> : int (default: 10)</p>
<p>Number of splits and iteration for the
cross-validation procedure</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>shuffle</code> : bool (default: True)</p>
<p>Whether to shuffle the dataset for generating
the k-fold splits.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for shuffling the dataset
for generating the k-fold splits.
Ignored if shuffle=False.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>t</code> : float</p>
<p>The t-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_kfold_cv/</p>
<h2 id="paired_ttest_resampled">paired_ttest_resampled</h2>
<p><em>paired_ttest_resampled(estimator1, estimator2, X, y, num_rounds=30, test_size=0.3, scoring=None, random_seed=None)</em></p>
<p>Implements the resampled paired t test procedure
    to compare the performance of two models
    (also called k-hold-out paired t test).</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default: 30)</p>
<p>Number of resampling iterations
(i.e., train/test splits)</p>
</li>
<li>
<p><code>test_size</code> : float or int (default: 0.3)</p>
<p>If float, should be between 0.0 and 1.0 and
represent the proportion of the dataset to use
as a test set.
If int, represents the absolute number of test exsamples.</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for creating the test/train splits.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>t</code> : float</p>
<p>The t-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_resampled/</p>
<h2 id="permutation_test">permutation_test</h2>
<p><em>permutation_test(x, y, func='x_mean != y_mean', method='exact', num_rounds=1000, seed=None, paired=False)</em></p>
<p>Nonparametric permutation test</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>x</code> : list or numpy array with shape (n_datapoints,)</p>
<p>A list or 1D numpy array of the first sample
(e.g., the treatment group).</p>
</li>
<li>
<p><code>y</code> : list or numpy array with shape (n_datapoints,)</p>
<p>A list or 1D numpy array of the second sample
(e.g., the control group).</p>
</li>
<li>
<p><code>func</code> : custom function or str (default: 'x_mean != y_mean')</p>
<p>function to compute the statistic for the permutation test.
- If 'x_mean != y_mean', uses
<code>func=lambda x, y: np.abs(np.mean(x) - np.mean(y)))</code>
for a two-sided test.
- If 'x_mean &gt; y_mean', uses
<code>func=lambda x, y: np.mean(x) - np.mean(y))</code>
for a one-sided test.
- If 'x_mean &lt; y_mean', uses
<code>func=lambda x, y: np.mean(y) - np.mean(x))</code>
for a one-sided test.</p>
</li>
<li>
<p><code>method</code> : 'approximate' or 'exact' (default: 'exact')</p>
<p>If 'exact' (default), all possible permutations are considered.
If 'approximate' the number of drawn samples is
given by <code>num_rounds</code>.
Note that 'exact' is typically not feasible unless the dataset
size is relatively small.</p>
</li>
<li>
<p><code>paired</code> : bool</p>
<p>If True, a paired test is performed by only exchanging each
datapoint with its associate.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default: 1000)</p>
<p>The number of permutation samples if <code>method='approximate'</code>.</p>
</li>
<li>
<p><code>seed</code> : int or None (default: None)</p>
<p>The random seed for generating permutation samples if
<code>method='approximate'</code>.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>p-value under the null hypothesis
    Examples</p>
<hr />
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/permutation_test/</p>
<h2 id="proportion_difference">proportion_difference</h2>
<p><em>proportion_difference(proportion_1, proportion_2, n_1, n_2=None)</em></p>
<p>Computes the test statistic and p-value for a difference of
    proportions test.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>proportion_1</code> : float</p>
<p>The first proportion</p>
</li>
<li>
<p><code>proportion_2</code> : float</p>
<p>The second proportion</p>
</li>
<li>
<p><code>n_1</code> : int</p>
<p>The sample size of the first test sample</p>
</li>
<li>
<p><code>n_2</code> : int or None (default=None)</p>
<p>The sample size of the second test sample.
If <code>None</code>, <code>n_1</code>=<code>n_2</code>.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>z, p</code> : float or None, float</p>
<p>Returns the z-score and the p-value</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/proportion_difference/</p>
<h2 id="scoring">scoring</h2>
<p><em>scoring(y_target, y_predicted, metric='error', positive_label=1, unique_labels='auto')</em></p>
<p>Compute a scoring metric for supervised learning.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_values]</p>
<p>True class labels or target values.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_values]</p>
<p>Predicted class labels or target values.</p>
</li>
<li>
<p><code>metric</code> : str (default: 'error')</p>
<p>Performance metric:
'accuracy': (TP + TN)/(FP + FN + TP + TN) = 1-ERR</p>
<p>'average per-class accuracy': Average per-class accuracy</p>
<p>'average per-class error':  Average per-class error</p>
<p>'balanced per-class accuracy': Average per-class accuracy</p>
<p>'balanced per-class error':  Average per-class error</p>
<p>'error': (TP + TN)/(FP+ FN + TP + TN) = 1-ACC</p>
<p>'false_positive_rate': FP/N = FP/(FP + TN)</p>
<p>'true_positive_rate': TP/P = TP/(FN + TP)</p>
<p>'true_negative_rate': TN/N = TN/(FP + TN)</p>
<p>'precision': TP/(TP + FP)</p>
<p>'recall': equal to 'true_positive_rate'</p>
<p>'sensitivity': equal to 'true_positive_rate' or 'recall'</p>
<p>'specificity': equal to 'true_negative_rate'</p>
<p>'f1': 2 * (PRE * REC)/(PRE + REC)</p>
<p>'matthews_corr_coef':  (TP<em>TN - FP</em>FN)
/ (sqrt{(TP + FP)( TP + FN )( TN + FP )( TN + FN )})</p>
<p>Where:
[TP: True positives, TN = True negatives,</p>
<p>TN: True negatives, FN = False negatives]</p>
</li>
<li>
<p><code>positive_label</code> : int (default: 1)</p>
<p>Label of the positive class for binary classification
metrics.</p>
</li>
<li>
<p><code>unique_labels</code> : str or array-like (default: 'auto')</p>
<p>If 'auto', deduces the unique class labels from
y_target</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>score</code> : float</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    https://rasbt.github.io/mlxtend/user_guide/evaluate/scoring/</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2014-2023 <a href="https://sebastianraschka.com">Sebastian Raschka</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../js/jquery-3.6.0.min.js"></script>
        <script src="../../js/bootstrap.min.js"></script>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js"></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
        <script src="../../mathjaxhelper.js"></script>
        <script src="../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
