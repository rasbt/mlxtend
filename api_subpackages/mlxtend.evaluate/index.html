<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A library consisting of useful tools and extensions for the day-to-day data science tasks."> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.evaluate/">
    <link rel="shortcut icon" href="../../img/favicon.ico">

    <title>Mlxtend.evaluate - mlxtend</title>

    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/base.css" rel="stylesheet">
    <link href="../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">


    <link href="../../cinder/css/base.css" rel="stylesheet">


    <link href="../../cinder/css/bootstrap-custom.css" rel="stylesheet">


    <link href="../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">


    <link href="../../cinder/css/cinder.css" rel="stylesheet">


    <link href="../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">


    <link href="../../cinder/css/highlight.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../USER_GUIDE_INDEX/">User Guide Index</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/classifier/Adaline/">Adaptive Linear Neuron -- Adaline</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/EnsembleVoteClassifier/">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/LogisticRegression/">Logistic Regression</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/MultiLayerPerceptron/">Neural Network - Multilayer Perceptron</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/Perceptron/">Perceptron</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/SoftmaxRegression/">Softmax Regression</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/StackingClassifier/">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../../user_guide/classifier/StackingCVClassifier/">StackingCVClassifier</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">cluster</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/cluster/Kmeans/">Kmeans</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/data/autompg_data/">Auto MPG</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/boston_housing_data/">Boston Housing Data</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/iris_data/">Iris Dataset</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/loadlocal_mnist/">Load the MNIST Dataset from Local Files</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/make_multiplexer_dataset/">Make Multiplexer Dataset</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/mnist_data/">MNIST Dataset</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/three_blobs_data/">Three Blobs Dataset</a>
</li>

        
            
<li >
    <a href="../../user_guide/data/wine_data/">Wine Dataset</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/evaluate/accuracy_score/">Accuracy Score</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/bias_variance_decomp/">Bias-Variance Decomposition</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/bootstrap/">Bootstrap</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/bootstrap_point632_score/">bootstrap_point632_score</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/BootstrapOutOfBag/">BootstrapOutOfBag</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/cochrans_q/">Cochran's Q Test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/combined_ftest_5x2cv/">5x2cv combined *F* test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/confusion_matrix/">Confusion Matrix</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/feature_importance_permutation/">Feature Importance Permutation</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/ftest/">F-Test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/lift_score/">Lift Score</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/mcnemar_table/">Contigency Table for McNemar's Test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/mcnemar_tables/">Contigency Tables for McNemar's Test and Cochran's Q Test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/mcnemar/">McNemar's Test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/paired_ttest_5x2cv/">5x2cv paired *t* test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/paired_ttest_kfold_cv/">K-fold cross-validated paired *t* test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/paired_ttest_resampled/">Resampled paired *t* test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/permutation_test/">Permutation Test</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/PredefinedHoldoutSplit/">PredefinedHoldoutSplit</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/RandomHoldoutSplit/">RandomHoldoutSplit</a>
</li>

        
            
<li >
    <a href="../../user_guide/evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_extraction</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/feature_extraction/LinearDiscriminantAnalysis/">Linear Discriminant Analysis</a>
</li>

        
            
<li >
    <a href="../../user_guide/feature_extraction/PrincipalComponentAnalysis/">Principal Component Analysis</a>
</li>

        
            
<li >
    <a href="../../user_guide/feature_extraction/RBFKernelPCA/">RBFKernelPCA</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/feature_selection/ColumnSelector/">ColumnSelector</a>
</li>

        
            
<li >
    <a href="../../user_guide/feature_selection/ExhaustiveFeatureSelector/">Exhaustive Feature Selector</a>
</li>

        
            
<li >
    <a href="../../user_guide/feature_selection/SequentialFeatureSelector/">Sequential Feature Selector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/file_io/find_filegroups/">Find Filegroups</a>
</li>

        
            
<li >
    <a href="../../user_guide/file_io/find_files/">Find Files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">frequent_patterns</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/frequent_patterns/apriori/">Apriori</a>
</li>

        
            
<li >
    <a href="../../user_guide/frequent_patterns/association_rules/">Association rules</a>
</li>

        
            
<li >
    <a href="../../user_guide/frequent_patterns/fpgrowth/">Fpgrowth</a>
</li>

        
            
<li >
    <a href="../../user_guide/frequent_patterns/fpmax/">Fpmax</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/general_concepts/activation-functions/">Activation Functions for Artificial Neural Networks</a>
</li>

        
            
<li >
    <a href="../../user_guide/general_concepts/gradient-optimization/">Gradient Descent and Stochastic Gradient Descent</a>
</li>

        
            
<li >
    <a href="../../user_guide/general_concepts/linear-gradient-derivative/">Deriving the Gradient Descent Rule for Linear Regression and Adaline</a>
</li>

        
            
<li >
    <a href="../../user_guide/general_concepts/regularization-linear/">Regularization of Generalized Linear Models</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">image</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/image/extract_face_landmarks/">Extract Face Landmarks</a>
</li>

        
            
<li >
    <a href="../../user_guide/image/eyepad_align/">EyepadAlign</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/math/num_combinations/">Compute the Number of Combinations</a>
</li>

        
            
<li >
    <a href="../../user_guide/math/num_permutations/">Compute the Number of Permutations</a>
</li>

        
            
<li >
    <a href="../../user_guide/math/vectorspace_dimensionality/">Vectorspace Dimensionality</a>
</li>

        
            
<li >
    <a href="../../user_guide/math/vectorspace_orthonormalization/">Vectorspace Orthonormalization</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/plotting/category_scatter/">Scatterplot with Categories</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/checkerboard_plot/">Checkerboard Plot</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/plot_pca_correlation_graph/">PCA Correlation Circle</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/ecdf/">Empirical Cumulative Distribution Function Plot</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/enrichment_plot/">Enrichment Plot</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/heatmap/">Heatmap</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/plot_confusion_matrix/">Confusion Matrix</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/plot_decision_regions/">Plotting Decision Regions</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/plot_learning_curves/">Plotting Learning Curves</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/plot_linear_regression/">Linear Regression Plot</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/plot_sequential_feature_selection/">Plot Sequential Feature Selection</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/scatterplotmatrix/">Scatter Plot Matrix</a>
</li>

        
            
<li >
    <a href="../../user_guide/plotting/stacked_barplot/">Stacked Barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/preprocessing/CopyTransformer/">CopyTransformer</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/MeanCenterer/">Mean Centerer</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/minmax_scaling/">MinMax Scaling</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/shuffle_arrays_unison/">Shuffle Arrays in Unison</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/standardize/">Standardize</a>
</li>

        
            
<li >
    <a href="../../user_guide/preprocessing/TransactionEncoder/">TransactionEncoder</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/regressor/LinearRegression/">LinearRegression</a>
</li>

        
            
<li >
    <a href="../../user_guide/regressor/StackingCVRegressor/">StackingCVRegressor</a>
</li>

        
            
<li >
    <a href="../../user_guide/regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/text/generalize_names/">Generalize Names</a>
</li>

        
            
<li >
    <a href="../../user_guide/text/generalize_names_duplcheck/">Generalize Names & Duplicate Checking</a>
</li>

        
            
<li >
    <a href="../../user_guide/text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../user_guide/utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.cluster/">Mlxtend.cluster</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li class="active">
    <a href="./">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.feature_extraction/">Mlxtend.feature extraction</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.frequent_patterns/">Mlxtend.frequent patterns</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.image/">Mlxtend.image</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.plotting/">Mlxtend.plotting</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../CHANGELOG/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../CONTRIBUTING/">How To Contribute</a>
</li>

                        
                            
<li >
    <a href="../../contributors/">Contributors</a>
</li>

                        
                            
<li >
    <a href="../../license/">License</a>
</li>

                        
                            
<li >
    <a href="../../cite/">Citing Mlxtend</a>
</li>

                        
                            
<li >
    <a href="../../discuss/">Discuss</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fa fa-search"></i> Search
                        </a>
                    </li>

                <!--
                    <li >
                        <a rel="next" href="../mlxtend.data/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../mlxtend.feature_extraction/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>-->
                    <li>
                        <a href="https://github.com/rasbt/mlxtend"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#bootstrapoutofbag">BootstrapOutOfBag</a></li>
            <li class="second-level"><a href="#methods">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#predefinedholdoutsplit">PredefinedHoldoutSplit</a></li>
            <li class="second-level"><a href="#methods_1">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#randomholdoutsplit">RandomHoldoutSplit</a></li>
            <li class="second-level"><a href="#methods_2">Methods</a></li>
                 <!--   -->
        <li class="first-level "><a href="#accuracy_score">accuracy_score</a></li>
        <li class="first-level "><a href="#bias_variance_decomp">bias_variance_decomp</a></li>
        <li class="first-level "><a href="#bootstrap">bootstrap</a></li>
        <li class="first-level "><a href="#bootstrap_point632_score">bootstrap_point632_score</a></li>
        <li class="first-level "><a href="#cochrans_q">cochrans_q</a></li>
        <li class="first-level "><a href="#combined_ftest_5x2cv">combined_ftest_5x2cv</a></li>
        <li class="first-level "><a href="#confusion_matrix">confusion_matrix</a></li>
        <li class="first-level "><a href="#feature_importance_permutation">feature_importance_permutation</a></li>
        <li class="first-level "><a href="#ftest">ftest</a></li>
        <li class="first-level "><a href="#lift_score">lift_score</a></li>
        <li class="first-level "><a href="#mcnemar">mcnemar</a></li>
        <li class="first-level "><a href="#mcnemar_table">mcnemar_table</a></li>
        <li class="first-level "><a href="#mcnemar_tables">mcnemar_tables</a></li>
        <li class="first-level "><a href="#paired_ttest_5x2cv">paired_ttest_5x2cv</a></li>
        <li class="first-level "><a href="#paired_ttest_kfold_cv">paired_ttest_kfold_cv</a></li>
        <li class="first-level "><a href="#paired_ttest_resampled">paired_ttest_resampled</a></li>
        <li class="first-level "><a href="#permutation_test">permutation_test</a></li>
        <li class="first-level "><a href="#proportion_difference">proportion_difference</a></li>
        <li class="first-level "><a href="#scoring">scoring</a></li>
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<p>mlxtend version: 0.17.2 </p>
<h2 id="bootstrapoutofbag">BootstrapOutOfBag</h2>
<p><em>BootstrapOutOfBag(n_splits=200, random_seed=None)</em></p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>n_splits</code> : int (default=200)</p>
<p>Number of bootstrap iterations.
Must be larger than 1.</p>
</li>
<li>
<p><code>random_seed</code> : int (default=None)</p>
<p>If int, random_seed is the seed used by
the random number generator.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>train_idx</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>test_idx</code> : ndarray</p>
<p>The testing set indices for that split.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/BootstrapOutOfBag/">http://rasbt.github.io/mlxtend/user_guide/evaluate/BootstrapOutOfBag/</a></p>
<h3 id="methods">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility with scikit-learn.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility with scikit-learn.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility with scikit-learn.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : int</p>
<p>Returns the number of splitting iterations in the cross-validator.</p>
</li>
</ul>
<hr>

<p><em>split(X, y=None, groups=None)</em></p>
<p>y : array-like or None (default: None)
Argument is not used and only included as parameter
for compatibility, similar to <code>KFold</code> in scikit-learn.</p>
<ul>
<li>
<p><code>groups</code> : array-like or None (default: None)</p>
<p>Argument is not used and only included as parameter
for compatibility, similar to <code>KFold</code> in scikit-learn.</p>
</li>
</ul>
<h2 id="predefinedholdoutsplit">PredefinedHoldoutSplit</h2>
<p><em>PredefinedHoldoutSplit(valid_indices)</em></p>
<p>Train/Validation set splitter for sklearn's GridSearchCV etc.</p>
<p>Uses user-specified train/validation set indices to split a dataset
into train/validation sets using user-defined or random
indices.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>valid_indices</code> : array-like, shape (num_examples,)</p>
<p>Indices of the training examples in the training set
to be used for validation. All other indices in the
training set are used to for a training subset
for model fitting.</p>
</li>
</ul>
<h3 id="methods_1">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : 1</p>
<p>Returns the number of splitting iterations in the cross-validator.
Always returns 1.</p>
</li>
</ul>
<hr>

<p><em>split(X, y, groups=None)</em></p>
<p>Generate indices to split data into training and test set.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape (num_examples, num_features)</p>
<p>Training data, where num_examples is the number of examples
and num_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape (num_examples,)</p>
<p>The target variable for supervised learning problems.
Stratification is done based on the y labels.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Yields</strong></p>
<ul>
<li>
<p><code>train_index</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>valid_index</code> : ndarray</p>
<p>The validation set indices for that split.</p>
</li>
</ul>
<h2 id="randomholdoutsplit">RandomHoldoutSplit</h2>
<p><em>RandomHoldoutSplit(valid_size=0.5, random_seed=None, stratify=False)</em></p>
<p>Train/Validation set splitter for sklearn's GridSearchCV etc.</p>
<p>Provides train/validation set indices to split a dataset
into train/validation sets using random indices.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>valid_size</code> : float (default: 0.5)</p>
<p>Proportion of examples that being assigned as
validation examples. 1-<code>valid_size</code> will then automatically
be assigned as training set examples.</p>
</li>
<li>
<p><code>random_seed</code> : int (default: None)</p>
<p>The random seed for splitting the data
into training and validation set partitions.</p>
</li>
<li>
<p><code>stratify</code> : bool (default: False)</p>
<p>True or False, whether to perform a stratified
split or not</p>
</li>
</ul>
<h3 id="methods_2">Methods</h3>
<hr>

<p><em>get_n_splits(X=None, y=None, groups=None)</em></p>
<p>Returns the number of splitting iterations in the cross-validator</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>y</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>n_splits</code> : 1</p>
<p>Returns the number of splitting iterations in the cross-validator.
Always returns 1.</p>
</li>
</ul>
<hr>

<p><em>split(X, y, groups=None)</em></p>
<p>Generate indices to split data into training and test set.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape (num_examples, num_features)</p>
<p>Training data, where num_examples is the number of
training examples and num_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape (num_examples,)</p>
<p>The target variable for supervised learning problems.
Stratification is done based on the y labels.</p>
</li>
<li>
<p><code>groups</code> : object</p>
<p>Always ignored, exists for compatibility.</p>
</li>
</ul>
<p><strong>Yields</strong></p>
<ul>
<li>
<p><code>train_index</code> : ndarray</p>
<p>The training set indices for that split.</p>
</li>
<li>
<p><code>valid_index</code> : ndarray</p>
<p>The validation set indices for that split.</p>
</li>
</ul>
<h2 id="accuracy_score">accuracy_score</h2>
<p><em>accuracy_score(y_target, y_predicted, method='standard', pos_label=1, normalize=True)</em></p>
<p>General accuracy function for supervised learning.
<strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_values]</p>
<p>True class labels or target values.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_values]</p>
<p>Predicted class labels or target values.</p>
</li>
<li>
<p><code>method</code> : str, 'standard' by default.</p>
<p>The chosen method for accuracy computation.
If set to 'standard', computes overall accuracy.
If set to 'binary', computes accuracy for class pos_label.
If set to 'average', computes average per class accuracy.</p>
</li>
<li>
<p><code>pos_label</code> : str or int, 1 by default.</p>
<p>The class whose accuracy score is to be reported.
Used only when <code>method</code> is set to 'binary'</p>
</li>
<li>
<p><code>normalize</code> : bool, True by default.</p>
<p>If True, returns fraction of correctly classified samples.
If False, returns number of correctly classified samples.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>score: float</p>
<h2 id="bias_variance_decomp">bias_variance_decomp</h2>
<p><em>bias_variance_decomp(estimator, X_train, y_train, X_test, y_test, loss='0-1_loss', num_rounds=200, random_seed=None)</em></p>
<p>estimator : object
A classifier or regressor object or class implementing a <code>fit</code>
<code>predict</code> method similar to the scikit-learn API.</p>
<ul>
<li>
<p><code>X_train</code> : array-like, shape=(num_examples, num_features)</p>
<p>A training dataset for drawing the bootstrap samples to carry
out the bias-variance decomposition.</p>
</li>
<li>
<p><code>y_train</code> : array-like, shape=(num_examples)</p>
<p>Targets (class labels, continuous values in case of regression)
associated with the <code>X_train</code> examples.</p>
</li>
<li>
<p><code>X_test</code> : array-like, shape=(num_examples, num_features)</p>
<p>The test dataset for computing the average loss, bias,
and variance.</p>
</li>
<li>
<p><code>y_test</code> : array-like, shape=(num_examples)</p>
<p>Targets (class labels, continuous values in case of regression)
associated with the <code>X_test</code> examples.</p>
</li>
<li>
<p><code>loss</code> : str (default='0-1_loss')</p>
<p>Loss function for performing the bias-variance decomposition.
Currently allowed values are '0-1_loss' and 'mse'.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default=200)</p>
<p>Number of bootstrap rounds for performing the bias-variance
decomposition.</p>
</li>
<li>
<p><code>random_seed</code> : int (default=None)</p>
<p>Random seed for the bootstrap sampling used for the
bias-variance decomposition.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>avg_expected_loss, avg_bias, avg_var</code> : returns the average expected</p>
<p>average bias, and average bias (all floats), where the average
is computed over the data points in the test set.</p>
</li>
</ul>
<h2 id="bootstrap">bootstrap</h2>
<p><em>bootstrap(x, func, num_rounds=1000, ci=0.95, ddof=1, seed=None)</em></p>
<p>Implements the ordinary nonparametric bootstrap</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>x</code> : NumPy array, shape=(n_samples, [n_columns])</p>
<p>An one or multidimensional array of data records</p>
</li>
<li>
<p><code>func</code> : <func></p>
<p>A function which computes a statistic that is used
to compute the bootstrap replicates (the statistic computed
from the bootstrap samples). This function must return a
scalar value. For example, <code>np.mean</code> or <code>np.median</code> would be
an acceptable argument for <code>func</code> if <code>x</code> is a 1-dimensional array
or vector.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default=1000)</p>
<p>The number of bootstrap samples to draw where each
bootstrap sample has the same number of records as the
original dataset.</p>
</li>
<li>
<p><code>ci</code> : int (default=0.95)</p>
<p>An integer in the range (0, 1) that represents the
confidence level for computing the confidence interval.
For example, <code>ci=0.95</code> (default)
will compute the 95% confidence
interval from the bootstrap replicates.</p>
</li>
<li>
<p><code>ddof</code> : int</p>
<p>The delta degrees of freedom used when computing the
standard error.</p>
</li>
<li>
<p><code>seed</code> : int or None (default=None)</p>
<p>Random seed for generating bootstrap samples.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>original, standard_error, (lower_ci, upper_ci)</code> : tuple</p>
<p>Returns the statistic of the original sample (<code>original</code>),
the standard error of the estimate, and the
respective confidence interval bounds.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>&gt;&gt;&gt; from mlxtend.evaluate import bootstrap
&gt;&gt;&gt; rng = np.random.RandomState(123)
&gt;&gt;&gt; x = rng.normal(loc=5., size=100)
&gt;&gt;&gt; original, std_err, ci_bounds = bootstrap(x,
...                                          num_rounds=1000,
...                                          func=np.mean,
...                                          ci=0.95,
...                                          seed=123)
&gt;&gt;&gt; print('Mean: %.2f, SE: +/- %.2f, CI95: [%.2f, %.2f]' % (original,
...                                                         std_err,
...                                                         ci_bounds[0],
...                                                         ci_bounds[1]))
Mean: 5.03, SE: +/- 0.11, CI95: [4.80, 5.26]
&gt;&gt;&gt;
</code></pre>
<p>For more usage examples, please see
<a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap/">http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap/</a></p>
<h2 id="bootstrap_point632_score">bootstrap_point632_score</h2>
<p><em>bootstrap_point632_score(estimator, X, y, n_splits=200, method='.632', scoring_func=None, random_seed=None, clone_estimator=True)</em></p>
<p>Implementation of the .632 [1] and .632+ [2] bootstrap
for supervised learning</p>
<p>References:</p>
<ul>
<li>[1] Efron, Bradley. 1983. "Estimating the Error Rate
of a Prediction Rule: Improvement on Cross-Validation."
Journal of the American Statistical Association
78 (382): 316. doi:10.2307/2288636.</li>
<li>[2] Efron, Bradley, and Robert Tibshirani. 1997.
"Improvements on Cross-Validation: The .632+ Bootstrap Method."
Journal of the American Statistical Association
92 (438): 548. doi:10.2307/2965703.</li>
</ul>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator</code> : object</p>
<p>An estimator for classification or regression that
follows the scikit-learn API and implements "fit" and "predict"
methods.</p>
</li>
<li>
<p><code>X</code> : array-like</p>
<p>The data to fit. Can be, for example a list, or an array at least 2d.</p>
</li>
<li>
<p><code>y</code> : array-like, optional, default: None</p>
<p>The target variable to try to predict in the case of
supervised learning.</p>
</li>
<li>
<p><code>n_splits</code> : int (default=200)</p>
<p>Number of bootstrap iterations.
Must be larger than 1.</p>
</li>
<li>
<p><code>method</code> : str (default='.632')</p>
<p>The bootstrap method, which can be either
- 1) '.632' bootstrap (default)
- 2) '.632+' bootstrap
- 3) 'oob' (regular out-of-bag, no weighting)
for comparison studies.</p>
</li>
<li>
<p><code>scoring_func</code> : callable,</p>
<p>Score function (or loss function) with signature
<code>scoring_func(y, y_pred, **kwargs)</code>.
If none, uses classification accuracy if the</p>
</li>
</ul>
<p>estimator is a classifier and mean squared error
    if the estimator is a regressor.</p>
<ul>
<li>
<p><code>random_seed</code> : int (default=None)</p>
<p>If int, random_seed is the seed used by
the random number generator.</p>
</li>
<li>
<p><code>clone_estimator</code> : bool (default=True)</p>
<p>Clones the estimator if true, otherwise fits
the original.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>scores</code> : array of float, shape=(len(list(n_splits)),)</p>
<p>Array of scores of the estimator for each bootstrap
replicate.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>&gt;&gt;&gt; from sklearn import datasets, linear_model
&gt;&gt;&gt; from mlxtend.evaluate import bootstrap_point632_score
&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; X = iris.data
&gt;&gt;&gt; y = iris.target
&gt;&gt;&gt; lr = linear_model.LogisticRegression()
&gt;&gt;&gt; scores = bootstrap_point632_score(lr, X, y)
&gt;&gt;&gt; acc = np.mean(scores)
&gt;&gt;&gt; print('Accuracy:', acc)
0.953023146884
&gt;&gt;&gt; lower = np.percentile(scores, 2.5)
&gt;&gt;&gt; upper = np.percentile(scores, 97.5)
&gt;&gt;&gt; print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))
95% Confidence interval: [0.90, 0.98]
</code></pre>
<p>For more usage examples, please see
<a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/">http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/</a></p>
<h2 id="cochrans_q">cochrans_q</h2>
<p><em>cochrans_q(y_target, </em>y_model_predictions)*</p>
<p>Cochran's Q test to compare 2 or more models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>*y_model_predictions</code> : array-likes, shape=[n_samples]</p>
<p>Variable number of 2 or more arrays that
contain the predicted class labels
from models as 1D NumPy array.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>q, p</code> : float or None, float</p>
<p>Returns the Q (chi-squared) value and the p-value</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/cochrans_q/">http://rasbt.github.io/mlxtend/user_guide/evaluate/cochrans_q/</a></p>
<h2 id="combined_ftest_5x2cv">combined_ftest_5x2cv</h2>
<p><em>combined_ftest_5x2cv(estimator1, estimator2, X, y, scoring=None, random_seed=None)</em></p>
<p>Implements the 5x2cv combined F test proposed
by Alpaydin 1999,
to compare the performance of two models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for creating the test/train splits.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>f</code> : float</p>
<p>The F-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/combined_ftest_5x2cv/">http://rasbt.github.io/mlxtend/user_guide/evaluate/combined_ftest_5x2cv/</a></p>
<h2 id="confusion_matrix">confusion_matrix</h2>
<p><em>confusion_matrix(y_target, y_predicted, binary=False, positive_label=1)</em></p>
<p>Compute a confusion matrix/contingency table.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels.</p>
</li>
<li>
<p><code>binary</code> : bool (default: False)</p>
<p>Maps a multi-class problem onto a
binary confusion matrix, where
the positive class is 1 and
all other classes are 0.</p>
</li>
<li>
<p><code>positive_label</code> : int (default: 1)</p>
<p>Class label of the positive class.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>mat</code> : array-like, shape=[n_classes, n_classes]</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix/">http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix/</a></p>
<h2 id="feature_importance_permutation">feature_importance_permutation</h2>
<p><em>feature_importance_permutation(X, y, predict_method, metric, num_rounds=1, seed=None)</em></p>
<p>Feature importance imputation via permutation importance</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : NumPy array, shape = [n_samples, n_features]</p>
<p>Dataset, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : NumPy array, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>predict_method</code> : prediction function</p>
<p>A callable function that predicts the target values
from X.</p>
</li>
<li>
<p><code>metric</code> : str, callable</p>
<p>The metric for evaluating the feature importance through
permutation. By default, the strings 'accuracy' is
recommended for classifiers and the string 'r2' is
recommended for regressors. Optionally, a custom
scoring function (e.g., <code>metric=scoring_func</code>) that
accepts two arguments, y_true and y_pred, which have
similar shape to the <code>y</code> array.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default=1)</p>
<p>Number of rounds the feature columns are permuted to
compute the permutation importance.</p>
</li>
<li>
<p><code>seed</code> : int or None (default=None)</p>
<p>Random seed for permuting the feature columns.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>mean_importance_vals, all_importance_vals</code> : NumPy arrays.</p>
<p>The first array, mean_importance_vals has shape [n_features, ] and
contains the importance values for all features.
The shape of the second array is [n_features, num_rounds] and contains
the feature importance for each repetition. If num_rounds=1,
it contains the same values as the first array, mean_importance_vals.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/feature_importance_permutation/">http://rasbt.github.io/mlxtend/user_guide/evaluate/feature_importance_permutation/</a></p>
<h2 id="ftest">ftest</h2>
<p><em>ftest(y_target, </em>y_model_predictions)*</p>
<p>F-Test test to compare 2 or more models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>*y_model_predictions</code> : array-likes, shape=[n_samples]</p>
<p>Variable number of 2 or more arrays that
contain the predicted class labels
from models as 1D NumPy array.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>f, p</code> : float or None, float</p>
<p>Returns the F-value and the p-value</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/ftest/">http://rasbt.github.io/mlxtend/user_guide/evaluate/ftest/</a></p>
<h2 id="lift_score">lift_score</h2>
<p><em>lift_score(y_target, y_predicted, binary=True, positive_label=1)</em></p>
<p>Lift measures the degree to which the predictions of a
classification model are better than randomly-generated predictions.</p>
<p>The in terms of True Positives (TP), True Negatives (TN),
False Positives (FP), and False Negatives (FN), the lift score is
computed as:
[ TP / (TP+FP) ] / [ (TP+FN) / (TP+TN+FP+FN) ]</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels.</p>
</li>
<li>
<p><code>binary</code> : bool (default: True)</p>
<p>Maps a multi-class problem onto a
binary, where
the positive class is 1 and
all other classes are 0.</p>
</li>
<li>
<p><code>positive_label</code> : int (default: 0)</p>
<p>Class label of the positive class.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>score</code> : float</p>
<p>Lift score in the range [0, <script type="math/tex">\infty</script>]</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/lift_score/">http://rasbt.github.io/mlxtend/user_guide/evaluate/lift_score/</a></p>
<h2 id="mcnemar">mcnemar</h2>
<p><em>mcnemar(ary, corrected=True, exact=False)</em></p>
<p>McNemar test for paired nominal data</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>ary</code> : array-like, shape=[2, 2]</p>
<p>2 x 2 contigency table (as returned by evaluate.mcnemar_table),
where
a: ary[0, 0]: # of samples that both models predicted correctly
b: ary[0, 1]: # of samples that model 1 got right and model 2 got wrong
c: ary[1, 0]: # of samples that model 2 got right and model 1 got wrong
d: aryCell [1, 1]: # of samples that both models predicted incorrectly</p>
</li>
<li>
<p><code>corrected</code> : array-like, shape=[n_samples] (default: True)</p>
<p>Uses Edward's continuity correction for chi-squared if <code>True</code></p>
</li>
<li>
<p><code>exact</code> : bool, (default: False)</p>
<p>If <code>True</code>, uses an exact binomial test comparing b to
a binomial distribution with n = b + c and p = 0.5.
It is highly recommended to use <code>exact=True</code> for sample sizes &lt; 25
since chi-squared is not well-approximated
by the chi-squared distribution!</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>chi2, p</code> : float or None, float</p>
<p>Returns the chi-squared value and the p-value;
if <code>exact=True</code> (default: <code>False</code>), <code>chi2</code> is <code>None</code></p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>For usage examples, please see
[http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar/](http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar/)
</code></pre>
<h2 id="mcnemar_table">mcnemar_table</h2>
<p><em>mcnemar_table(y_target, y_model1, y_model2)</em></p>
<p>Compute a 2x2 contigency table for McNemar's test.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>y_model1</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels from model as 1D NumPy array.</p>
</li>
<li>
<p><code>y_model2</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels from model 2 as 1D NumPy array.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>tb</code> : array-like, shape=[2, 2]</p>
<p>2x2 contingency table with the following contents:
a: tb[0, 0]: # of samples that both models predicted correctly
b: tb[0, 1]: # of samples that model 1 got right and model 2 got wrong
c: tb[1, 0]: # of samples that model 2 got right and model 1 got wrong
d: tb[1, 1]: # of samples that both models predicted incorrectly</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar_table/">http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar_table/</a></p>
<h2 id="mcnemar_tables">mcnemar_tables</h2>
<p><em>mcnemar_tables(y_target, </em>y_model_predictions)*</p>
<p>Compute multiple 2x2 contigency tables for McNemar's
test or Cochran's Q test.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_samples]</p>
<p>True class labels as 1D NumPy array.</p>
</li>
<li>
<p><code>y_model_predictions</code> : array-like, shape=[n_samples]</p>
<p>Predicted class labels for a model.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>tables</code> : dict</p>
<p>Dictionary of NumPy arrays with shape=[2, 2]. Each dictionary
key names the two models to be compared based on the order the
models were passed as <code>*y_model_predictions</code>. The number of
dictionary entries is equal to the number of pairwise combinations
between the m models, i.e., "m choose 2."</p>
<p>For example the following target array (containing the true labels)
and 3 models</p>
<ul>
<li>y_true = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])</li>
<li>y_mod0 = np.array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0])</li>
<li>y_mod0 = np.array([0, 0, 1, 1, 0, 1, 1, 0, 0, 0])</li>
<li>y_mod0 = np.array([0, 1, 1, 1, 0, 1, 0, 0, 0, 0])</li>
</ul>
<p>would result in the following dictionary:</p>
<p>{'model_0 vs model_1': array([[ 4.,  1.],
[ 2.,  3.]]),
'model_0 vs model_2': array([[ 3.,  0.],
[ 3.,  4.]]),
'model_1 vs model_2': array([[ 3.,  0.],
[ 2.,  5.]])}</p>
<p>Each array is structured in the following way:</p>
<ul>
<li>tb[0, 0]: # of samples that both models predicted correctly</li>
<li>tb[0, 1]: # of samples that model a got right and model b got wrong</li>
<li>tb[1, 0]: # of samples that model b got right and model a got wrong</li>
<li>tb[1, 1]: # of samples that both models predicted incorrectly</li>
</ul>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>For usage examples, please see
[http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar_tables/](http://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar_tables/)
</code></pre>
<h2 id="paired_ttest_5x2cv">paired_ttest_5x2cv</h2>
<p><em>paired_ttest_5x2cv(estimator1, estimator2, X, y, scoring=None, random_seed=None)</em></p>
<p>Implements the 5x2cv paired t test proposed
by Dieterrich (1998)
to compare the performance of two models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for creating the test/train splits.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>t</code> : float</p>
<p>The t-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/">http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/</a></p>
<h2 id="paired_ttest_kfold_cv">paired_ttest_kfold_cv</h2>
<p><em>paired_ttest_kfold_cv(estimator1, estimator2, X, y, cv=10, scoring=None, shuffle=False, random_seed=None)</em></p>
<p>Implements the k-fold paired t test procedure
to compare the performance of two models.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>cv</code> : int (default: 10)</p>
<p>Number of splits and iteration for the
cross-validation procedure</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>shuffle</code> : bool (default: True)</p>
<p>Whether to shuffle the dataset for generating
the k-fold splits.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for shuffling the dataset
for generating the k-fold splits.
Ignored if shuffle=False.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>t</code> : float</p>
<p>The t-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_kfold_cv/">http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_kfold_cv/</a></p>
<h2 id="paired_ttest_resampled">paired_ttest_resampled</h2>
<p><em>paired_ttest_resampled(estimator1, estimator2, X, y, num_rounds=30, test_size=0.3, scoring=None, random_seed=None)</em></p>
<p>Implements the resampled paired t test procedure
to compare the performance of two models
(also called k-hold-out paired t test).</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>estimator1</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>estimator2</code> : scikit-learn classifier or regressor</p>
</li>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default: 30)</p>
<p>Number of resampling iterations
(i.e., train/test splits)</p>
</li>
<li>
<p><code>test_size</code> : float or int (default: 0.3)</p>
<p>If float, should be between 0.0 and 1.0 and
represent the proportion of the dataset to use
as a test set.
If int, represents the absolute number of test exsamples.</p>
</li>
<li>
<p><code>scoring</code> : str, callable, or None (default: None)</p>
<p>If None (default), uses 'accuracy' for sklearn classifiers
and 'r2' for sklearn regressors.
If str, uses a sklearn scoring metric string identifier, for example
{accuracy, f1, precision, recall, roc_auc} for classifiers,
{'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',
'median_absolute_error', 'r2'} for regressors.
If a callable object or function is provided, it has to be conform with
sklearn's signature <code>scorer(estimator, X, y)</code>; see
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
for more information.</p>
</li>
<li>
<p><code>random_seed</code> : int or None (default: None)</p>
<p>Random seed for creating the test/train splits.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>t</code> : float</p>
<p>The t-statistic</p>
</li>
<li>
<p><code>pvalue</code> : float</p>
<p>Two-tailed p-value.
If the chosen significance level is larger
than the p-value, we reject the null hypothesis
and accept that there are significant differences
in the two compared models.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_resampled/">http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_resampled/</a></p>
<h2 id="permutation_test">permutation_test</h2>
<p><em>permutation_test(x, y, func='x_mean != y_mean', method='exact', num_rounds=1000, seed=None)</em></p>
<p>Nonparametric permutation test</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>x</code> : list or numpy array with shape (n_datapoints,)</p>
<p>A list or 1D numpy array of the first sample
(e.g., the treatment group).</p>
</li>
<li>
<p><code>y</code> : list or numpy array with shape (n_datapoints,)</p>
<p>A list or 1D numpy array of the second sample
(e.g., the control group).</p>
</li>
<li>
<p><code>func</code> : custom function or str (default: 'x_mean != y_mean')</p>
<p>function to compute the statistic for the permutation test.
- If 'x_mean != y_mean', uses
<code>func=lambda x, y: np.abs(np.mean(x) - np.mean(y)))</code>
for a two-sided test.
- If 'x_mean &gt; y_mean', uses
<code>func=lambda x, y: np.mean(x) - np.mean(y))</code>
for a one-sided test.
- If 'x_mean &lt; y_mean', uses
<code>func=lambda x, y: np.mean(y) - np.mean(x))</code>
for a one-sided test.</p>
</li>
<li>
<p><code>method</code> : 'approximate' or 'exact' (default: 'exact')</p>
<p>If 'exact' (default), all possible permutations are considered.
If 'approximate' the number of drawn samples is
given by <code>num_rounds</code>.
Note that 'exact' is typically not feasible unless the dataset
size is relatively small.</p>
</li>
<li>
<p><code>num_rounds</code> : int (default: 1000)</p>
<p>The number of permutation samples if <code>method='approximate'</code>.</p>
</li>
<li>
<p><code>seed</code> : int or None (default: None)</p>
<p>The random seed for generating permutation samples if
<code>method='approximate'</code>.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<p>p-value under the null hypothesis</p>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/permutation_test/">http://rasbt.github.io/mlxtend/user_guide/evaluate/permutation_test/</a></p>
<h2 id="proportion_difference">proportion_difference</h2>
<p><em>proportion_difference(proportion_1, proportion_2, n_1, n_2=None)</em></p>
<p>Computes the test statistic and p-value for a difference of
proportions test.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>proportion_1</code> : float</p>
<p>The first proportion</p>
</li>
<li>
<p><code>proportion_2</code> : float</p>
<p>The second proportion</p>
</li>
<li>
<p><code>n_1</code> : int</p>
<p>The sample size of the first test sample</p>
</li>
<li>
<p><code>n_2</code> : int or None (default=None)</p>
<p>The sample size of the second test sample.
If <code>None</code>, <code>n_1</code>=<code>n_2</code>.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>z, p</code> : float or None, float</p>
<p>Returns the z-score and the p-value</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/proportion_difference/">http://rasbt.github.io/mlxtend/user_guide/evaluate/proportion_difference/</a></p>
<h2 id="scoring">scoring</h2>
<p><em>scoring(y_target, y_predicted, metric='error', positive_label=1, unique_labels='auto')</em></p>
<p>Compute a scoring metric for supervised learning.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>y_target</code> : array-like, shape=[n_values]</p>
<p>True class labels or target values.</p>
</li>
<li>
<p><code>y_predicted</code> : array-like, shape=[n_values]</p>
<p>Predicted class labels or target values.</p>
</li>
<li>
<p><code>metric</code> : str (default: 'error')</p>
<p>Performance metric:
'accuracy': (TP + TN)/(FP + FN + TP + TN) = 1-ERR</p>
<p>'average per-class accuracy': Average per-class accuracy</p>
<p>'average per-class error':  Average per-class error</p>
<p>'error': (TP + TN)/(FP+ FN + TP + TN) = 1-ACC</p>
<p>'false_positive_rate': FP/N = FP/(FP + TN)</p>
<p>'true_positive_rate': TP/P = TP/(FN + TP)</p>
<p>'true_negative_rate': TN/N = TN/(FP + TN)</p>
<p>'precision': TP/(TP + FP)</p>
<p>'recall': equal to 'true_positive_rate'</p>
<p>'sensitivity': equal to 'true_positive_rate' or 'recall'</p>
<p>'specificity': equal to 'true_negative_rate'</p>
<p>'f1': 2 * (PRE * REC)/(PRE + REC)</p>
<p>'matthews_corr_coef':  (TP<em>TN - FP</em>FN)
/ (sqrt{(TP + FP)( TP + FN )( TN + FP )( TN + FN )})</p>
<p>Where:
[TP: True positives, TN = True negatives,</p>
<p>TN: True negatives, FN = False negatives]</p>
</li>
<li>
<p><code>positive_label</code> : int (default: 1)</p>
<p>Label of the positive class for binary classification
metrics.</p>
</li>
<li>
<p><code>unique_labels</code> : str or array-like (default: 'auto')</p>
<p>If 'auto', deduces the unique class labels from
y_target</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>score</code> : float</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/scoring/">http://rasbt.github.io/mlxtend/user_guide/evaluate/scoring/</a></p></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2019 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../js/jquery-1.10.2.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../..';
    </script>
    <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
    <script src="../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../mathjaxhelper.js"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
