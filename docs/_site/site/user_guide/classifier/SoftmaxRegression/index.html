<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A library consisting of useful tools and extensions for the day-to-day data science tasks."> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/">
    <link rel="shortcut icon" href="../../../img/favicon.ico">

    <title>Softmax Regression - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../cinder/css/base.css" rel="stylesheet">


    <link href="../../../cinder/css/bootstrap-custom.css" rel="stylesheet">


    <link href="../../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">


    <link href="../../../cinder/css/cinder.css" rel="stylesheet">


    <link href="../../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">


    <link href="../../../cinder/css/highlight.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../USER_GUIDE_INDEX/">User Guide Index</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../Adaline/">Adaptive Linear Neuron -- Adaline</a>
</li>

        
            
<li >
    <a href="../EnsembleVoteClassifier/">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../LogisticRegression/">Logistic Regression</a>
</li>

        
            
<li >
    <a href="../MultiLayerPerceptron/">Neural Network - Multilayer Perceptron</a>
</li>

        
            
<li >
    <a href="../Perceptron/">Perceptron</a>
</li>

        
            
<li class="active">
    <a href="./">Softmax Regression</a>
</li>

        
            
<li >
    <a href="../StackingClassifier/">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../StackingCVClassifier/">StackingCVClassifier</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">cluster</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../cluster/Kmeans/">Kmeans</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">Auto MPG</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">Boston Housing Data</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">Iris Dataset</a>
</li>

        
            
<li >
    <a href="../../data/loadlocal_mnist/">Load the MNIST Dataset from Local Files</a>
</li>

        
            
<li >
    <a href="../../data/make_multiplexer_dataset/">Make Multiplexer Dataset</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">MNIST Dataset</a>
</li>

        
            
<li >
    <a href="../../data/three_blobs_data/">Three Blobs Dataset</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">Wine Dataset</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/bootstrap/">Bootstrap</a>
</li>

        
            
<li >
    <a href="../../evaluate/bootstrap_point632_score/">bootstrap_point632_score</a>
</li>

        
            
<li >
    <a href="../../evaluate/BootstrapOutOfBag/">BootstrapOutOfBag</a>
</li>

        
            
<li >
    <a href="../../evaluate/cochrans_q/">Cochran's Q Test</a>
</li>

        
            
<li >
    <a href="../../evaluate/combined_ftest_5x2cv/">5x2cv combined *F* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/confusion_matrix/">Confusion Matrix</a>
</li>

        
            
<li >
    <a href="../../evaluate/feature_importance_permutation/">Feature Importance Permutation</a>
</li>

        
            
<li >
    <a href="../../evaluate/ftest/">F-Test</a>
</li>

        
            
<li >
    <a href="../../evaluate/lift_score/">Lift Score</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar_table/">Contigency Table for McNemar's Test</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar_tables/">Contigency Tables for McNemar's Test and Cochran's Q Test</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar/">McNemar's Test</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_5x2cv/">5x2cv paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_kfold_cv/">K-fold cross-validated paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_resampled/">Resampled paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/permutation_test/">Permutation Test</a>
</li>

        
            
<li >
    <a href="../../evaluate/PredefinedHoldoutSplit/">PredefinedHoldoutSplit</a>
</li>

        
            
<li >
    <a href="../../evaluate/RandomHoldoutSplit/">RandomHoldoutSplit</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_extraction</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_extraction/LinearDiscriminantAnalysis/">Linear Discriminant Analysis</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/PrincipalComponentAnalysis/">Principal Component Analysis</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/RBFKernelPCA/">RBFKernelPCA</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/ColumnSelector/">ColumnSelector</a>
</li>

        
            
<li >
    <a href="../../feature_selection/ExhaustiveFeatureSelector/">Exhaustive Feature Selector</a>
</li>

        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">Sequential Feature Selector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">Find Filegroups</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">Find Files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">frequent_patterns</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../frequent_patterns/apriori/">Apriori</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/association_rules/">Association rules</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_concepts/activation-functions/">Activation Functions for Artificial Neural Networks</a>
</li>

        
            
<li >
    <a href="../../general_concepts/gradient-optimization/">Gradient Descent and Stochastic Gradient Descent</a>
</li>

        
            
<li >
    <a href="../../general_concepts/linear-gradient-derivative/">Deriving the Gradient Descent Rule for Linear Regression and Adaline</a>
</li>

        
            
<li >
    <a href="../../general_concepts/regularization-linear/">Regularization of Generalized Linear Models</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">image</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../image/extract_face_landmarks/">Extract Face Landmarks</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">Compute the Number of Combinations</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">Compute the Number of Permutations</a>
</li>

        
            
<li >
    <a href="../../math/vectorspace_dimensionality/">Vectorspace Dimensionality</a>
</li>

        
            
<li >
    <a href="../../math/vectorspace_orthonormalization/">Vectorspace Orthonormalization</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../plotting/category_scatter/">Scatterplot with Categories</a>
</li>

        
            
<li >
    <a href="../../plotting/checkerboard_plot/">Checkerboard Plot</a>
</li>

        
            
<li >
    <a href="../../plotting/ecdf/">Empirical Cumulative Distribution Function Plot</a>
</li>

        
            
<li >
    <a href="../../plotting/enrichment_plot/">Enrichment Plot</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_confusion_matrix/">Confusion Matrix</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_decision_regions/">Plotting Decision Regions</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_learning_curves/">Plotting Learning Curves</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_linear_regression/">Linear Regression Plot</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_sequential_feature_selection/">Plot Sequential Feature Selection</a>
</li>

        
            
<li >
    <a href="../../plotting/scatterplotmatrix/">Scatter Plot Matrix</a>
</li>

        
            
<li >
    <a href="../../plotting/stacked_barplot/">Stacked Barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/CopyTransformer/">CopyTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">Mean Centerer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">MinMax Scaling</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">Shuffle Arrays in Unison</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">Standardize</a>
</li>

        
            
<li >
    <a href="../../preprocessing/TransactionEncoder/">TransactionEncoder</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingCVRegressor/">StackingCVRegressor</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">Generalize Names</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">Generalize Names & Duplicate Checking</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.cluster/">Mlxtend.cluster</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_extraction/">Mlxtend.feature extraction</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.frequent_patterns/">Mlxtend.frequent patterns</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.image/">Mlxtend.image</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.plotting/">Mlxtend.plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../CHANGELOG/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../CONTRIBUTING/">How To Contribute</a>
</li>

                        
                            
<li >
    <a href="../../../contributors/">Contributors</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                            
<li >
    <a href="../../../cite/">Citing Mlxtend</a>
</li>

                        
                            
<li >
    <a href="../../../discuss/">Discuss</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fa fa-search"></i> Search
                        </a>
                    </li>

                <!--
                    <li >
                        <a rel="next" href="../Perceptron/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../StackingClassifier/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>-->
                    <li>
                        <a href="https://github.com/rasbt/mlxtend"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#softmax-regression">Softmax Regression</a></li>
            <li class="second-level"><a href="#overview">Overview</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-1-gradient-descent">Example 1 - Gradient Descent</a></li>
                 <!-- 
                <li class="third-level"><a href="#predicting-class-labels">Predicting Class Labels</a></li>
                <li class="third-level"><a href="#predicting-class-probabilities">Predicting Class Probabilities</a></li>  -->
            <li class="second-level"><a href="#example-2-stochastic-gradient-descent">Example 2 - Stochastic Gradient Descent</a></li>
                 <!--   -->
        <li class="first-level "><a href="#api">API</a></li>
            <li class="second-level"><a href="#methods">Methods</a></li>
                 <!--   -->
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="softmax-regression">Softmax Regression</h1>
<p>A logistic regression class for multi-class classification tasks.</p>
<blockquote>
<p>from mlxtend.classifier import SoftmaxRegression</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p><em>Softmax Regression</em> (synonyms: <em>Multinomial Logistic</em>, <em>Maximum Entropy Classifier</em>, or just <em>Multi-class Logistic Regression</em>) is a generalization of logistic regression that we can use for multi-class classification (under the assumption that the classes are  mutually exclusive). In contrast, we use the (standard) <em>Logistic Regression</em> model in binary classification tasks.</p>
<p>Below is a schematic of a <em>Logistic Regression</em> model, for more details, please see the <a href="../LogisticRegression/"><code>LogisticRegression</code> manual</a>.</p>
<p><img alt="" src="../SoftmaxRegression_files/logistic_regression_schematic.png" /></p>
<p>In <em>Softmax Regression</em> (SMR), we replace the sigmoid logistic function by the so-called <em>softmax</em> function <script type="math/tex">\phi_{softmax}(\cdot)</script>.</p>
<p>
<script type="math/tex; mode=display">P(y=j \mid z^{(i)}) = \phi_{softmax}(z^{(i)}) = \frac{e^{z^{(i)}}}{\sum_{j=0}^{k} e^{z_{k}^{(i)}}},</script>
</p>
<p>where we define the net input <em>z</em> as </p>
<p>
<script type="math/tex; mode=display">z = w_1x_1 + ... + w_mx_m  + b= \sum_{l=1}^{m} w_l x_l + b= \mathbf{w}^T\mathbf{x} + b.</script>
</p>
<p>(<strong>w</strong> is the weight vector, <script type="math/tex">\mathbf{x}</script> is the feature vector of 1 training sample, and <script type="math/tex">b</script> is the bias unit.) <br />
Now, this softmax function computes the probability that this training sample <script type="math/tex">\mathbf{x}^{(i)}</script> belongs to class <script type="math/tex">j</script> given the weight and net input <script type="math/tex">z^{(i)}</script>. So, we compute the probability <script type="math/tex">p(y = j \mid \mathbf{x^{(i)}; w}_j)</script> for each class label in  <script type="math/tex">j = 1, \ldots, k.</script>. Note the normalization term in the denominator which causes these class probabilities to sum up to one.</p>
<p><img alt="" src="../SoftmaxRegression_files/softmax_schematic_1.png" /></p>
<p>To illustrate the concept of softmax, let us walk through a concrete example. Let's assume we have a training set consisting of 4 samples from 3 different classes (0, 1, and 2)</p>
<ul>
<li>
<script type="math/tex">x_0 \rightarrow \text{class }0</script>
</li>
<li>
<script type="math/tex">x_1 \rightarrow \text{class }1</script>
</li>
<li>
<script type="math/tex">x_2 \rightarrow \text{class }2</script>
</li>
<li>
<script type="math/tex">x_3 \rightarrow \text{class }2</script>
</li>
</ul>
<pre><code class="python">import numpy as np

y = np.array([0, 1, 2, 2])
</code></pre>

<p>First, we want to encode the class labels into a format that we can more easily work with; we apply one-hot encoding:</p>
<pre><code class="python">y_enc = (np.arange(np.max(y) + 1) == y[:, None]).astype(float)

print('one-hot encoding:\n', y_enc)
</code></pre>

<pre><code>one-hot encoding:
 [[ 1.  0.  0.]
 [ 0.  1.  0.]
 [ 0.  0.  1.]
 [ 0.  0.  1.]]
</code></pre>
<p>A sample that belongs to class 0 (the first row) has a 1 in the first cell, a sample that belongs to class 2 has a 1 in the second cell of its row, and so forth.</p>
<p>Next, let us define the feature matrix of our 4 training samples. Here, we assume that our dataset consists of 2 features; thus, we create a 4x2 dimensional matrix of our samples and features.
Similarly, we create a 2x3 dimensional weight matrix (one row per feature and one column for each class).</p>
<pre><code class="python">X = np.array([[0.1, 0.5],
              [1.1, 2.3],
              [-1.1, -2.3],
              [-1.5, -2.5]])

W = np.array([[0.1, 0.2, 0.3],
              [0.1, 0.2, 0.3]])

bias = np.array([0.01, 0.1, 0.1])

print('Inputs X:\n', X)
print('\nWeights W:\n', W)
print('\nbias:\n', bias)
</code></pre>

<pre><code>Inputs X:
 [[ 0.1  0.5]
 [ 1.1  2.3]
 [-1.1 -2.3]
 [-1.5 -2.5]]

Weights W:
 [[ 0.1  0.2  0.3]
 [ 0.1  0.2  0.3]]

bias:
 [ 0.01  0.1   0.1 ]
</code></pre>
<p>To compute the net input, we multiply the 4x2 matrix feature matrix <code>X</code> with the 2x3 (n_features x n_classes) weight matrix <code>W</code>, which yields a 4x3 output matrix (n_samples x n_classes) to which we then add the bias unit: </p>
<p>
<script type="math/tex; mode=display">\mathbf{Z} = \mathbf{X}\mathbf{W} + \mathbf{b}.</script>
</p>
<pre><code class="python">X = np.array([[0.1, 0.5],
              [1.1, 2.3],
              [-1.1, -2.3],
              [-1.5, -2.5]])

W = np.array([[0.1, 0.2, 0.3],
              [0.1, 0.2, 0.3]])

bias = np.array([0.01, 0.1, 0.1])

print('Inputs X:\n', X)
print('\nWeights W:\n', W)
print('\nbias:\n', bias)
</code></pre>

<pre><code>Inputs X:
 [[ 0.1  0.5]
 [ 1.1  2.3]
 [-1.1 -2.3]
 [-1.5 -2.5]]

Weights W:
 [[ 0.1  0.2  0.3]
 [ 0.1  0.2  0.3]]

bias:
 [ 0.01  0.1   0.1 ]
</code></pre>
<pre><code class="python">def net_input(X, W, b):
    return (X.dot(W) + b)

net_in = net_input(X, W, bias)
print('net input:\n', net_in)
</code></pre>

<pre><code>net input:
 [[ 0.07  0.22  0.28]
 [ 0.35  0.78  1.12]
 [-0.33 -0.58 -0.92]
 [-0.39 -0.7  -1.1 ]]
</code></pre>
<p>Now, it's time to compute the softmax activation that we discussed earlier:</p>
<p>
<script type="math/tex; mode=display">P(y=j \mid z^{(i)}) = \phi_{softmax}(z^{(i)}) = \frac{e^{z^{(i)}}}{\sum_{j=0}^{k} e^{z_{k}^{(i)}}}.</script>
</p>
<pre><code class="python">def softmax(z):
    return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T

smax = softmax(net_in)
print('softmax:\n', smax)
</code></pre>

<pre><code>softmax:
 [[ 0.29450637  0.34216758  0.36332605]
 [ 0.21290077  0.32728332  0.45981591]
 [ 0.42860913  0.33380113  0.23758974]
 [ 0.44941979  0.32962558  0.22095463]]
</code></pre>
<p>As we can see, the values for each sample (row) nicely sum up to 1 now. E.g., we can say that the first sample <br />
<code>[ 0.29450637  0.34216758  0.36332605]</code> has a 29.45% probability to belong to class 0.</p>
<p>Now, in order to turn these probabilities back into class labels, we could simply take the argmax-index position of each row:</p>
<p>[[ 0.29450637  0.34216758  <strong>0.36332605</strong>] -&gt; 2 <br />
[ 0.21290077  0.32728332  <strong>0.45981591</strong>]  -&gt; 2<br />
[ <strong>0.42860913</strong>  0.33380113  0.23758974]  -&gt; 0<br />
[ <strong>0.44941979</strong>  0.32962558  0.22095463]] -&gt; 0  </p>
<pre><code class="python">def to_classlabel(z):
    return z.argmax(axis=1)

print('predicted class labels: ', to_classlabel(smax))
</code></pre>

<pre><code>predicted class labels:  [2 2 0 0]
</code></pre>
<p>As we can see, our predictions are terribly wrong, since the correct class labels are <code>[0, 1, 2, 2]</code>. Now, in order to train our logistic model (e.g., via an optimization algorithm such as gradient descent), we need to define a cost function <script type="math/tex">J(\cdot)</script> that we want to minimize:</p>
<p>
<script type="math/tex; mode=display">J(\mathbf{W}; \mathbf{b}) = \frac{1}{n} \sum_{i=1}^{n} H(T_i, O_i),</script>
</p>
<p>which is the average of all cross-entropies over our <script type="math/tex">n</script> training samples. The cross-entropy  function is defined as</p>
<p>
<script type="math/tex; mode=display">H(T_i, O_i) = -\sum_m T_i \cdot log(O_i).</script>
</p>
<p>Here the <script type="math/tex">T</script> stands for "target" (i.e., the <em>true</em> class labels) and the <script type="math/tex">O</script> stands for output -- the computed <em>probability</em> via softmax; <strong>not</strong> the predicted class label.</p>
<pre><code class="python">def cross_entropy(output, y_target):
    return - np.sum(np.log(output) * (y_target), axis=1)

xent = cross_entropy(smax, y_enc)
print('Cross Entropy:', xent)
</code></pre>

<pre><code>Cross Entropy: [ 1.22245465  1.11692907  1.43720989  1.50979788]
</code></pre>
<pre><code class="python">def cost(output, y_target):
    return np.mean(cross_entropy(output, y_target))

J_cost = cost(smax, y_enc)
print('Cost: ', J_cost)
</code></pre>

<pre><code>Cost:  1.32159787159
</code></pre>
<p>In order to learn our softmax model -- determining the weight coefficients -- via gradient descent, we then need to compute the derivative </p>
<p>
<script type="math/tex; mode=display">\nabla \mathbf{w}_j \, J(\mathbf{W}; \mathbf{b}).</script>
</p>
<p>I don't want to walk through the tedious details here, but this cost derivative turns out to be simply:</p>
<p>
<script type="math/tex; mode=display">\nabla \mathbf{w}_j \, J(\mathbf{W}; \mathbf{b}) = \frac{1}{n} \sum^{n}_{i=0} \big[\mathbf{x}^{(i)}\ \big(O_i - T_i \big) \big]</script>
</p>
<p>We can then use the cost derivate to update the weights in opposite direction of the cost gradient with learning rate <script type="math/tex">\eta</script>:</p>
<p>
<script type="math/tex; mode=display">\mathbf{w}_j := \mathbf{w}_j - \eta \nabla \mathbf{w}_j \, J(\mathbf{W}; \mathbf{b})</script>
</p>
<p>for each class <script type="math/tex; mode=display">j \in \{0, 1, ..., k\}</script>
</p>
<p>(note that <script type="math/tex">\mathbf{w}_j</script> is the weight vector for the class <script type="math/tex">y=j</script>), and we update the bias units</p>
<p>
<script type="math/tex; mode=display">\mathbf{b}_j := \mathbf{b}_j   - \eta \bigg[ \frac{1}{n} \sum^{n}_{i=0} \big(O_i - T_i  \big) \bigg].</script>
</p>
<p>As a penalty against complexity, an approach to reduce the variance of our model and decrease the degree of overfitting by adding additional bias, we can further add a regularization term such as the L2 term with the regularization parameter <script type="math/tex">\lambda</script>:</p>
<p>L2:        <script type="math/tex">\frac{\lambda}{2} ||\mathbf{w}||_{2}^{2}</script>, </p>
<p>where </p>
<p>
<script type="math/tex; mode=display">||\mathbf{w}||_{2}^{2} = \sum^{m}_{l=0} \sum^{k}_{j=0} w_{i, j}</script>
</p>
<p>so that our cost function becomes</p>
<p>
<script type="math/tex; mode=display">J(\mathbf{W}; \mathbf{b}) = \frac{1}{n} \sum_{i=1}^{n} H(T_i, O_i) + \frac{\lambda}{2} ||\mathbf{w}||_{2}^{2}</script>
</p>
<p>and we define the "regularized" weight update as</p>
<p>
<script type="math/tex; mode=display">\mathbf{w}_j := \mathbf{w}_j -  \eta \big[\nabla \mathbf{w}_j \, J(\mathbf{W}) + \lambda \mathbf{w}_j \big].</script>
</p>
<p>(Please note that we don't regularize the bias term.)</p>
<h2 id="example-1-gradient-descent">Example 1 - Gradient Descent</h2>
<pre><code class="python">from mlxtend.data import iris_data
from mlxtend.plotting import plot_decision_regions
from mlxtend.classifier import SoftmaxRegression
import matplotlib.pyplot as plt

# Loading Data

X, y = iris_data()
X = X[:, [0, 3]] # sepal length and petal width

# standardize
X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()

lr = SoftmaxRegression(eta=0.01, 
                       epochs=500, 
                       minibatches=1, 
                       random_seed=1,
                       print_progress=3)
lr.fit(X, y)

plot_decision_regions(X, y, clf=lr)
plt.title('Softmax Regression - Gradient Descent')
plt.show()

plt.plot(range(len(lr.cost_)), lr.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<pre><code>Iteration: 500/500 | Cost 0.06 | Elapsed: 0:00:00 | ETA: 0:00:00
</code></pre>
<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_31_1.png" /></p>
<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_31_2.png" /></p>
<h4 id="predicting-class-labels">Predicting Class Labels</h4>
<pre><code class="python">y_pred = lr.predict(X)
print('Last 3 Class Labels: %s' % y_pred[-3:])
</code></pre>

<pre><code>Last 3 Class Labels: [2 2 2]
</code></pre>
<h4 id="predicting-class-probabilities">Predicting Class Probabilities</h4>
<pre><code class="python">y_pred = lr.predict_proba(X)
print('Last 3 Class Labels:\n %s' % y_pred[-3:])
</code></pre>

<pre><code>Last 3 Class Labels:
 [[  9.18728149e-09   1.68894679e-02   9.83110523e-01]
 [  2.97052325e-11   7.26356627e-04   9.99273643e-01]
 [  1.57464093e-06   1.57779528e-01   8.42218897e-01]]
</code></pre>
<h2 id="example-2-stochastic-gradient-descent">Example 2 - Stochastic Gradient Descent</h2>
<pre><code class="python">from mlxtend.data import iris_data
from mlxtend.plotting import plot_decision_regions
from mlxtend.classifier import SoftmaxRegression
import matplotlib.pyplot as plt

# Loading Data

X, y = iris_data()
X = X[:, [0, 3]] # sepal length and petal width

# standardize
X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()

lr = SoftmaxRegression(eta=0.01, epochs=300, minibatches=len(y), random_seed=1)
lr.fit(X, y)

plot_decision_regions(X, y, clf=lr)
plt.title('Softmax Regression - Stochastic Gradient Descent')
plt.show()

plt.plot(range(len(lr.cost_)), lr.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_37_0.png" /></p>
<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_37_1.png" /></p>
<h1 id="api">API</h1>
<p><em>SoftmaxRegression(eta=0.01, epochs=50, l2=0.0, minibatches=1, n_classes=None, random_seed=None, print_progress=0)</em></p>
<p>Softmax regression classifier.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>eta</code> : float (default: 0.01)</p>
<p>Learning rate (between 0.0 and 1.0)</p>
</li>
<li>
<p><code>epochs</code> : int (default: 50)</p>
<p>Passes over the training dataset.
Prior to each epoch, the dataset is shuffled
if <code>minibatches &gt; 1</code> to prevent cycles in stochastic gradient descent.</p>
</li>
<li>
<p><code>l2</code> : float</p>
<p>Regularization parameter for L2 regularization.
No regularization if l2=0.0.</p>
</li>
<li>
<p><code>minibatches</code> : int (default: 1)</p>
<p>The number of minibatches for gradient-based optimization.
If 1: Gradient Descent learning
If len(y): Stochastic Gradient Descent (SGD) online learning
If 1 &lt; minibatches &lt; len(y): SGD Minibatch learning</p>
</li>
<li>
<p><code>n_classes</code> : int (default: None)</p>
<p>A positive integer to declare the number of class labels
if not all class labels are present in a partial training set.
Gets the number of class labels automatically if None.</p>
</li>
<li>
<p><code>random_seed</code> : int (default: None)</p>
<p>Set random state for shuffling and initializing the weights.</p>
</li>
<li>
<p><code>print_progress</code> : int (default: 0)</p>
<p>Prints progress in fitting to stderr.
0: No output
1: Epochs elapsed and cost
2: 1 plus time elapsed
3: 2 plus estimated time until completion</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>w_</code> : 2d-array, shape={n_features, 1}</p>
<p>Model weights after fitting.</p>
</li>
<li>
<p><code>b_</code> : 1d-array, shape={1,}</p>
<p>Bias unit after fitting.</p>
</li>
<li>
<p><code>cost_</code> : list</p>
<p>List of floats, the average cross_entropy for each epoch.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/">http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/</a></p>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y, init_params=True)</em></p>
<p>Learn model from training data.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>init_params</code> : bool (default: True)</p>
<p>Re-initializes model parameters prior to fitting.
Set False to continue training with weights from
a previous model fitting.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>predict(X)</em></p>
<p>Predict targets from X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>target_values</code> : array-like, shape = [n_samples]</p>
<p>Predicted target values.</p>
</li>
</ul>
<hr>

<p><em>predict_proba(X)</em></p>
<p>Predict class probabilities of X from the net input.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>Class probabilties</code> : array-like, shape= [n_samples, n_classes]</li>
</ul>
<hr>

<p><em>score(X, y)</em></p>
<p>Compute the prediction accuracy</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values (true class labels).</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>acc</code> : float</p>
<p>The prediction accuracy as a float
between 0.0 and 1.0 (perfect score).</p>
</li>
</ul></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2019 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>
    <script src="../../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
