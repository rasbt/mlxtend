{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Multiplexer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that creates a dataset generated by a n-bit Boolean multiplexer for evaluating supervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `from mlxtend.data import make_multiplexer_dataset`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_multiplexer_dataset` function creates a dataset generated by an n-bit Boolean multiplexer. Such dataset represents a dataset generated by a simple rule, based on the behavior of a electric multiplexer, yet presents a relatively challenging classification problem for supervised learning algorithm with interactions between features (epistasis) as it may be encountered in many real-world scenarios [1].\n",
    "\n",
    "The following illustration depicts a 6-bit multiplexer that consists of 2 address bits and 4 register bits. The address bits converted to decimal representation point to a position in the register bit. For example, if the address bits are \"00\" (0 in decimal), the address bits point to the register bit at position 0. The value of the register position pointed to determines the class label. For example, if the register bit at position is 0, the class label is 0. Vice versa, if the register bit at position 0 is 1, the class label is 1. \n",
    "\n",
    "\n",
    "In the example above, the address bits \"10\" (2 in decimal) point to the 3rd register position (as we start counting from index 0), which has a bit value of 1. Hence, the class label is 1.\n",
    "\n",
    "Below are a few more examples:\n",
    "\n",
    "1. Address bits: [0, 1], register bits: [1, 0, 1, 1], class label: 0\n",
    "2. Address bits: [0, 1], register bits: [1, 1, 1, 0], class label: 1\n",
    "3. Address bits: [1, 0], register bits: [1, 0, 0, 1], class label: 0\n",
    "4. Address bits: [1, 1], register bits: [1, 1, 1, 0], class label: 0\n",
    "5. Address bits: [0, 1], register bits: [0, 1, 1, 0], class label: 1\n",
    "6. Address bits: [0, 1], register bits: [1, 0, 0, 1], class label: 0\n",
    "7. Address bits: [0, 1], register bits: [0, 1, 1, 1], class label: 1\n",
    "8. Address bits: [0, 1], register bits: [0, 0, 0, 0], class label: 0\n",
    "9. Address bits: [1, 0], register bits: [1, 0, 1, 1], class label: 1\n",
    "10. Address bits: [0, 1], register bits: [1, 1, 1, 1], class label: 1\n",
    "\n",
    "Note that in the implementation of the multiplexer function, if the number of address bits is set to 2, this results in a 6 bit multiplexer as two bit can have 2^2=4 different register positions (2 bit + 4 bit = 6 bit). However, if we choose 3 address bits instead, 2^3=8 positions would be covered, resulting in a 11 bit (3 bit + 8 bit = 11 bit) multiplexer, and so forth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [1]  Urbanowicz, R. J., & Browne, W. N. (2017). *Introduction to Learning Classifier Systems*. Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 -- Bootstrapping the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple example illustrates how you could bootstrap the mean of a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 5.03, SE: +/- 0.11, CI95: [4.80, 5.26]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import bootstrap\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(123)\n",
    "x = rng.normal(loc=5., size=100)\n",
    "original, std_err, ci_bounds = bootstrap(x, num_rounds=1000, func=np.mean, ci=0.95, seed=123)\n",
    "print('Mean: %.2f, SE: +/- %.2f, CI95: [%.2f, %.2f]' % (original, \n",
    "                                                             std_err, \n",
    "                                                             ci_bounds[0],\n",
    "                                                             ci_bounds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - Bootstrapping a Regression Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates how you can bootstrap the $R^2$ of a regression fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.90, SE: +/- 0.01, CI95: [0.89, 0.92]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.data import autompg_data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X, y = autompg_data()\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "def r2_fit(X, model=lr):\n",
    "    x, y = X[:, 0].reshape(-1, 1), X[:, 1]\n",
    "    pred = lr.fit(x, y).predict(x)\n",
    "    return r2_score(y, pred)\n",
    "    \n",
    "    \n",
    "original, std_err, ci_bounds = bootstrap(X, num_rounds=1000,\n",
    "                                         func=r2_fit,\n",
    "                                         ci=0.95,\n",
    "                                         seed=123)\n",
    "print('Mean: %.2f, SE: +/- %.2f, CI95: [%.2f, %.2f]' % (original, \n",
    "                                                             std_err, \n",
    "                                                             ci_bounds[0],\n",
    "                                                             ci_bounds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## bootstrap\n",
      "\n",
      "*bootstrap(x, func, num_rounds=1000, ci=0.95, ddof=1, seed=None)*\n",
      "\n",
      "Implements the ordinary nonparametric bootstrap\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "\n",
      "- `x` : NumPy array, shape=(n_samples, [n_columns])\n",
      "\n",
      "    An one or multidimensional array of data records\n",
      "\n",
      "\n",
      "- `func` : <func>\n",
      "\n",
      "    A function which computes a statistic that is used\n",
      "    to compute the bootstrap replicates (the statistic computed\n",
      "    from the bootstrap samples). This function must return a\n",
      "    scalar value. For example, `np.mean` or `np.median` would be\n",
      "    an acceptable argument for `func` if `x` is a 1-dimensional array\n",
      "    or vector.\n",
      "\n",
      "\n",
      "- `num_rounds` : int (default=1000)\n",
      "\n",
      "    The number of bootstrap samnples to draw where each\n",
      "    bootstrap sample has the same number of records as the\n",
      "    original dataset.\n",
      "\n",
      "\n",
      "- `ci` : int (default=0.95)\n",
      "\n",
      "    An integer in the range (0, 1) that represents the\n",
      "    confidence level for computing the confidence interval.\n",
      "    For example, `ci=0.95` (default)\n",
      "    will compute the 95% confidence\n",
      "    interval from the bootstrap replicates.\n",
      "\n",
      "\n",
      "- `ddof` : int\n",
      "\n",
      "    The delta degrees of freedom used when computing the\n",
      "    standard error.\n",
      "\n",
      "\n",
      "- `seed` : int or None (default=None)\n",
      "\n",
      "    Random seed for generating bootstrap samples.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "    original, standard_error, (lower_ci, upper_ci)\n",
      "    Returns the statistic of the original sample (`original`),\n",
      "    the standard error of the estimate, and the\n",
      "    respective confidence interval bounds.\n",
      "\n",
      "**Examples**\n",
      "\n",
      "    >>> from mlxtend.evaluate import bootstrap\n",
      "    >>> rng = np.random.RandomState(123)\n",
      "    >>> x = rng.normal(loc=5., size=100)\n",
      "    >>> original, std_err, ci_bounds = bootstrap(x,\n",
      "    ...                                          num_rounds=1000,\n",
      "    ...                                          func=np.mean,\n",
      "    ...                                          ci=0.95,\n",
      "    ...                                          seed=123)\n",
      "    >>> print('Mean: %.2f, SE: +/- %.2f, CI95: [%.2f, %.2f]' % (original,\n",
      "    ...                                                         std_err,\n",
      "    ...                                                         ci_bounds[0],\n",
      "    ...                                                         ci_bounds[1]))\n",
      "    Mean: 5.03, SE: +/- 0.11, CI95: [4.80, 5.26]\n",
      "    >>>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../api_modules/mlxtend.evaluate/bootstrap.md', 'r') as f:\n",
    "    s = f.read() \n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
