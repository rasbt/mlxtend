{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemar's Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McNemar's test for paired nominal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `from mlxtend.evaluate import mcnemar`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McNemar's Test [1] (sometimes also called \"within-subjects chi-squared test\") is a statistical test for paired nominal data. In context of machine learning (or statistical) models, we can use McNemar's Test to compare the predictive accuracy of two models. McNemar's test is based on a 2 times 2 contigency table of the two model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  McNemar's Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In McNemar's Test, we formulate the null hypothesis that the probabilities $p(b)$ and $p(c)$ are the same, or in simplified terms: None of the two models performs better than the other. Thus, the alternative hypothesis is that the performances of the two models are not equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./mcnemar_table_files/mcnemar_contingency_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The McNemar test statistic (\"chi-squared\") can be computed as follows:\n",
    "\n",
    "$$\\chi^2 = \\frac{(b - c)^2}{(b + c)},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the sum of cell c and b is sufficiently large, the $\\chi^2$ value follows a chi-squared distribution with one degree of freedom. After setting a significance threshold, e.g,. $\\alpha=0.05$ we can compute the p-value -- assuming that the null hypothesis is true, the p-value is the probability of observing this empirical (or a larger) chi-squared value. If the p-value is lower than our chosen significance level, we can reject the null hypothesis that the two model's performances are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuity Correction\n",
    "\n",
    "Approximately 1 year after Quinn McNemar published the McNemar Test [1], Edwards [2] proposed a continuity corrected version, which is the more commonly used variant today:\n",
    "\n",
    "$$\\chi^2 = \\frac{( \\mid b - c \\mid - 1)^2}{(b + c)}.$$\n",
    "\n",
    "### Exact p-values\n",
    "\n",
    "As mentioned earlier, an exact binomial test is recommended for small sample sizes ($b + c < 25$ [3]), since the chi-squared value is may not be well-approximated by the chi-squared distribution. The exact p-value can be computed as follows:\n",
    "\n",
    "$$p = 2 \\sum^{n}_{i=b} \\binom{n}{i} 0.5^i (1 - 0.5)^{n-i},$$\n",
    "\n",
    "where $n = b + c$, and the factor $2$ is used to compute the two-sided p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, given that 2 models have a accuracy of with a 99.7% and 99.6% a 2x2 contigency table can provide further insights for model selection.\n",
    "\n",
    "\n",
    "![](./mcnemar_table_files/mcnemar_contingency_table_ex1.png)\n",
    "\n",
    "In both subfigure A and B, the predictive accuracies of the two models are as follows:\n",
    "\n",
    "- model 1 accuracy: 9,960 / 10,000 = 99.6%\n",
    "- model 2 accuracy: 9,970 / 10,000 = 99.7%\n",
    "\n",
    "Now, in subfigure A, we can see that model 2 got 11 predictions right that model 1 got wrong. Vice versa, model 2 got 1 prediction right that model 2 got wrong. Thus, based on this 11:1 ratio, we may conclude that model 2 performs substantially better than model 1. However, in subfigure B, the ratio is 25:15, which is less conclusive about which model is the better one to choose.\n",
    "\n",
    "In the following coding examples, we will use these 2 scenarios A and B to illustrate McNemar's test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [1] McNemar, Quinn, 1947. \"[Note on the sampling error of the difference between correlated proportions or percentages](http://link.springer.com/article/10.1007%2FBF02295996)\". Psychometrika. 12 (2): 153–157.\n",
    "- [2] Edwards AL: Note on the “correction for continuity” in testing the significance of the difference between correlated proportions. Psychometrika. 1948, 13 (3): 185-187. 10.1007/BF02289261.\n",
    "- [3] https://en.wikipedia.org/wiki/McNemar%27s_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - Creating 2x2 Contigency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mcnemar` funtion expects a 2x2 contingency table as a NumPy array that is formatted as follows:\n",
    "    \n",
    "![](./mcnemar_table_files/mcnemar_contingency_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a contigency matrix can be created by using the `mcnemar_table` function from `mlxtend.evaluate`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "\n",
    "# The correct target (class) labels\n",
    "y_target = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Class labels predicted by model 1\n",
    "y_model1 = np.array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
    "\n",
    "# Class labels predicted by model 2\n",
    "y_model2 = np.array([0, 0, 1, 1, 0, 1, 1, 0, 0, 0])\n",
    "\n",
    "tb = mcnemar_table(y_target=y_target, \n",
    "                   y_model1=y_model1, \n",
    "                   y_model2=y_model2)\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - McNemar's Test for Scenario B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, let us continue with the example mentioned in the overview section and assume that we already computed the 2x2 contigency table:\n",
    "\n",
    "![](./mcnemar_files/mcnemar_scenario_b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tb_b = np.array([[9945, 25],\n",
    "                 [15, 15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the null hypothesis that the predictive performance of two models are equal (using a significance level of $\\alpha=0.05$), we can conduct a corrected McNemar Test for computing the chi-squared and p-value as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared: 2.025\n",
      "p-value: 0.154728923485\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2, p = mcnemar(ary=tb_b, corrected=True)\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is larger than our assumed significance threshold ($\\alpha=0.05$), we cannot reject our null hypothesis and assume that there is no significant difference between the two predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 - McNemar's Test for Scenario A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to scenario B (Example 2), the sample size in scenario A is relatively small (b + c = 11  + 1 = 12) and smaller than the recommended 25 [3] to approximate the computed chi-square value by the chi-square distribution well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./mcnemar_files/mcnemar_scenario_a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we need to compute the exact p-value from the binomial distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared: None\n",
      "p-value: 0.005859375\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "import numpy as np\n",
    "\n",
    "tb_a = np.array([[9959, 11],\n",
    "                 [1, 29]])\n",
    "\n",
    "chi2, p = mcnemar(ary=tb_a, exact=True)\n",
    "\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that we conducted this test also with a significance level of $\\alpha=0.05$, we can reject the null-hypothesis that both models perform equally well on this dataset, since the p-value ($p \\approx 0.006$) is smaller than $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## mcnemar\n",
      "\n",
      "*mcnemar(ary, corrected=True, exact=False)*\n",
      "\n",
      "McNemar test for paired nominal data\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `ary` : array-like, shape=[2, 2]\n",
      "\n",
      "    2 x 2 contigency table (as returned by evaluate.mcnemar_table),\n",
      "    where\n",
      "    a: ary[0, 0]: # of samples that both models predicted correctly\n",
      "    b: ary[0, 1]: # of samples that model 1 got right and model 2 got wrong\n",
      "    c: ary[1, 0]: # of samples that model 2 got right and model 1 got wrong\n",
      "    d: aryCell [1, 1]: # of samples that both models predicted incorrectly\n",
      "\n",
      "- `corrected` : array-like, shape=[n_samples] (default: True)\n",
      "\n",
      "    Uses Edward's continuity correction for chi-squared if `True`\n",
      "\n",
      "- `exact` : bool, (default: False)\n",
      "\n",
      "    If `True`, uses an exact binomial test comparing b to\n",
      "    a binomial distribution with n = b + c and p = 0.5.\n",
      "    It is highly recommended to use `exact=True` for sample sizes < 25\n",
      "    since chi-squared is not well-approximated\n",
      "    by the chi-squared distribution!\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `chi2, p` : float or None, float\n",
      "\n",
      "    Returns the chi-squared value and the p-value;\n",
      "    if `exact=True` (default: `False`), `chi2` is `None`\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../api_modules/mlxtend.evaluate/mcnemar.md', 'r') as f:\n",
    "    s = f.read() \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
