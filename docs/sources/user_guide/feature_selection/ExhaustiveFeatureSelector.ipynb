{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebastian Raschka, 2015-2022  \n",
    "`mlxtend`, a library of extension and helper modules for Python's data analysis and machine learning libraries\n",
    "\n",
    "- GitHub repository: https://github.com/rasbt/mlxtend\n",
    "- Documentation: https://rasbt.github.io/mlxtend/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Last updated: 2022-09-13\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.7\n",
      "IPython version      : 8.0.1\n",
      "\n",
      "matplotlib: 3.5.2\n",
      "numpy     : 1.22.1\n",
      "scipy     : 1.9.1\n",
      "mlxtend   : 0.21.0.dev0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -u -d -v -p matplotlib,numpy,scipy,mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExhaustiveFeatureSelector: Optimal feature sets by considering all possible feature combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of an *exhaustive feature selector* for sampling and evaluating all possible feature combinations in a specified range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> from mlxtend.feature_selection import ExhaustiveFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exhaustive feature selection algorithm is a wrapper approach for brute-force evaluation of feature subsets; the best subset is selected by optimizing a specified performance metric given an arbitrary regressor or classifier. For instance, if the classifier is a logistic regression and the dataset consists of 4 features, the alogorithm will evaluate all 15 feature combinations (if `min_features=1` and `max_features=4`)\n",
    "\n",
    "- {0}\n",
    "- {1}\n",
    "- {2}\n",
    "- {3}\n",
    "- {0, 1}\n",
    "- {0, 2}\n",
    "- {0, 3}\n",
    "- {1, 2}\n",
    "- {1, 3}\n",
    "- {2, 3}\n",
    "- {0, 1, 2}\n",
    "- {0, 1, 3}\n",
    "- {0, 2, 3}\n",
    "- {1, 2, 3}\n",
    "- {0, 1, 2, 3}\n",
    "\n",
    "and select the one that results in the best performance (e.g., classification accuracy) of the logistic regression classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - A simple Iris example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a simple classifier from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.97\n",
      "Best subset (indices): (0, 2, 3)\n",
      "Best subset (corresponding names): ('0', '2', '3')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "efs1 = EFS(knn, \n",
    "           min_features=1,\n",
    "           max_features=4,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=5)\n",
    "\n",
    "efs1 = efs1.fit(X, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with large datasets, the feature indices might be hard to interpret. In this case, we recommend using pandas DataFrames with distinct column names as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length</th>\n",
       "      <th>Sepal width</th>\n",
       "      <th>Petal length</th>\n",
       "      <th>Petal width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal length  Sepal width  Petal length  Petal width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_X = pd.DataFrame(X, columns=[\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\"])\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.97\n",
      "Best subset (indices): (0, 2, 3)\n",
      "Best subset (corresponding names): ('Sepal length', 'Petal length', 'Petal width')\n"
     ]
    }
   ],
   "source": [
    "efs1 = efs1.fit(df_X, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via the `subsets_` attribute, we can take a look at the selected feature indices at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'feature_idx': (0,),\n",
       "  'cv_scores': array([0.53333333, 0.63333333, 0.7       , 0.8       , 0.56666667]),\n",
       "  'avg_score': 0.6466666666666667,\n",
       "  'feature_names': ('Sepal length',)},\n",
       " 1: {'feature_idx': (1,),\n",
       "  'cv_scores': array([0.43333333, 0.63333333, 0.53333333, 0.43333333, 0.5       ]),\n",
       "  'avg_score': 0.5066666666666666,\n",
       "  'feature_names': ('Sepal width',)},\n",
       " 2: {'feature_idx': (2,),\n",
       "  'cv_scores': array([0.93333333, 0.93333333, 0.9       , 0.93333333, 1.        ]),\n",
       "  'avg_score': 0.9400000000000001,\n",
       "  'feature_names': ('Petal length',)},\n",
       " 3: {'feature_idx': (3,),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ]),\n",
       "  'avg_score': 0.96,\n",
       "  'feature_names': ('Petal width',)},\n",
       " 4: {'feature_idx': (0, 1),\n",
       "  'cv_scores': array([0.66666667, 0.8       , 0.7       , 0.86666667, 0.66666667]),\n",
       "  'avg_score': 0.74,\n",
       "  'feature_names': ('Sepal length', 'Sepal width')},\n",
       " 5: {'feature_idx': (0, 2),\n",
       "  'cv_scores': array([0.96666667, 1.        , 0.86666667, 0.93333333, 0.96666667]),\n",
       "  'avg_score': 0.9466666666666667,\n",
       "  'feature_names': ('Sepal length', 'Petal length')},\n",
       " 6: {'feature_idx': (0, 3),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.9       , 0.93333333, 1.        ]),\n",
       "  'avg_score': 0.9533333333333334,\n",
       "  'feature_names': ('Sepal length', 'Petal width')},\n",
       " 7: {'feature_idx': (1, 2),\n",
       "  'cv_scores': array([0.93333333, 0.93333333, 0.9       , 0.93333333, 0.93333333]),\n",
       "  'avg_score': 0.9266666666666667,\n",
       "  'feature_names': ('Sepal width', 'Petal length')},\n",
       " 8: {'feature_idx': (1, 3),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.86666667, 0.93333333, 0.96666667]),\n",
       "  'avg_score': 0.9400000000000001,\n",
       "  'feature_names': ('Sepal width', 'Petal width')},\n",
       " 9: {'feature_idx': (2, 3),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.9       , 0.93333333, 1.        ]),\n",
       "  'avg_score': 0.9533333333333334,\n",
       "  'feature_names': ('Petal length', 'Petal width')},\n",
       " 10: {'feature_idx': (0, 1, 2),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.86666667, 0.93333333, 0.96666667]),\n",
       "  'avg_score': 0.9400000000000001,\n",
       "  'feature_names': ('Sepal length', 'Sepal width', 'Petal length')},\n",
       " 11: {'feature_idx': (0, 1, 3),\n",
       "  'cv_scores': array([0.93333333, 0.96666667, 0.9       , 0.93333333, 1.        ]),\n",
       "  'avg_score': 0.9466666666666667,\n",
       "  'feature_names': ('Sepal length', 'Sepal width', 'Petal width')},\n",
       " 12: {'feature_idx': (0, 2, 3),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 1.        ]),\n",
       "  'avg_score': 0.9733333333333334,\n",
       "  'feature_names': ('Sepal length', 'Petal length', 'Petal width')},\n",
       " 13: {'feature_idx': (1, 2, 3),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ]),\n",
       "  'avg_score': 0.96,\n",
       "  'feature_names': ('Sepal width', 'Petal length', 'Petal width')},\n",
       " 14: {'feature_idx': (0, 1, 2, 3),\n",
       "  'cv_scores': array([0.96666667, 0.96666667, 0.93333333, 0.96666667, 1.        ]),\n",
       "  'avg_score': 0.9666666666666668,\n",
       "  'feature_names': ('Sepal length',\n",
       "   'Sepal width',\n",
       "   'Petal length',\n",
       "   'Petal width')}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs1.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - Visualizing the feature selection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For our convenience, we can visualize the output from the feature selection in a pandas DataFrame format using the `get_metric_dict` method of the `ExhaustiveFeatureSelector` object. The columns `std_dev` and `std_err` represent the standard deviation and standard errors of the cross-validation scores, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we see the DataFrame of the Sequential Forward Selector from Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0, 2, 3)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.966...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>(Sepal length, Petal length, Petal width)</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0, 1, 2, 3)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.933...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>(Sepal length, Sepal width, Petal length, Peta...</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.010541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3,)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.933...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>(Petal width,)</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>0.012472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.933...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>(Sepal width, Petal length, Petal width)</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>0.012472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.9, ...</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>(Sepal length, Petal width)</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.016997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.9, ...</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>(Petal length, Petal width)</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.016997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>[0.9666666666666667, 1.0, 0.8666666666666667, ...</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>(Sepal length, Petal length)</td>\n",
       "      <td>0.058115</td>\n",
       "      <td>0.045216</td>\n",
       "      <td>0.022608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0, 1, 3)</td>\n",
       "      <td>[0.9333333333333333, 0.9666666666666667, 0.9, ...</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>(Sepal length, Sepal width, Petal width)</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.016997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2,)</td>\n",
       "      <td>[0.9333333333333333, 0.9333333333333333, 0.9, ...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>(Petal length,)</td>\n",
       "      <td>0.041977</td>\n",
       "      <td>0.03266</td>\n",
       "      <td>0.01633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.866...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>(Sepal width, Petal width)</td>\n",
       "      <td>0.049963</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>0.019437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>[0.9666666666666667, 0.9666666666666667, 0.866...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>(Sepal length, Sepal width, Petal length)</td>\n",
       "      <td>0.049963</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>0.019437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>[0.9333333333333333, 0.9333333333333333, 0.9, ...</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>(Sepal width, Petal length)</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>[0.6666666666666666, 0.8, 0.7, 0.8666666666666...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>(Sepal length, Sepal width)</td>\n",
       "      <td>0.102823</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0,)</td>\n",
       "      <td>[0.5333333333333333, 0.6333333333333333, 0.7, ...</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>(Sepal length,)</td>\n",
       "      <td>0.122983</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>0.047842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1,)</td>\n",
       "      <td>[0.43333333333333335, 0.6333333333333333, 0.53...</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>(Sepal width,)</td>\n",
       "      <td>0.095416</td>\n",
       "      <td>0.074237</td>\n",
       "      <td>0.037118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_idx                                          cv_scores avg_score  \\\n",
       "12     (0, 2, 3)  [0.9666666666666667, 0.9666666666666667, 0.966...  0.973333   \n",
       "14  (0, 1, 2, 3)  [0.9666666666666667, 0.9666666666666667, 0.933...  0.966667   \n",
       "3           (3,)  [0.9666666666666667, 0.9666666666666667, 0.933...      0.96   \n",
       "13     (1, 2, 3)  [0.9666666666666667, 0.9666666666666667, 0.933...      0.96   \n",
       "6         (0, 3)  [0.9666666666666667, 0.9666666666666667, 0.9, ...  0.953333   \n",
       "9         (2, 3)  [0.9666666666666667, 0.9666666666666667, 0.9, ...  0.953333   \n",
       "5         (0, 2)  [0.9666666666666667, 1.0, 0.8666666666666667, ...  0.946667   \n",
       "11     (0, 1, 3)  [0.9333333333333333, 0.9666666666666667, 0.9, ...  0.946667   \n",
       "2           (2,)  [0.9333333333333333, 0.9333333333333333, 0.9, ...      0.94   \n",
       "8         (1, 3)  [0.9666666666666667, 0.9666666666666667, 0.866...      0.94   \n",
       "10     (0, 1, 2)  [0.9666666666666667, 0.9666666666666667, 0.866...      0.94   \n",
       "7         (1, 2)  [0.9333333333333333, 0.9333333333333333, 0.9, ...  0.926667   \n",
       "4         (0, 1)  [0.6666666666666666, 0.8, 0.7, 0.8666666666666...      0.74   \n",
       "0           (0,)  [0.5333333333333333, 0.6333333333333333, 0.7, ...  0.646667   \n",
       "1           (1,)  [0.43333333333333335, 0.6333333333333333, 0.53...  0.506667   \n",
       "\n",
       "                                        feature_names  ci_bound   std_dev  \\\n",
       "12          (Sepal length, Petal length, Petal width)  0.017137  0.013333   \n",
       "14  (Sepal length, Sepal width, Petal length, Peta...  0.027096  0.021082   \n",
       "3                                      (Petal width,)  0.032061  0.024944   \n",
       "13           (Sepal width, Petal length, Petal width)  0.032061  0.024944   \n",
       "6                         (Sepal length, Petal width)  0.043691  0.033993   \n",
       "9                         (Petal length, Petal width)  0.043691  0.033993   \n",
       "5                        (Sepal length, Petal length)  0.058115  0.045216   \n",
       "11           (Sepal length, Sepal width, Petal width)  0.043691  0.033993   \n",
       "2                                     (Petal length,)  0.041977   0.03266   \n",
       "8                          (Sepal width, Petal width)  0.049963  0.038873   \n",
       "10          (Sepal length, Sepal width, Petal length)  0.049963  0.038873   \n",
       "7                         (Sepal width, Petal length)  0.017137  0.013333   \n",
       "4                         (Sepal length, Sepal width)  0.102823      0.08   \n",
       "0                                     (Sepal length,)  0.122983  0.095685   \n",
       "1                                      (Sepal width,)  0.095416  0.074237   \n",
       "\n",
       "     std_err  \n",
       "12  0.006667  \n",
       "14  0.010541  \n",
       "3   0.012472  \n",
       "13  0.012472  \n",
       "6   0.016997  \n",
       "9   0.016997  \n",
       "5   0.022608  \n",
       "11  0.016997  \n",
       "2    0.01633  \n",
       "8   0.019437  \n",
       "10  0.019437  \n",
       "7   0.006667  \n",
       "4       0.04  \n",
       "0   0.047842  \n",
       "1   0.037118  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "efs1 = EFS(knn, \n",
    "           min_features=1,\n",
    "           max_features=4,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=5)\n",
    "\n",
    "feature_names = ('sepal length', 'sepal width',\n",
    "                 'petal length', 'petal width')\n",
    "\n",
    "df_X = pd.DataFrame(\n",
    "    X, columns=[\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\"])\n",
    "efs1 = efs1.fit(df_X, y)\n",
    "\n",
    "df = pd.DataFrame.from_dict(efs1.get_metric_dict()).T\n",
    "df.sort_values('avg_score', inplace=True, ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric_dict = efs1.get_metric_dict()\n",
    "\n",
    "fig = plt.figure()\n",
    "k_feat = sorted(metric_dict.keys())\n",
    "avg = [metric_dict[k]['avg_score'] for k in k_feat]\n",
    "\n",
    "upper, lower = [], []\n",
    "for k in k_feat:\n",
    "    upper.append(metric_dict[k]['avg_score'] +\n",
    "                 metric_dict[k]['std_dev'])\n",
    "    lower.append(metric_dict[k]['avg_score'] -\n",
    "                 metric_dict[k]['std_dev'])\n",
    "    \n",
    "plt.fill_between(k_feat,\n",
    "                 upper,\n",
    "                 lower,\n",
    "                 alpha=0.2,\n",
    "                 color='blue',\n",
    "                 lw=1)\n",
    "\n",
    "plt.plot(k_feat, avg, color='blue', marker='o')\n",
    "plt.ylabel('Accuracy +/- Standard Deviation')\n",
    "plt.xlabel('Number of Features')\n",
    "feature_min = len(metric_dict[k_feat[0]]['feature_idx'])\n",
    "feature_max = len(metric_dict[k_feat[-1]]['feature_idx'])\n",
    "plt.xticks(k_feat, \n",
    "           [str(metric_dict[k]['feature_names']) for k in k_feat], \n",
    "           rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 - Exhaustive feature selection for regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the classification examples above, the `SequentialFeatureSelector` also supports scikit-learn's estimators\n",
    "for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianraschka/miniforge3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"https://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Features: 377/377"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best subset: (0, 1, 4, 6, 7, 8, 9, 10, 11, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "efs = EFS(lr, \n",
    "          min_features=10,\n",
    "          max_features=12,\n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "efs.fit(X, y)\n",
    "\n",
    "print('Best MSE score: %.2f' % efs.best_score_ * (-1))\n",
    "print('Best subset:', efs.best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4 - Regression and adjusted R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in Example 3, the exhaustive feature selector can be used for selecting features via a regression model. In regression analysis, there exists the common phenomenon that the $R^2$ score can become spuriously inflated the more features we choose. Hence, and this is especially true for feature selection, it is useful to make model comparisons based on the adjusted $R^2$ value rather than the regular $R^2$. The adjusted $R^2$, $\\bar{R}^{2}$, accounts for the number of features and examples as follows:\n",
    "\n",
    "$$\\bar{R}^{2}=1-\\left(1-R^{2}\\right) \\frac{n-1}{n-p-1},$$\n",
    "\n",
    "where $n$ is the number of examples and $p$ is the number of features.\n",
    "\n",
    "One of the advantages of scikit-learn's API is that it's consistent, intuitive, and simple to use. However, one downside of this API design is that it can be a bit restrictive for certain scenarios. For instance, scikit-learn scoring function only take two inputs, the predicted and the true target values. Hence, we cannot use scikit-learn's scoring API to compute the adjusted $R^2$, which also requires the number of features.\n",
    "\n",
    "However, as a workaround, we can compute the $R^2$ for the different feature subsets and then do a posthoc computation to obtain the adjusted $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Compute $R^2$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianraschka/miniforge3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"https://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Features: 377/377"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best subset: (1, 3, 5, 6, 7, 8, 9, 10, 11, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "efs = EFS(lr, \n",
    "          min_features=10,\n",
    "          max_features=12,\n",
    "          scoring='r2',\n",
    "          cv=10)\n",
    "\n",
    "efs.fit(X, y)\n",
    "\n",
    "print('Best R2 score: %.2f' % efs.best_score_ * (-1))\n",
    "print('Best subset:', efs.best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Compute adjusted $R^2$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_r2(r2, num_examples, num_features):\n",
    "    coef = (num_examples - 1) / (num_examples - num_features - 1) \n",
    "    return 1 - (1 - r2) * coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in efs.subsets_:\n",
    "    efs.subsets_[i]['adjusted_avg_score'] = (\n",
    "        adjust_r2(r2=efs.subsets_[i]['avg_score'],\n",
    "                  num_examples=X.shape[0]/10,\n",
    "                  num_features=len(efs.subsets_[i]['feature_idx']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Select best subset based on adjusted $R^2$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = -99e10\n",
    "\n",
    "for i in efs.subsets_:\n",
    "    score = efs.subsets_[i]['adjusted_avg_score']\n",
    "    if ( efs.subsets_[i]['adjusted_avg_score'] == score and\n",
    "        len(efs.subsets_[i]['feature_idx']) < len(efs.best_idx_) )\\\n",
    "      or efs.subsets_[i]['adjusted_avg_score'] > score:\n",
    "        efs.best_idx_ = efs.subsets_[i]['feature_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best subset: (1, 3, 5, 6, 7, 8, 9, 10, 11, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Best adjusted R2 score: %.2f' % efs.best_score_ * (-1))\n",
    "print('Best subset:', efs.best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5 - Using the selected feature subset For making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    }
   ],
   "source": [
    "# Select the \"best\" three features via\n",
    "# 5-fold cross-validation on the training set.\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "efs1 = EFS(knn, \n",
    "           min_features=1,\n",
    "           max_features=4,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "efs1 = efs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Selected features:', efs1.best_idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 96.00 %\n"
     ]
    }
   ],
   "source": [
    "# Generate the new subsets based on the selected features\n",
    "# Note that the transform call is equivalent to\n",
    "# X_train[:, efs1.k_feature_idx_]\n",
    "\n",
    "X_train_efs = efs1.transform(X_train)\n",
    "X_test_efs = efs1.transform(X_test)\n",
    "\n",
    "# Fit the estimator using the new feature subset\n",
    "# and make a prediction on the test data\n",
    "knn.fit(X_train_efs, y_train)\n",
    "y_pred = knn.predict(X_test_efs)\n",
    "\n",
    "# Compute the accuracy of the prediction\n",
    "acc = float((y_test == y_pred).sum()) / y_pred.shape[0]\n",
    "print('Test set accuracy: %.2f %%' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6 - Exhaustive feature selection and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn's `GridSearch` to tune the hyperparameters of the `LogisticRegression` estimator inside the `ExhaustiveFeatureSelector` and use it for prediction in the pipeline. **Note that the `clone_estimator` attribute needs to be set to `False`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial', \n",
    "                        solver='newton-cg', \n",
    "                        random_state=123)\n",
    "\n",
    "efs1 = EFS(estimator=lr, \n",
    "           min_features=2,\n",
    "           max_features=3,\n",
    "           scoring='accuracy',\n",
    "           print_progress=False,\n",
    "           clone_estimator=False,\n",
    "           cv=5,\n",
    "           n_jobs=1)\n",
    "\n",
    "pipe = make_pipeline(efs1, lr)\n",
    "\n",
    "param_grid = {'exhaustivefeatureselector__estimator__C': [0.1, 1.0, 10.0]}\n",
    "    \n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=2, \n",
    "                  verbose=1, \n",
    "                  refit=False)\n",
    "\n",
    "# run gridearch\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the \"best\" parameters determined by GridSearch are ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters via GridSearch {'exhaustivefeatureselector__estimator__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters via GridSearch\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining the best *k* feature indices after GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in the best *k* best feature indices via `SequentialFeatureSelection.best_idx_`, we have to initialize a `GridSearchCV` object with `refit=True`. Now, the grid search object will take the complete training dataset and the best parameters, which it found via cross-validation, to train the estimator pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=1, \n",
    "                  cv=2, \n",
    "                  verbose=1, \n",
    "                  refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the grid search, we can access the individual pipeline objects of the `best_estimator_` via the `steps` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('exhaustivefeatureselector',\n",
       "  ExhaustiveFeatureSelector(clone_estimator=False,\n",
       "                            estimator=LogisticRegression(C=0.1,\n",
       "                                                         multi_class='multinomial',\n",
       "                                                         random_state=123,\n",
       "                                                         solver='newton-cg'),\n",
       "                            feature_groups=[[0], [1], [2], [3]], max_features=3,\n",
       "                            min_features=2, print_progress=False)),\n",
       " ('logisticregression',\n",
       "  LogisticRegression(multi_class='multinomial', random_state=123,\n",
       "                     solver='newton-cg'))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = gs.fit(X_train, y_train)\n",
    "gs.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via sub-indexing, we can then obtain the best-selected feature subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Best features:', gs.best_estimator_.steps[0][1].best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During cross-validation, this feature combination had a CV accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Best score:', gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exhaustivefeatureselector__estimator__C': 0.1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively**, if we can set the \"best grid search parameters\" in our pipeline manually if we ran `GridSearchCV` with `refit=False`. It should yield the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "pipe.set_params(**gs.best_params_).fit(X_train, y_train)\n",
    "print('Best features:', pipe.steps[0][1].best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7 - Exhaustive Feature Selection with LOOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ExhaustiveFeatureSelector` is not restricted to k-fold cross-validation. You can use any type of cross-validation method that supports the general scikit-learn cross-validation API. \n",
    "\n",
    "The following example illustrates the use of scikit-learn's `LeaveOneOut` cross-validation method in combination with the exhaustive feature selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.96\n",
      "Best subset (indices): (3,)\n",
      "Best subset (corresponding names): ('3',)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "efs1 = EFS(knn, \n",
    "           min_features=1,\n",
    "           max_features=4,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=LeaveOneOut()) ### Use cross-validation generator here\n",
    "\n",
    "efs1 = efs1.fit(X, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example 8 - Interrupting Long Runs for Intermediate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your run is taking too long, it is possible to trigger a `KeyboardInterrupt` (e.g., ctrl+c on a Mac, or interrupting the cell in a Jupyter notebook) to obtain temporary results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toy dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=200000,\n",
    "    n_features=6,\n",
    "    n_informative=2,\n",
    "    n_redundant=1,\n",
    "    n_repeated=1,\n",
    "    n_clusters_per_class=2,\n",
    "    flip_y=0.05,\n",
    "    class_sep=0.5,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Long run with interruption**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 56/56"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "efs1 = EFS(model, \n",
    "           min_features=1, \n",
    "           max_features=4,\n",
    "           print_progress=True,\n",
    "           scoring='accuracy')\n",
    "\n",
    "efs1 = efs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalizing the fit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the feature selection run hasn't finished, so certain attributes may not be available. In order to use the EFS instance, it is recommended to call `finalize_fit`, which will make EFS estimator appear as \"fitted\" process the temporary results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1.finalize_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.73\n",
      "Best subset (indices): (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9 - Working with Feature Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since mlxtend v0.21.0, it is possible to specify feature groups. Feature groups allow you to group certain features together, such that they are always selected as a group. This can be very useful in contexts similar to one-hot encoding -- if you want to treat the one-hot encoded feature as a single feature:\n",
    "\n",
    "![](SequentialFeatureSelector_files/feature_groups.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we specify sepal length and sepal width as a feature group so that they are always selected together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal len</th>\n",
       "      <th>petal len</th>\n",
       "      <th>sepal wid</th>\n",
       "      <th>petal wid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal len  petal len  sepal wid  petal wid\n",
       "0        5.1        3.5        1.4        0.2\n",
       "1        4.9        3.0        1.4        0.2\n",
       "2        4.7        3.2        1.3        0.2\n",
       "3        4.6        3.1        1.5        0.2\n",
       "4        5.0        3.6        1.4        0.2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_df = pd.DataFrame(X, columns=['sepal len', 'petal len',\n",
    "                                'sepal wid', 'petal wid'])\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 3/3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.97\n",
      "Best subset (indices): (0, 2, 3)\n",
      "Best subset (corresponding names): ('sepal len', 'sepal wid', 'petal wid')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "efs1 = EFS(knn, \n",
    "           min_features=2,\n",
    "           max_features=2,\n",
    "           scoring='accuracy',\n",
    "           feature_groups=[['sepal len', 'sepal wid'], ['petal len'], ['petal wid']],\n",
    "           cv=3)\n",
    "\n",
    "efs1 = efs1.fit(X_df, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the returned number of features is 3, since the number of `min_features` and `max_features` corresponds to the number of feature groups. I.e., we have 2 feature groups in `['sepal len', 'sepal wid'], ['petal wid']`, but it expands to 3 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ExhaustiveFeatureSelector\n",
      "\n",
      "*ExhaustiveFeatureSelector(estimator, min_features=1, max_features=1, print_progress=True, scoring='accuracy', cv=5, n_jobs=1, pre_dispatch='2*n_jobs', clone_estimator=True, fixed_features=None, feature_groups=None)*\n",
      "\n",
      "Exhaustive Feature Selection for Classification and Regression.\n",
      "    (new in v0.4.3)\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `estimator` : scikit-learn classifier or regressor\n",
      "\n",
      "\n",
      "\n",
      "- `min_features` : int (default: 1)\n",
      "\n",
      "    Minumum number of features to select\n",
      "\n",
      "\n",
      "- `max_features` : int (default: 1)\n",
      "\n",
      "    Maximum number of features to select. If parameter `feature_groups` is not\n",
      "    None, the number of features is equal to the number of feature groups, i.e.\n",
      "    `len(feature_groups)`. For  example, if `feature_groups = [[0], [1], [2, 3],\n",
      "    [4]]`, then the `max_features` value cannot exceed 4.\n",
      "\n",
      "\n",
      "- `print_progress` : bool (default: True)\n",
      "\n",
      "    Prints progress as the number of epochs\n",
      "    to stderr.\n",
      "\n",
      "\n",
      "- `scoring` : str, (default='accuracy')\n",
      "\n",
      "    Scoring metric in {accuracy, f1, precision, recall, roc_auc}\n",
      "    for classifiers,\n",
      "    {'mean_absolute_error', 'mean_squared_error',\n",
      "    'median_absolute_error', 'r2'} for regressors,\n",
      "    or a callable object or function with\n",
      "    signature ``scorer(estimator, X, y)``.\n",
      "\n",
      "\n",
      "- `cv` : int (default: 5)\n",
      "\n",
      "    Scikit-learn cross-validation generator or `int`.\n",
      "    If estimator is a classifier (or y consists of integer class labels),\n",
      "    stratified k-fold is performed, and regular k-fold cross-validation\n",
      "    otherwise.\n",
      "    No cross-validation if cv is None, False, or 0.\n",
      "\n",
      "\n",
      "- `n_jobs` : int (default: 1)\n",
      "\n",
      "    The number of CPUs to use for evaluating different feature subsets\n",
      "    in parallel. -1 means 'all CPUs'.\n",
      "\n",
      "\n",
      "- `pre_dispatch` : int, or string (default: '2*n_jobs')\n",
      "\n",
      "    Controls the number of jobs that get dispatched\n",
      "    during parallel execution if `n_jobs > 1` or `n_jobs=-1`.\n",
      "    Reducing this number can be useful to avoid an explosion of\n",
      "    memory consumption when more jobs get dispatched than CPUs can process.\n",
      "    This parameter can be:\n",
      "    None, in which case all the jobs are immediately created and spawned.\n",
      "    Use this for lightweight and fast-running jobs,\n",
      "    to avoid delays due to on-demand spawning of the jobs\n",
      "    An int, giving the exact number of total jobs that are spawned\n",
      "    A string, giving an expression as a function\n",
      "    of n_jobs, as in `2*n_jobs`\n",
      "\n",
      "\n",
      "- `clone_estimator` : bool (default: True)\n",
      "\n",
      "    Clones estimator if True; works with the original estimator instance\n",
      "    if False. Set to False if the estimator doesn't\n",
      "    implement scikit-learn's set_params and get_params methods.\n",
      "    In addition, it is required to set cv=0, and n_jobs=1.\n",
      "\n",
      "\n",
      "- `fixed_features` : tuple (default: None)\n",
      "\n",
      "    If not `None`, the feature indices provided as a tuple will be\n",
      "    regarded as fixed by the feature selector. For example, if\n",
      "    `fixed_features=(1, 3, 7)`, the 2nd, 4th, and 8th feature are\n",
      "    guaranteed to be present in the solution. Note that if\n",
      "    `fixed_features` is not `None`, make sure that the number of\n",
      "    features to be selected is greater than `len(fixed_features)`.\n",
      "    In other words, ensure that `k_features > len(fixed_features)`.\n",
      "\n",
      "\n",
      "- `feature_groups` : list or None (default: None)\n",
      "\n",
      "    Optional argument for treating certain features as a group.\n",
      "    This means, the features within a group are always selected together,\n",
      "    never split.\n",
      "    For example, `feature_groups=[[1], [2], [3, 4, 5]]`\n",
      "    specifies 3 feature groups.In this case,\n",
      "    possible feature selection results with `k_features=2`\n",
      "    are `[[1], [2]`, `[[1], [3, 4, 5]]`, or `[[2], [3, 4, 5]]`.\n",
      "    Feature groups can be useful for\n",
      "    interpretability, for example, if features 3, 4, 5 are one-hot\n",
      "    encoded features.  (For  more details, please read the notes at the\n",
      "    bottom of this docstring).  New in mlxtend v. 0.21.0.\n",
      "\n",
      "**Attributes**\n",
      "\n",
      "- `best_idx_` : array-like, shape = [n_predictions]\n",
      "\n",
      "    Feature Indices of the selected feature subsets.\n",
      "\n",
      "\n",
      "- `best_feature_names_` : array-like, shape = [n_predictions]\n",
      "\n",
      "    Feature names of the selected feature subsets. If pandas\n",
      "    DataFrames are used in the `fit` method, the feature\n",
      "    names correspond to the column names. Otherwise, the\n",
      "    feature names are string representation of the feature\n",
      "    array indices. New in v 0.13.0.\n",
      "\n",
      "\n",
      "- `best_score_` : float\n",
      "\n",
      "    Cross validation average score of the selected subset.\n",
      "\n",
      "\n",
      "- `subsets_` : dict\n",
      "\n",
      "    A dictionary of selected feature subsets during the\n",
      "    exhaustive selection, where the dictionary keys are\n",
      "    the lengths k of these feature subsets. The dictionary\n",
      "    values are dictionaries themselves with the following\n",
      "    keys: 'feature_idx' (tuple of indices of the feature subset)\n",
      "    'feature_names' (tuple of feature names of the feat. subset)\n",
      "    'cv_scores' (list individual cross-validation scores)\n",
      "    'avg_score' (average cross-validation score)\n",
      "    Note that if pandas\n",
      "    DataFrames are used in the `fit` method, the 'feature_names'\n",
      "    correspond to the column names. Otherwise, the\n",
      "    feature names are string representation of the feature\n",
      "    array indices. The 'feature_names' is new in v. 0.13.0.\n",
      "\n",
      "**Notes**\n",
      "\n",
      "(1) If parameter `feature_groups` is not None, the\n",
      "    number of features is equal to the number of feature groups, i.e.\n",
      "    `len(feature_groups)`. For  example, if `feature_groups = [[0], [1], [2, 3],\n",
      "    [4]]`, then the `max_features` value cannot exceed 4.\n",
      "\n",
      "    (2) Although two or more individual features may be considered as one group\n",
      "    throughout the feature-selection process, it does not mean the individual\n",
      "    features of that group have the same impact on the outcome. For instance, in\n",
      "    linear regression, the coefficient of the feature 2 and 3 can be different\n",
      "    even if they are considered as one group in feature_groups.\n",
      "\n",
      "    (3) If both fixed_features and feature_groups are specified, ensure that each\n",
      "    feature group contains the fixed_features selection. E.g., for a 3-feature set\n",
      "    fixed_features=[0, 1] and feature_groups=[[0, 1], [2]] is valid;\n",
      "    fixed_features=[0, 1] and feature_groups=[[0], [1, 2]] is not valid.\n",
      "\n",
      "**Examples**\n",
      "\n",
      "For usage examples, please see\n",
      "    https://rasbt.github.io/mlxtend/user_guide/feature_selection/ExhaustiveFeatureSelector/\n",
      "\n",
      "### Methods\n",
      "\n",
      "<hr>\n",
      "\n",
      "*fit(X, y, groups=None, **fit_params)*\n",
      "\n",
      "Perform feature selection and learn model from training data.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `X` : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "\n",
      "    Training vectors, where n_samples is the number of samples and\n",
      "    n_features is the number of features.\n",
      "    New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      "    argument for X.\n",
      "\n",
      "\n",
      "- `y` : array-like, shape = [n_samples]\n",
      "\n",
      "    Target values.\n",
      "\n",
      "\n",
      "- `groups` : array-like, with shape (n_samples,), optional\n",
      "\n",
      "    Group labels for the samples used while splitting the dataset into\n",
      "    train/test set. Passed to the fit method of the cross-validator.\n",
      "\n",
      "\n",
      "- `fit_params` : dict of string -> object, optional\n",
      "\n",
      "    Parameters to pass to to the fit method of classifier.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `self` : object\n",
      "\n",
      "\n",
      "<hr>\n",
      "\n",
      "*fit_transform(X, y, groups=None, **fit_params)*\n",
      "\n",
      "Fit to training data and return the best selected features from X.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `X` : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "\n",
      "    Training vectors, where n_samples is the number of samples and\n",
      "    n_features is the number of features.\n",
      "    New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      "    argument for X.\n",
      "\n",
      "- `y` : array-like, shape = [n_samples]\n",
      "\n",
      "    Target values.\n",
      "\n",
      "- `groups` : array-like, with shape (n_samples,), optional\n",
      "\n",
      "    Group labels for the samples used while splitting the dataset into\n",
      "    train/test set. Passed to the fit method of the cross-validator.\n",
      "\n",
      "- `fit_params` : dict of string -> object, optional\n",
      "\n",
      "    Parameters to pass to to the fit method of classifier.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "Feature subset of X, shape={n_samples, k_features}\n",
      "\n",
      "<hr>\n",
      "\n",
      "*get_metric_dict(confidence_interval=0.95)*\n",
      "\n",
      "Return metric dictionary\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `confidence_interval` : float (default: 0.95)\n",
      "\n",
      "    A positive float between 0.0 and 1.0 to compute the confidence\n",
      "    interval bounds of the CV score averages.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "Dictionary with items where each dictionary value is a list\n",
      "    with the number of iterations (number of feature subsets) as\n",
      "    its length. The dictionary keys corresponding to these lists\n",
      "    are as follows:\n",
      "    'feature_idx': tuple of the indices of the feature subset\n",
      "    'cv_scores': list with individual CV scores\n",
      "    'avg_score': of CV average scores\n",
      "    'std_dev': standard deviation of the CV score average\n",
      "    'std_err': standard error of the CV score average\n",
      "    'ci_bound': confidence interval bound of the CV score average\n",
      "\n",
      "<hr>\n",
      "\n",
      "*get_params(deep=True)*\n",
      "\n",
      "Get parameters for this estimator.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `deep` : bool, default=True\n",
      "\n",
      "    If True, will return the parameters for this estimator and\n",
      "    contained subobjects that are estimators.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `params` : dict\n",
      "\n",
      "    Parameter names mapped to their values.\n",
      "\n",
      "<hr>\n",
      "\n",
      "*set_params(**params)*\n",
      "\n",
      "Set the parameters of this estimator.\n",
      "\n",
      "    The method works on simple estimators as well as on nested objects\n",
      "    (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "    parameters of the form ``<component>__<parameter>`` so that it's\n",
      "    possible to update each component of a nested object.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `**params` : dict\n",
      "\n",
      "    Estimator parameters.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "- `self` : estimator instance\n",
      "\n",
      "    Estimator instance.\n",
      "\n",
      "<hr>\n",
      "\n",
      "*transform(X)*\n",
      "\n",
      "Return the best selected features from X.\n",
      "\n",
      "**Parameters**\n",
      "\n",
      "- `X` : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "\n",
      "    Training vectors, where n_samples is the number of samples and\n",
      "    n_features is the number of features.\n",
      "    New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      "    argument for X.\n",
      "\n",
      "**Returns**\n",
      "\n",
      "Feature subset of X, shape={n_samples, k_features}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../api_modules/mlxtend.feature_selection/ExhaustiveFeatureSelector.md', 'r') as f:\n",
    "    print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
