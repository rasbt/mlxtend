{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kota/miniconda3/envs/mlxtend/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.externals.estimator_checks import NotFittedError\n",
    "from mlxtend.utils import assert_raises\n",
    "from mlxtend.regressor import StackingRegressor, StackingCVRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import sparse\n",
    "from numpy.testing import assert_almost_equal\n",
    "from nose.tools import raises\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from mlxtend.externals.estimator_checks import NotFittedError\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from mlxtend.utils import assert_raises\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "# Some test data\n",
    "np.random.seed(1)\n",
    "X1 = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "X2 = np.sort(5 * np.random.rand(40, 2), axis=0)\n",
    "X3 = np.zeros((40, 3))\n",
    "y = np.sin(X1).ravel()\n",
    "y[::5] += 3 * (0.5 - np.random.rand(8))\n",
    "y2 = np.zeros((40,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20166969294437087\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(8)\n",
    "w = np.array([random.random() for _ in range(40)])\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                            meta_regressor=svr_rbf, \n",
    "                            cv=KFold(4, shuffle=True, random_state=7))\n",
    "stack.fit(X1, y, sample_weight=np.ones(40)).predict(X1)\n",
    "mse = 0.21\n",
    "got = np.mean((stack.predict(X1) - y) ** 2)\n",
    "print(got)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36775818  0.41422082  0.43800099  0.46889041  0.59272485  0.61231241\n",
      "  0.62836283  0.7367122   0.7522366   0.80566971  0.84050448  0.86365339\n",
      "  0.87532447  0.9710891   0.97014473  0.96966604  0.952006    0.87445258\n",
      "  0.82740436  0.82668374  0.82182401  0.81682575  0.40477061  0.37905676\n",
      "  0.28624875 -0.25799577 -0.32626711 -0.33209999 -0.35638635 -0.35838507\n",
      " -0.47926837 -0.59599037 -0.75945827 -0.84141441 -0.91029104 -0.91237472\n",
      " -0.9124045  -0.92923798 -0.94573335 -0.94170385]\n",
      "[ 0.36775818  0.41422082  0.43800099  0.46889041  0.59272485  0.61231241\n",
      "  0.62836283  0.7367122   0.7522366   0.80566971  0.84050448  0.86365339\n",
      "  0.87532447  0.9710891   0.97014473  0.96966604  0.952006    0.87445258\n",
      "  0.82740436  0.82668374  0.82182401  0.81682575  0.40477061  0.37905676\n",
      "  0.28624875 -0.25799577 -0.32626711 -0.33209999 -0.35638635 -0.35838507\n",
      " -0.47926837 -0.59599037 -0.75945827 -0.84141441 -0.91029104 -0.91237472\n",
      " -0.9124045  -0.92923798 -0.94573335 -0.94170385]\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                            meta_regressor=svr_rbf, \n",
    "                            cv=KFold(5, shuffle=True, random_state=5))\n",
    "pred1 = stack.fit(X1, y, sample_weight=np.ones(40)).predict(X1)\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# svr_lin = SVR(kernel='linear')\n",
    "# ridge = Ridge(random_state=1)\n",
    "# svr_rbf = SVR(kernel='rbf')\n",
    "# stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "#                             meta_regressor=svr_rbf, \n",
    "#                             cv=KFold(5, shuffle=True, random_state=5))\n",
    "pred2 = stack.fit(X1, y).predict(X1)\n",
    "\n",
    "print(pred1)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2ca36aa8e938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "r = RandomForestClassifier()\n",
    "r.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cd5c02103ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "g = GaussianNB()\n",
    "g.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-32260a6ba21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l = LogisticRegression()\n",
    "l.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "0.700000 is wrong",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3baa3ca6d56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mgot\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgot\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%f is wrong'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mtest_gridsearch_numerate_regr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3baa3ca6d56d>\u001b[0m in \u001b[0;36mtest_gridsearch_numerate_regr\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mgot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mgot\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgot\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%f is wrong'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0mtest_gridsearch_numerate_regr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 0.700000 is wrong"
     ]
    }
   ],
   "source": [
    "def test_multivariate():\n",
    "    lr = LinearRegression()\n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                                meta_regressor=svr_rbf, \n",
    "                                cv=KFold(5, shuffle=True, random_state=3))\n",
    "    stack.fit(X2, y).predict(X2)\n",
    "    mse = 0.20\n",
    "    got = np.mean((stack.predict(X2) - y) ** 2)\n",
    "    assert round(got, 2) == mse, '%f != %f' % (round(got, 2), mse)\n",
    "\n",
    "\n",
    "def test_internals():\n",
    "    lr = LinearRegression()\n",
    "    regressors = [lr, lr, lr, lr, lr]\n",
    "    #cv = 10\n",
    "    stack = StackingCVRegressor(regressors=[lr, lr, lr, lr, lr],\n",
    "                                meta_regressor=lr,\n",
    "                                cv=KFold(10, shuffle=True, random_state=4))\n",
    "    stack.fit(X3, y2)\n",
    "    assert stack.predict(X3).mean() == y2.mean()\n",
    "    assert stack.meta_regr_.intercept_ == 0.0\n",
    "    assert stack.meta_regr_.coef_[0] == 0.0\n",
    "    assert stack.meta_regr_.coef_[1] == 0.0\n",
    "    assert stack.meta_regr_.coef_[2] == 0.0\n",
    "    assert len(stack.regr_) == len(regressors)\n",
    "\n",
    "\n",
    "def test_gridsearch_numerate_regr():\n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    stack = StackingCVRegressor(regressors=[svr_lin, ridge, ridge],\n",
    "                                meta_regressor=svr_rbf, \n",
    "                                cv=KFold(3, shuffle=True, random_state=4))\n",
    "\n",
    "    params = {'ridge-1__alpha': [0.01, 1.0],\n",
    "              'ridge-2__alpha': [0.01, 1.0],\n",
    "              'svr__C': [0.01, 1.0],\n",
    "              'meta-svr__C': [0.01, 1.0],\n",
    "              'use_features_in_secondary': [True, False]}\n",
    "\n",
    "    grid = GridSearchCV(estimator=stack,\n",
    "                        param_grid=params,\n",
    "                        cv=KFold(5, shuffle=True, random_state=5),\n",
    "                        refit=True,\n",
    "                        verbose=0)\n",
    "    grid = grid.fit(X1, y)\n",
    "    got = round(grid.best_score_, 1)\n",
    "    print(got)\n",
    "    assert got >= 0.1 and got <= 0.2, '%f is wrong' % got\n",
    "test_gridsearch_numerate_regr()\n",
    "\n",
    "def test_get_params():\n",
    "    lr = LinearRegression()\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    stregr = StackingCVRegressor(regressors=[ridge, lr],\n",
    "                                 meta_regressor=svr_rbf, cv=cv3)\n",
    "\n",
    "    got = sorted(list({s.split('__')[0] for s in stregr.get_params().keys()}))\n",
    "    expect = ['cv',\n",
    "              'linearregression',\n",
    "              'meta-svr',\n",
    "              'meta_regressor',\n",
    "              'refit',\n",
    "              'regressors',\n",
    "              'ridge',\n",
    "              'shuffle',\n",
    "              'store_train_meta_features',\n",
    "              'use_features_in_secondary']\n",
    "    assert got == expect, got\n",
    "\n",
    "\n",
    "def test_regressor_gridsearch():\n",
    "    lr = LinearRegression()\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    stregr = StackingCVRegressor(regressors=[lr],\n",
    "                                 meta_regressor=svr_rbf, cv=cv3)\n",
    "\n",
    "    params = {'regressors': [[ridge, lr], [lr, ridge, lr]]}\n",
    "\n",
    "    grid = GridSearchCV(estimator=stregr,\n",
    "                        param_grid=params,\n",
    "                        cv=cv5,\n",
    "                        refit=True)\n",
    "    grid.fit(X1, y)\n",
    "\n",
    "    assert len(grid.best_params_['regressors']) == 3\n",
    "\n",
    "\n",
    "def test_predict_meta_features():\n",
    "    lr = LinearRegression()\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    stregr = StackingCVRegressor(regressors=[lr, ridge],\n",
    "                                 meta_regressor=svr_rbf, cv=cv3)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.3)\n",
    "    stregr.fit(X_train, y_train)\n",
    "    test_meta_features = stregr.predict(X_test)\n",
    "    assert test_meta_features.shape[0] == X_test.shape[0]\n",
    "\n",
    "\n",
    "def test_train_meta_features_():\n",
    "    lr = LinearRegression()\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    stregr = StackingCVRegressor(regressors=[lr, ridge],\n",
    "                                 meta_regressor=svr_rbf, cv=cv3,\n",
    "                                 store_train_meta_features=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.3)\n",
    "    stregr.fit(X_train, y_train)\n",
    "    train_meta_features = stregr.train_meta_features_\n",
    "    assert train_meta_features.shape[0] == X_train.shape[0]\n",
    "\n",
    "\n",
    "def test_not_fitted_predict():\n",
    "    lr = LinearRegression()\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    stregr = StackingCVRegressor(regressors=[lr, ridge],\n",
    "                                 meta_regressor=svr_rbf, cv=cv3,\n",
    "                                 store_train_meta_features=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.3)\n",
    "\n",
    "    expect = (\"This StackingCVRegressor instance is not fitted yet. Call \"\n",
    "              \"'fit' with appropriate arguments before using this method.\")\n",
    "\n",
    "    assert_raises(NotFittedError,\n",
    "                  expect,\n",
    "                  stregr.predict,\n",
    "                  X_train)\n",
    "\n",
    "    assert_raises(NotFittedError,\n",
    "                  expect,\n",
    "                  stregr.predict_meta_features,\n",
    "                  X_train)\n",
    "\n",
    "\n",
    "def test_clone():\n",
    "    lr = LinearRegression()\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    stregr = StackingCVRegressor(regressors=[lr, ridge],\n",
    "                                 meta_regressor=svr_rbf, cv=cv3,\n",
    "                                 store_train_meta_features=True)\n",
    "    clone(stregr)\n",
    "\n",
    "\n",
    "def test_sparse_matrix_inputs():\n",
    "    lr = LinearRegression()\n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                                meta_regressor=svr_rbf, cv=cv3)\n",
    "\n",
    "    # dense\n",
    "    stack.fit(X1, y).predict(X1)\n",
    "    mse = 0.20\n",
    "    got = np.mean((stack.predict(X1) - y) ** 2)\n",
    "    assert round(got, 2) == mse\n",
    "\n",
    "    # sparse\n",
    "    stack.fit(sparse.csr_matrix(X1), y)\n",
    "    mse = 0.20\n",
    "    got = np.mean((stack.predict(sparse.csr_matrix(X1)) - y) ** 2)\n",
    "    assert round(got, 2) == mse\n",
    "\n",
    "\n",
    "def test_sparse_matrix_inputs_with_features_in_secondary():\n",
    "    lr = LinearRegression()\n",
    "    svr_lin = SVR(kernel='linear')\n",
    "    ridge = Ridge(random_state=1)\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                                meta_regressor=svr_rbf, cv=cv3,\n",
    "                                use_features_in_secondary=True)\n",
    "\n",
    "    # dense\n",
    "    stack.fit(X1, y).predict(X1)\n",
    "    mse = 0.20\n",
    "    got = np.mean((stack.predict(X1) - y) ** 2)\n",
    "    assert round(got, 2) == mse\n",
    "\n",
    "    # sparse\n",
    "    stack.fit(sparse.csr_matrix(X1), y)\n",
    "    mse = 0.20\n",
    "    got = np.mean((stack.predict(sparse.csr_matrix(X1)) - y) ** 2)\n",
    "    assert round(got, 2) == mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "X2 = np.sort(5 * np.random.rand(40, 2), axis=0)\n",
    "y = np.sin(X1).ravel()\n",
    "y[::5] += 3 * (0.5 - np.random.rand(8))\n",
    "y2 = np.sin(X2)\n",
    "\n",
    "#w = np.random.random(40)\n",
    "import random\n",
    "random.seed(1)\n",
    "w = np.array([random.random() for _ in range(40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stregr = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                             meta_regressor=svr_rbf, cv=cv)\n",
    "stregr.fit(X1, y, sample_weight=w).predict(X1)\n",
    "mse = 0.21\n",
    "got = np.mean((stregr.predict(X1) - y) ** 2)\n",
    "print(got)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stregr = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                             meta_regressor=svr_rbf, cv=cv)\n",
    "stregr.fit(X1, y, sample_weight=np.ones(40)).predict(X1)\n",
    "mse = 0.21\n",
    "got = np.mean((stregr.predict(X1) - y) ** 2)\n",
    "print(got)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stregr = StackingRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                           meta_regressor=svr_rbf)\n",
    "pred1 = stregr.fit(X1, y).predict(X1)\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stregr = StackingRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                           meta_regressor=svr_rbf)\n",
    "pred2 = stregr.fit(X1, y, np.ones(40)).predict(X1)\n",
    "print(pred1)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge.fit(X1, y).predict(X1))\n",
    "print(ridge.fit(X1, y, 2*np.ones(40)).predict(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge.fit(X1, y, ).predict(X1))\n",
    "print(ridge.fit(X1, y, np.ones(40)).predict(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                           meta_regressor=MLPRegressor())\n",
    "stregr.fit(X1, y, w).predict(X1)\n",
    "mse = 0.21\n",
    "got = np.mean((stregr.predict(X1) - y) ** 2)\n",
    "got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "np.random.seed(1)\n",
    "cv = KFold(2, shuffle=True)\n",
    "print(list(cv.split([1,2,3,4,5,6])))\n",
    "\n",
    "np.random.seed(1)\n",
    "random.random()\n",
    "cv = KFold(2, shuffle=True)\n",
    "print(list(cv.split([1,2,3,4,5,6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "stack = StackingCVRegressor(regressors=[svr_lin, lr, ridge],\n",
    "                            meta_regressor=svr_rbf, cv=cv)\n",
    "stack.fit(X1, y).predict(X1)\n",
    "mse = 0.21\n",
    "got = np.mean((stack.predict(X1) - y) ** 2)\n",
    "got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
