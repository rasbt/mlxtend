<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A library consisting of useful tools and extensions for the day-to-day data science tasks."> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/">
    <link rel="shortcut icon" href="../../../img/favicon.ico">

    <title>EnsembleVoteClassifier: A majority voting classifier - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../cinder/css/base.css" rel="stylesheet">


    <link href="../../../cinder/css/bootstrap-custom.css" rel="stylesheet">


    <link href="../../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">


    <link href="../../../cinder/css/cinder.css" rel="stylesheet">


    <link href="../../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">


    <link href="../../../cinder/css/highlight.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../USER_GUIDE_INDEX/">User Guide Index</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../Adaline/">Adaline: Adaptive Linear Neuron Classifier</a>
</li>

        
            
<li class="active">
    <a href="./">EnsembleVoteClassifier: A majority voting classifier</a>
</li>

        
            
<li >
    <a href="../LogisticRegression/">LogisticRegression: A binary classifier</a>
</li>

        
            
<li >
    <a href="../MultiLayerPerceptron/">MultilayerPerceptron: A simple multilayer neural network</a>
</li>

        
            
<li >
    <a href="../OneRClassifier/">OneRClassifier: One Rule (OneR) method for classfication</a>
</li>

        
            
<li >
    <a href="../Perceptron/">Perceptron: A simple binary classifier</a>
</li>

        
            
<li >
    <a href="../SoftmaxRegression/">SoftmaxRegression: Multiclass version of logistic regression</a>
</li>

        
            
<li >
    <a href="../StackingClassifier/">StackingClassifier: Simple stacking</a>
</li>

        
            
<li >
    <a href="../StackingCVClassifier/">StackingCVClassifier: Stacking with cross-validation</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">cluster</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../cluster/Kmeans/">Kmeans: k-means clustering</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">autompg_data: The Auto-MPG dataset for regression</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">boston_housing_data: The Boston housing dataset for regression</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">iris_data: The 3-class iris dataset for classification</a>
</li>

        
            
<li >
    <a href="../../data/loadlocal_mnist/">loadlocal_mnist: A function for loading MNIST from the original ubyte files</a>
</li>

        
            
<li >
    <a href="../../data/make_multiplexer_dataset/">make_multiplexer_dataset: A function for creating multiplexer data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">mnist_data: A subset of the MNIST dataset for classification</a>
</li>

        
            
<li >
    <a href="../../data/three_blobs_data/">three_blobs_data: The synthetic blobs for classification</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">wine_data: A 3-class wine dataset for classification</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/accuracy_score/">accuracy_score: Computing standard, balanced, and per-class accuracy</a>
</li>

        
            
<li >
    <a href="../../evaluate/bias_variance_decomp/">bias_variance_decomp: Bias-variance decomposition for classification and regression losses</a>
</li>

        
            
<li >
    <a href="../../evaluate/bootstrap/">bootstrap: The ordinary nonparametric boostrap for arbitrary parameters</a>
</li>

        
            
<li >
    <a href="../../evaluate/bootstrap_point632_score/">bootstrap_point632_score: The .632 and .632+ boostrap for classifier evaluation</a>
</li>

        
            
<li >
    <a href="../../evaluate/BootstrapOutOfBag/">BootstrapOutOfBag: A scikit-learn compatible version of the out-of-bag bootstrap</a>
</li>

        
            
<li >
    <a href="../../evaluate/cochrans_q/">cochrans_q: Cochran's Q test for comparing multiple classifiers</a>
</li>

        
            
<li >
    <a href="../../evaluate/combined_ftest_5x2cv/">combined_ftest_5x2cv: 5x2cv combined *F* test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/confusion_matrix/">confusion_matrix: creating a confusion matrix for model evaluation</a>
</li>

        
            
<li >
    <a href="../../evaluate/create_counterfactual/">create_counterfactual: Interpreting models via counterfactuals</a>
</li>

        
            
<li >
    <a href="../../evaluate/feature_importance_permutation/">feature_importance_permutation: Estimate feature importance via feature permutation.</a>
</li>

        
            
<li >
    <a href="../../evaluate/ftest/">ftest: F-test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/GroupTimeSeriesSplit/">GroupTimeSeriesSplit: A scikit-learn compatible version of the time series validation with groups</a>
</li>

        
            
<li >
    <a href="../../evaluate/lift_score/">lift_score: Lift score for classification and association rule mining</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar_table/">mcnemar_table: Ccontingency table for McNemar's test</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar_tables/">mcnemar_tables: contingency tables for McNemar's test and Cochran's Q test</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar/">mcnemar: McNemar's test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_5x2cv/">paired_ttest_5x2cv: 5x2cv paired *t* test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_kfold_cv/">paired_ttest_kfold_cv: K-fold cross-validated paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_resampled/">paired_ttest_resample: Resampled paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/permutation_test/">permutation_test: Permutation test for hypothesis testing</a>
</li>

        
            
<li >
    <a href="../../evaluate/PredefinedHoldoutSplit/">PredefinedHoldoutSplit: Utility for the holdout method compatible with scikit-learn</a>
</li>

        
            
<li >
    <a href="../../evaluate/RandomHoldoutSplit/">RandomHoldoutSplit: split a dataset into a train and validation subset for validation</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">scoring: computing various performance metrics</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_extraction</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_extraction/LinearDiscriminantAnalysis/">LinearDiscriminantAnalysis: Linear discriminant analysis for dimensionality reduction</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/PrincipalComponentAnalysis/">PrincipalComponentAnalysis: Principal component analysis (PCA) for dimensionality reduction</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/RBFKernelPCA/">RBFKernelPCA</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/ColumnSelector/">ColumnSelector: Scikit-learn utility function to select specific columns in a pipeline</a>
</li>

        
            
<li >
    <a href="../../feature_selection/ExhaustiveFeatureSelector/">ExhaustiveFeatureSelector: Optimal feature sets by considering all possible feature combinations</a>
</li>

        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector: The popular forward and backward feature selection approaches incl. floating variants</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">find_filegroups: Find files that only differ via their file extensions</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">find_files: Find files based on substring matches</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">frequent_patterns</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../frequent_patterns/apriori/">Apriori</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/association_rules/">Association rules</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/fpgrowth/">Fpgrowth</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/fpmax/">Fpmax</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">image</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../image/extract_face_landmarks/">extract_face_landmarks: extract 68 landmark features from face images</a>
</li>

        
            
<li >
    <a href="../../image/eyepad_align/">EyepadAlign:  align face images based on eye location</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">num_combinations: combinations for creating subsequences of *k* elements</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">num_permutations: number of permutations for creating subsequences of *k* elements</a>
</li>

        
            
<li >
    <a href="../../math/vectorspace_dimensionality/">vectorspace_dimensionality: compute the number of dimensions that a set of vectors spans</a>
</li>

        
            
<li >
    <a href="../../math/vectorspace_orthonormalization/">vectorspace_orthonormalization: Converts a set of linearly independent vectors to a set of orthonormal basis vectors</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../plotting/category_scatter/">Scategory_scatter: Create a scatterplot with categories in different colors</a>
</li>

        
            
<li >
    <a href="../../plotting/checkerboard_plot/">checkerboard_plot: Create a checkerboard plot in matplotlib</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_pca_correlation_graph/">plot_pca_correlation_graph: plot correlations between original features and principal components</a>
</li>

        
            
<li >
    <a href="../../plotting/ecdf/">ecdf: Create an empirical cumulative distribution function plot</a>
</li>

        
            
<li >
    <a href="../../plotting/enrichment_plot/">enrichment_plot: create an enrichment plot for cumulative counts</a>
</li>

        
            
<li >
    <a href="../../plotting/heatmap/">heatmap: Create a heatmap in matplotlib</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_confusion_matrix/">plot_confusion_matrix: Visualize confusion matrices</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_decision_regions/">plot_decision_regions: Visualize the decision regions of a classifier</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_learning_curves/">plot_learning_curves: Plot learning curves from training and test sets</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_linear_regression/">plot_linear_regression: A quick way for plotting linear regression fits</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_sequential_feature_selection/">plot_sequential_feature_selection: Visualize selected feature subset performances from the SequentialFeatureSelector</a>
</li>

        
            
<li >
    <a href="../../plotting/scatterplotmatrix/">scatterplotmatrix: visualize datasets via a scatter plot matrix</a>
</li>

        
            
<li >
    <a href="../../plotting/scatter_hist/">scatter_hist: create a scatter histogram plot</a>
</li>

        
            
<li >
    <a href="../../plotting/stacked_barplot/">stacked_barplot: Plot stacked bar plots in matplotlib</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/CopyTransformer/">CopyTransformer: A function that creates a copy of the input array in a scikit-learn pipeline</a>
</li>

        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer: Transforms a sparse into a dense NumPy array, e.g., in a scikit-learn pipeline</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer: column-based mean centering on a NumPy array</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">MinMaxScaling: Min-max scaling fpr pandas DataFrames and NumPy arrays</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">shuffle_arrays_unison: shuffle arrays in a consistent fashion</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">standardize: A function to standardize columns in a 2D NumPy array</a>
</li>

        
            
<li >
    <a href="../../preprocessing/TransactionEncoder/">TransactionEncoder</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression: An implementation of ordinary least-squares linear regression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingCVRegressor/">StackingCVRegressor: stacking with cross-validation for regression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor: a simple stacking implementation for regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">generalize_names: convert names into a generalized format</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">generalize_names_duplcheck: Generalize names while preventing duplicates among different names</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">tokenizer_emoticons: tokenizers for emoticons</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter: A simple progress counter</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.cluster/">Mlxtend.cluster</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_extraction/">Mlxtend.feature extraction</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.frequent_patterns/">Mlxtend.frequent patterns</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.image/">Mlxtend.image</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.plotting/">Mlxtend.plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../CHANGELOG/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../Code-of-Conduct/">Code of Conduct</a>
</li>

                        
                            
<li >
    <a href="../../../CONTRIBUTING/">How To Contribute</a>
</li>

                        
                            
<li >
    <a href="../../../contributors/">Contributors</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                            
<li >
    <a href="../../../cite/">Citing Mlxtend</a>
</li>

                        
                            
<li >
    <a href="../../../discuss/">Discuss</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fa fa-search"></i> Search
                        </a>
                    </li>

                <!--
                    <li >
                        <a rel="next" href="../Adaline/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../LogisticRegression/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>-->
                    <li>
                        <a href="https://github.com/rasbt/mlxtend"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#ensemblevoteclassifier-a-majority-voting-classifier">EnsembleVoteClassifier: A majority voting classifier</a></li>
        <li class="first-level "><a href="#overview">Overview</a></li>
            <li class="second-level"><a href="#majority-voting-hard-voting">Majority Voting / Hard Voting</a></li>
                 <!--   -->
            <li class="second-level"><a href="#weighted-majority-vote">Weighted Majority Vote</a></li>
                 <!--   -->
            <li class="second-level"><a href="#soft-voting">Soft Voting</a></li>
                 <!--   -->
            <li class="second-level"><a href="#references">References</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-1-classifying-iris-flowers-using-different-classification-models">Example 1 -  Classifying Iris Flowers Using Different Classification Models</a></li>
                 <!-- 
                <li class="third-level"><a href="#plotting-decision-regions">Plotting Decision Regions</a></li>  -->
            <li class="second-level"><a href="#example-2-grid-search">Example 2 - Grid Search</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-3-majority-voting-with-classifiers-trained-on-different-feature-subsets">Example 3 - Majority voting with classifiers trained on different feature subsets</a></li>
                 <!-- 
                <li class="third-level"><a href="#manual-approach">Manual Approach</a></li>  -->
            <li class="second-level"><a href="#example-5-using-pre-fitted-classifiers">Example 5 - Using Pre-fitted Classifiers</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-6-ensembles-of-classifiers-that-operate-on-different-feature-subsets">Example 6 - Ensembles of Classifiers that Operate on Different Feature Subsets</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-7-a-note-about-scikit-learn-svms-and-soft-voting">Example 7 - A Note about Scikit-Learn SVMs and Soft Voting</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-7-a-note-about-scikit-learn-svms-and-soft-voting_1">Example 7 - A Note about Scikit-Learn SVMs and Soft Voting</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-8-optimizing-ensemble-weights-with-nelder-mead">Example 8 - Optimizing Ensemble Weights with Nelder-Mead</a></li>
                 <!--   -->
        <li class="first-level "><a href="#api">API</a></li>
            <li class="second-level"><a href="#methods">Methods</a></li>
                 <!--   -->
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="ensemblevoteclassifier-a-majority-voting-classifier">EnsembleVoteClassifier: A majority voting classifier</h1>
<p>Implementation of a majority voting <code>EnsembleVoteClassifier</code> for classification.</p>
<blockquote>
<p>from mlxtend.classifier import EnsembleVoteClassifier</p>
</blockquote>
<h1 id="overview">Overview</h1>
<p>The <code>EnsembleVoteClassifier</code> is a meta-classifier for combining similar or conceptually different machine learning classifiers for classification via majority or plurality voting. (For simplicity, we will refer to both majority and plurality voting as majority voting.)</p>
<p><img alt="" src="../EnsembleVoteClassifier_files/voting.png" /></p>
<p>The <code>EnsembleVoteClassifier</code> implements "hard" and "soft" voting. In hard voting, we predict the final class label as the class label that has been predicted most frequently by the classification models. In soft voting, we predict the class labels by averaging the class-probabilities (only recommended if the classifiers are well-calibrated).</p>
<p><img alt="" src="../EnsembleVoteClassifier_files/majority_voting.png" /></p>
<p><strong>Note</strong></p>
<p>If you are interested in using the <code>EnsembleVoteClassifier</code>, please note that it is now also available through scikit learn (&gt;0.17) as <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"><code>VotingClassifier</code></a>.</p>
<h3 id="majority-voting-hard-voting">Majority Voting / Hard Voting</h3>
<p>Hard voting is the simplest case of majority voting. Here, we predict the class label <script type="math/tex">\hat{y}</script> via majority (plurality) voting of each classifier <script type="math/tex">C_j</script>:</p>
<p>
<script type="math/tex; mode=display">\hat{y}=mode\{C_1(\mathbf{x}), C_2(\mathbf{x}), ..., C_m(\mathbf{x})\}</script>
</p>
<p>Assuming that we combine three classifiers that classify a training sample as follows:</p>
<ul>
<li>classifier 1 -&gt; class 0</li>
<li>classifier 2 -&gt; class 0</li>
<li>classifier 3 -&gt; class 1</li>
</ul>
<p>
<script type="math/tex; mode=display">\hat{y}=mode\{0, 0, 1\} = 0</script>
</p>
<p>Via majority vote, we would we would classify the sample as "class 0."</p>
<h3 id="weighted-majority-vote">Weighted Majority Vote</h3>
<p>In addition to the simple majority vote (hard voting) as described in the previous section, we can compute a weighted majority vote by associating a weight <script type="math/tex">w_j</script> with classifier <script type="math/tex">C_j</script>:</p>
<p>
<script type="math/tex; mode=display">\hat{y} = \arg \max_i \sum^{m}_{j=1} w_j \chi_A \big(C_j(\mathbf{x})=i\big),</script>
</p>
<p>where <script type="math/tex">\chi_A</script> is the characteristic function <script type="math/tex">[C_j(\mathbf{x}) = i \; \in A]</script>, and <script type="math/tex">A</script> is the set of unique class labels. </p>
<p>Continuing with the example from the previous section</p>
<ul>
<li>classifier 1 -&gt; class 0</li>
<li>classifier 2 -&gt; class 0</li>
<li>classifier 3 -&gt; class 1</li>
</ul>
<p>assigning the weights {0.2, 0.2, 0.6} would yield a prediction <script type="math/tex">\hat{y} = 1</script>:</p>
<p>
<script type="math/tex; mode=display">\arg \max_i [0.2 \times i_0 + 0.2 \times i_0 + 0.6 \times i_1] = 1</script>
</p>
<h3 id="soft-voting">Soft Voting</h3>
<p>In soft voting, we predict the class labels based on the predicted probabilities <script type="math/tex">p</script> for classifier -- this approach is only recommended if the classifiers are well-calibrated.</p>
<p>
<script type="math/tex; mode=display">\hat{y} = \arg \max_i \sum^{m}_{j=1} w_j p_{ij},</script>
</p>
<p>where <script type="math/tex">w_j</script> is the weight that can be assigned to the <script type="math/tex">j</script>th classifier.</p>
<p>Assuming the example in the previous section was a binary classification task with class labels <script type="math/tex">i \in \{0, 1\}</script>, our ensemble could make the following prediction:</p>
<ul>
<li>
<script type="math/tex">C_1(\mathbf{x}) \rightarrow [0.9, 0.1]</script>
</li>
<li>
<script type="math/tex">C_2(\mathbf{x}) \rightarrow [0.8, 0.2]</script>
</li>
<li>
<script type="math/tex">C_3(\mathbf{x}) \rightarrow [0.4, 0.6]</script>
</li>
</ul>
<p>Using uniform weights, we compute the average probabilities:</p>
<p>
<script type="math/tex; mode=display">p(i_0 \mid \mathbf{x}) = \frac{0.9 + 0.8 + 0.4}{3} = 0.7 \\\\
p(i_1 \mid \mathbf{x}) = \frac{0.1 + 0.2 + 0.6}{3} = 0.3</script>
</p>
<p>
<script type="math/tex; mode=display">\hat{y} = \arg \max_i \big[p(i_0 \mid \mathbf{x}), p(i_1 \mid \mathbf{x}) \big] = 0</script>
</p>
<p>However, assigning the weights {0.1, 0.1, 0.8} would yield a prediction <script type="math/tex">\hat{y} = 1</script>:</p>
<p>
<script type="math/tex; mode=display">p(i_0 \mid \mathbf{x}) = {0.1 \times 0.9 + 0.1 \times 0.8 + 0.8 \times  0.4} = 0.49 \\\\
p(i_1 \mid \mathbf{x}) = {0.1 \times 0.1 + 0.2 \times 0.1 + 0.8 \times 0.6} = 0.51</script>
</p>
<p>
<script type="math/tex; mode=display">\hat{y} = \arg \max_i \big[p(i_0 \mid \mathbf{x}), p(i_1 \mid \mathbf{x}) \big] = 1</script>
</p>
<h3 id="references">References</h3>
<ul>
<li>[1] S. Raschka. <a href="https://github.com/rasbt/python-machine-learning-book">Python Machine Learning</a>. Packt Publishing Ltd., 2015.</li>
</ul>
<h2 id="example-1-classifying-iris-flowers-using-different-classification-models">Example 1 -  Classifying Iris Flowers Using Different Classification Models</h2>
<pre><code class="language-python">from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target
</code></pre>
<pre><code class="language-python">from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
import numpy as np

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()

print('5-fold cross validation:\n')

labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes']

for clf, label in zip([clf1, clf2, clf3], labels):

    scores = model_selection.cross_val_score(clf, X, y, 
                                              cv=5, 
                                              scoring='accuracy')
    print(&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot;
          % (scores.mean(), scores.std(), label))
</code></pre>
<pre><code>5-fold cross validation:

Accuracy: 0.95 (+/- 0.04) [Logistic Regression]
Accuracy: 0.94 (+/- 0.04) [Random Forest]
Accuracy: 0.91 (+/- 0.04) [Naive Bayes]
</code></pre>
<pre><code class="language-python">from mlxtend.classifier import EnsembleVoteClassifier

eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1])

labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']
for clf, label in zip([clf1, clf2, clf3, eclf], labels):

    scores = model_selection.cross_val_score(clf, X, y, 
                                              cv=5, 
                                              scoring='accuracy')
    print(&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot; 
          % (scores.mean(), scores.std(), label))
</code></pre>
<pre><code>Accuracy: 0.95 (+/- 0.04) [Logistic Regression]
Accuracy: 0.94 (+/- 0.04) [Random Forest]
Accuracy: 0.91 (+/- 0.04) [Naive Bayes]
Accuracy: 0.95 (+/- 0.04) [Ensemble]
</code></pre>
<h4 id="plotting-decision-regions">Plotting Decision Regions</h4>
<pre><code class="language-python">import matplotlib.pyplot as plt
from mlxtend.plotting import plot_decision_regions
import matplotlib.gridspec as gridspec
import itertools

gs = gridspec.GridSpec(2, 2)

fig = plt.figure(figsize=(10,8))

labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']
for clf, lab, grd in zip([clf1, clf2, clf3, eclf],
                         labels,
                         itertools.product([0, 1], repeat=2)):

    clf.fit(X, y)
    ax = plt.subplot(gs[grd[0], grd[1]])
    fig = plot_decision_regions(X=X, y=y, clf=clf)
    plt.title(lab)
</code></pre>
<p><img alt="png" src="../EnsembleVoteClassifier_files/EnsembleVoteClassifier_24_0.png" /></p>
<h2 id="example-2-grid-search">Example 2 - Grid Search</h2>
<pre><code class="language-python">from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target
</code></pre>
<pre><code class="language-python">%%capture --no-display

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
from mlxtend.classifier import EnsembleVoteClassifier

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()
eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='soft')

params = {'logisticregression__C': [1.0, 100.0],
          'randomforestclassifier__n_estimators': [20, 200],}

grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)
grid.fit(iris.data, iris.target)

cv_keys = ('mean_test_score', 'std_test_score', 'params')

for r, _ in enumerate(grid.cv_results_['mean_test_score']):
    print(&quot;%0.3f +/- %0.2f %r&quot;
          % (grid.cv_results_[cv_keys[0]][r],
             grid.cv_results_[cv_keys[1]][r] / 2.0,
             grid.cv_results_[cv_keys[2]][r]))
</code></pre>
<p><strong>Note</strong>: If the <code>EnsembleClassifier</code> is initialized with multiple similar estimator objects, the estimator names are modified with consecutive integer indices, for example:</p>
<pre><code class="language-python">%%capture --no-display

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
eclf = EnsembleVoteClassifier(clfs=[clf1, clf1, clf2], 
                              voting='soft')

params = {'logisticregression-1__C': [1.0, 100.0],
          'logisticregression-2__C': [1.0, 100.0],
          'randomforestclassifier__n_estimators': [20, 200],}

grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)
grid = grid.fit(iris.data, iris.target)
</code></pre>
<p><strong>Note</strong></p>
<p>The <code>EnsembleVoteClass</code> also enables grid search over the <code>clfs</code> argument. However, due to the current implementation of <code>GridSearchCV</code> in scikit-learn, it is not possible to search over both, differenct classifiers and classifier parameters at the same time. For instance, while the following parameter dictionary works</p>
<pre><code>params = {'randomforestclassifier__n_estimators': [1, 100],
'clfs': [(clf1, clf1, clf1), (clf2, clf3)]}
</code></pre>
<p>it will use the instance settings of <code>clf1</code>, <code>clf2</code>, and <code>clf3</code> and not overwrite it with the <code>'n_estimators'</code> settings from <code>'randomforestclassifier__n_estimators': [1, 100]</code>.</p>
<h2 id="example-3-majority-voting-with-classifiers-trained-on-different-feature-subsets">Example 3 - Majority voting with classifiers trained on different feature subsets</h2>
<p>Feature selection algorithms implemented in scikit-learn as well as the <code>SequentialFeatureSelector</code> implement a <code>transform</code> method that passes the reduced feature subset to the next item in a <code>Pipeline</code>.</p>
<p>For example, the method</p>
<pre><code>def transform(self, X):
    return X[:, self.k_feature_idx_]
</code></pre>
<p>returns the best feature columns, <code>k_feature_idx_</code>, given a dataset X.</p>
<p>Thus, we simply need to construct a <code>Pipeline</code> consisting of the feature selector and the classifier in order to select different feature subsets for different algorithms. During <code>fitting</code>, the optimal feature subsets are automatically determined via the <code>GridSearchCV</code> object, and by calling <code>predict</code>, the fitted feature selector in the pipeline only passes these columns along, which resulted in the best performance for the respective classifier.</p>
<pre><code class="language-python">%%capture --no-display

from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, :], iris.target

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
from mlxtend.classifier import EnsembleVoteClassifier
from sklearn.pipeline import Pipeline
from mlxtend.feature_selection import SequentialFeatureSelector

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()

# Creating a feature-selection-classifier pipeline

sfs1 = SequentialFeatureSelector(clf1, 
                                 k_features=4,
                                 forward=True, 
                                 floating=False, 
                                 scoring='accuracy',
                                 verbose=0,
                                 cv=0)

clf1_pipe = Pipeline([('sfs', sfs1),
                      ('logreg', clf1)])

eclf = EnsembleVoteClassifier(clfs=[clf1_pipe, clf2, clf3], 
                              voting='soft')


params = {'pipeline__sfs__k_features': [1, 2, 3],
          'pipeline__logreg__C': [1.0, 100.0],
          'randomforestclassifier__n_estimators': [20, 200]}

grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)
grid.fit(iris.data, iris.target)



cv_keys = ('mean_test_score', 'std_test_score', 'params')

for r, _ in enumerate(grid.cv_results_['mean_test_score']):
    print(&quot;%0.3f +/- %0.2f %r&quot;
          % (grid.cv_results_[cv_keys[0]][r],
             grid.cv_results_[cv_keys[1]][r] / 2.0,
             grid.cv_results_[cv_keys[2]][r]))
</code></pre>
<p>The best parameters determined via GridSearch are:</p>
<pre><code class="language-python">grid.best_params_
</code></pre>
<pre><code>{'pipeline__logreg__C': 1.0,
 'pipeline__sfs__k_features': 2,
 'randomforestclassifier__n_estimators': 200}
</code></pre>
<p>Now, we assign these parameters to the ensemble voting classifier, fit the models on the complete training set, and perform a prediction on 3 samples from the Iris dataset.</p>
<pre><code class="language-python">eclf = eclf.set_params(**grid.best_params_)
eclf.fit(X, y).predict(X[[1, 51, 149]])
</code></pre>
<pre><code>array([0, 1, 2])
</code></pre>
<h4 id="manual-approach">Manual Approach</h4>
<p>Alternatively, we can select different columns "manually" using the <code>ColumnSelector</code> object. In this example, we select only the first (sepal length) and third (petal length) column for the logistic regression classifier (<code>clf1</code>).</p>
<pre><code class="language-python">from mlxtend.feature_selection import ColumnSelector


col_sel = ColumnSelector(cols=[0, 2])

clf1_pipe = Pipeline([('sel', col_sel),
                      ('logreg', clf1)])

eclf = EnsembleVoteClassifier(clfs=[clf1_pipe, clf2, clf3],
                              voting='soft')
eclf.fit(X, y).predict(X[[1, 51, 149]])
</code></pre>
<pre><code>array([0, 1, 2])
</code></pre>
<p>Furthermore, we can fit the <code>SequentialFeatureSelector</code> separately, outside the grid search hyperparameter optimization pipeline. Here, we determine the best features first, and then we construct a pipeline using these "fixed," best features as seed for the <code>ColumnSelector</code>:</p>
<pre><code class="language-python">sfs1 = SequentialFeatureSelector(clf1, 
                                 k_features=2,
                                 forward=True, 
                                 floating=False, 
                                 scoring='accuracy',
                                 verbose=1,
                                 cv=0)

sfs1.fit(X, y)

print('Best features', sfs1.k_feature_idx_)

col_sel = ColumnSelector(cols=sfs1.k_feature_idx_)

clf1_pipe = Pipeline([('sel', col_sel),
                      ('logreg', clf1)])
</code></pre>
<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished
Features: 1/2[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
Features: 2/2

Best features (2, 3)
</code></pre>
<pre><code class="language-python">eclf = EnsembleVoteClassifier(clfs=[clf1_pipe, clf2, clf3], 
                              voting='soft')
eclf.fit(X, y).predict(X[[1, 51, 149]])
</code></pre>
<pre><code>array([0, 1, 2])
</code></pre>
<h2 id="example-5-using-pre-fitted-classifiers">Example 5 - Using Pre-fitted Classifiers</h2>
<pre><code class="language-python">from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target
</code></pre>
<p>Assume that we previously fitted our classifiers:</p>
<pre><code class="language-python">from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
import numpy as np

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()

for clf in (clf1, clf2, clf3):
    clf.fit(X, y)
</code></pre>
<p>By setting <code>fit_base_estimators=False</code>, it will enforce <code>use_clones</code> to be False and the <code>EnsembleVoteClassifier</code> will not re-fit these classifers to save computational time:</p>
<pre><code class="language-python">from mlxtend.classifier import EnsembleVoteClassifier
import copy
eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1], fit_base_estimators=False)

labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']

eclf.fit(X, y)

print('accuracy:', np.mean(y == eclf.predict(X)))
</code></pre>
<pre><code>accuracy: 0.96


/Users/sebastian/miniforge3/lib/python3.9/site-packages/mlxtend/classifier/ensemble_vote.py:166: UserWarning: fit_base_estimators=False enforces use_clones to be `False`
  warnings.warn("fit_base_estimators=False "
</code></pre>
<p>However, please note that <code>fit_base_estimators=False</code> is incompatible to any form of cross-validation that is done in e.g., <code>model_selection.cross_val_score</code> or <code>model_selection.GridSearchCV</code>, etc., since it would require the classifiers to be refit to the training folds. Thus, only use <code>fit_base_estimators=False</code> if you want to make a prediction directly without cross-validation.</p>
<h2 id="example-6-ensembles-of-classifiers-that-operate-on-different-feature-subsets">Example 6 - Ensembles of Classifiers that Operate on Different Feature Subsets</h2>
<p>If desired, the different classifiers can be fit to different subsets of features in the training dataset. The following example illustrates how this can be done on a technical level using scikit-learn pipelines and the <code>ColumnSelector</code>:</p>
<pre><code class="language-python">from sklearn.datasets import load_iris
from mlxtend.classifier import EnsembleVoteClassifier
from mlxtend.feature_selection import ColumnSelector
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression

iris = load_iris()
X = iris.data
y = iris.target

pipe1 = make_pipeline(ColumnSelector(cols=(0, 2)),
                      LogisticRegression())
pipe2 = make_pipeline(ColumnSelector(cols=(1, 2, 3)),
                      LogisticRegression())

eclf = EnsembleVoteClassifier(clfs=[pipe1, pipe2])

eclf.fit(X, y)
</code></pre>
<pre><code>EnsembleVoteClassifier(clfs=[Pipeline(steps=[('columnselector',
                                              ColumnSelector(cols=(0, 2))),
                                             ('logisticregression',
                                              LogisticRegression())]),
                             Pipeline(steps=[('columnselector',
                                              ColumnSelector(cols=(1, 2, 3))),
                                             ('logisticregression',
                                              LogisticRegression())])])
</code></pre>
<h2 id="example-7-a-note-about-scikit-learn-svms-and-soft-voting">Example 7 - A Note about Scikit-Learn SVMs and Soft Voting</h2>
<p>This section provides some additional technical insights in how probabilities are used when <code>voting='soft'</code>. </p>
<p>Note that scikit-learn estimates the probabilities for SVMs (more info here: http://scikit-learn.org/stable/modules/svm.html#scores-probabilities) in a way that these may not be consistent with the class labels that the SVM predicts. This is an extreme example, but let's say we have a dataset with 3 class labels, 0, 1, and 2. For a given training example, the SVM classifier may predict class 2. However, the class-membership probabilities may look as follows:</p>
<ul>
<li>class 0: 99%</li>
<li>class 1: 0.5%</li>
<li>class 2: 0.5%</li>
</ul>
<p>A practical example of this scenario is shown below:</p>
<pre><code class="language-python">import numpy as np
from mlxtend.classifier import EnsembleVoteClassifier
from sklearn.svm import SVC
from sklearn.datasets import load_iris

iris = load_iris()
X, y = iris.data, iris.target

clf2 = SVC(probability=True, random_state=4)
clf2.fit(X, y)
eclf = EnsembleVoteClassifier(clfs=[clf2], voting='soft', fit_base_estimators=False)
eclf.fit(X, y)

for svm_class, e_class, svm_prob, e_prob, in zip(clf2.predict(X),
                                                 eclf.predict(X),
                                                 clf2.predict_proba(X),
                                                 eclf.predict_proba(X)):
    if svm_class != e_class:
        print('============')
        print('Probas from SVM            :', svm_prob)
        print('Class from SVM             :', svm_class)
        print('Probas from SVM in Ensemble:', e_prob)
        print('Class from SVM in Ensemble :', e_class)
        print('============')
</code></pre>
<pre><code>============
Probas from SVM            : [0.00921708 0.49415165 0.49663127]
Class from SVM             : 1
Probas from SVM in Ensemble: [0.00921708 0.49415165 0.49663127]
Class from SVM in Ensemble : 2
============


/Users/sebastian/miniforge3/lib/python3.9/site-packages/mlxtend/classifier/ensemble_vote.py:166: UserWarning: fit_base_estimators=False enforces use_clones to be `False`
  warnings.warn("fit_base_estimators=False "
</code></pre>
<h2 id="example-7-a-note-about-scikit-learn-svms-and-soft-voting_1">Example 7 - A Note about Scikit-Learn SVMs and Soft Voting</h2>
<p>Based on the probabilities, we would expect the SVM to predict class 2, because it has the highest probability. Since the <code>EnsembleVoteClassifier</code> uses the <code>argmax</code> function internally if <code>voting='soft'</code>, it would indeed predict class 2 in this case even if the ensemble consists of only one SVM model.</p>
<p>Note that in practice, this minor technical detail does not need to concern you, but it is useful to keep it in mind in case you are wondering about results from a 1-model SVM ensemble compared to that SVM alone -- this is not a bug.</p>
<h2 id="example-8-optimizing-ensemble-weights-with-nelder-mead">Example 8 - Optimizing Ensemble Weights with Nelder-Mead</h2>
<p>In this section, we will see how we can use a heuristic search method like <a href="https://en.wikipedia.org/wiki/NelderMead_method">Nelder-Mead</a> for optimizing the ensemble weights.</p>
<p>Suppose we have the following example scenario where we fit 3 individual classifiers on different subsets of the training dataset:</p>
<pre><code class="language-python">from mlxtend.classifier import EnsembleVoteClassifier
from mlxtend.data import mnist_data
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier

X, y = mnist_data()

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.5, shuffle=True, random_state=1
)

clf1 = GaussianNB()
clf2 = LogisticRegression(random_state=123, solver='newton-cg')
clf3 = DecisionTreeClassifier(random_state=123, max_depth=2)

clf1.fit(X_train[500:1000], y_train[500:1000])
clf2.fit(X_train[750:1250], y_train[750:1250])
clf3.fit(X_train[1250:2000], y_train[1250:2000]);
</code></pre>
<p>Then, we construct the an ensemble classifier from these 3 classifiers where each classifier contributes equally with weight 1:</p>
<pre><code class="language-python">eclf = EnsembleVoteClassifier(
    clfs=(clf1, clf2, clf3),
    voting=&quot;soft&quot;,  # the same would also work with &quot;hard&quot; voting
    weights=(1, 1, 1),
    use_clones=False,
    fit_base_estimators=False,
)
eclf.fit(X_train, y_train)
eclf.score(X_val, y_val)
</code></pre>
<pre><code>/Users/sebastian/miniforge3/lib/python3.9/site-packages/mlxtend/classifier/ensemble_vote.py:166: UserWarning: fit_base_estimators=False enforces use_clones to be `False`
  warnings.warn("fit_base_estimators=False "





0.8012
</code></pre>
<p>We see that we reach 80% accuracy on the validation set. Can we do better? Maybe they indvidual classifiers shouldn't be contributing equally. Perhaps, we can use an optimization algorothm from <code>scipy.optimize</code> to find a better relative weighting of these individual classifiers.</p>
<p>Let's set up an objective function that we want to minimize via SciPy's <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code>minimize</code></a>:</p>
<pre><code class="language-python">from scipy.optimize import minimize


def function_to_minimize(weights, fitted_clfs):

    w1, w2 = weights  # these are the new weights!

    newclf = EnsembleVoteClassifier(
        voting=&quot;soft&quot;,
        use_clones=False,
        fit_base_estimators=False,
        clfs=fitted_clfs,
        weights=(w1, w2, 1.),  # use the new weights
    )

    newclf.fit(X_train, y_train)
    score = newclf.score(X_val, y_val)

    # change accuracy to error so that smaller is better
    score_to_minimize = 1 - score

    return score_to_minimize
</code></pre>
<p>Note a few things:</p>
<ol>
<li>
<p>We only optimize 2 out of the 3 classifier weigths. That's because the weighting is relative to each other, and it would be overkill (and too many degrees of freedom) to also optimize weight 3.</p>
</li>
<li>
<p>We set <code>use_clones=False &amp; fit_base_estimators=False</code> as before, this is to make sure that we use the prefit classifiers in the ensemble classifier.</p>
</li>
<li>
<p>Instead of optimizing the accuracy, we optimize the the classification error, <code>score_to_minimize = 1 - score</code>. That's because we use the <code>minimize</code> function where lower means better.</p>
</li>
</ol>
<p>Next, let's choose some initial weight values and run the optimization. Via the <code>bounds</code> we specify the range (lower and upper value) for each weight so that the search doesn't go crazy:</p>
<pre><code class="language-python">%%capture --no-display

init_weights = [1., 1.]

results = minimize(
    function_to_minimize,
    init_weights,
    args=((clf1, clf2, clf3),),
    bounds=((0, 5), (0, 5)),
    method=&quot;nelder-mead&quot;,
)
</code></pre>
<p>Let's look at the results!</p>
<pre><code class="language-python">print(results)
</code></pre>
<pre><code> final_simplex: (array([[0.575     , 1.40625   ],
       [0.57500153, 1.40622215],
       [0.57508965, 1.40617647]]), array([0.1324, 0.1324, 0.1324]))
           fun: 0.13239999999999996
       message: 'Optimization terminated successfully.'
          nfev: 60
           nit: 21
        status: 0
       success: True
             x: array([0.575  , 1.40625])
</code></pre>
<p>It looks like the search was successful and returned the following weights:</p>
<pre><code class="language-python">solution = results[&quot;x&quot;]
print(solution)
</code></pre>
<pre><code>[0.575   1.40625]
</code></pre>
<p>Let's use these new weights in our ensemble classifier:</p>
<pre><code class="language-python">eclf = EnsembleVoteClassifier(
    clfs=(clf1, clf2, clf3),
    voting=&quot;soft&quot;,
    weights=(solution[0], solution[1], 1),
    use_clones=False,
    fit_base_estimators=False,
)

eclf.fit(X_train, y_train)
eclf.score(X_val, y_val)
</code></pre>
<pre><code>/Users/sebastian/miniforge3/lib/python3.9/site-packages/mlxtend/classifier/ensemble_vote.py:166: UserWarning: fit_base_estimators=False enforces use_clones to be `False`
  warnings.warn("fit_base_estimators=False "





0.8676
</code></pre>
<p>As we can see, the results on the validation set (0.8676) improved compared to the original ones (0.8012). Yay!</p>
<h1 id="api">API</h1>
<p><em>EnsembleVoteClassifier(clfs, voting='hard', weights=None, verbose=0, use_clones=True, fit_base_estimators=True)</em></p>
<p>Soft Voting/Majority Rule classifier for scikit-learn estimators.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>clfs</code> : array-like, shape = [n_classifiers]</p>
<p>A list of classifiers.
Invoking the <code>fit</code> method on the <code>VotingClassifier</code> will fit clones
of those original classifiers
be stored in the class attribute
if <code>use_clones=True</code> (default) and
<code>fit_base_estimators=True</code> (default).</p>
</li>
<li>
<p><code>voting</code> : str, {'hard', 'soft'} (default='hard')</p>
<p>If 'hard', uses predicted class labels for majority rule voting.
Else if 'soft', predicts the class label based on the argmax of
the sums of the predicted probalities, which is recommended for
an ensemble of well-calibrated classifiers.</p>
</li>
<li>
<p><code>weights</code> : array-like, shape = [n_classifiers], optional (default=<code>None</code>)</p>
<p>Sequence of weights (<code>float</code> or <code>int</code>) to weight the occurances of
predicted class labels (<code>hard</code> voting) or class probabilities
before averaging (<code>soft</code> voting). Uses uniform weights if <code>None</code>.</p>
</li>
<li>
<p><code>verbose</code> : int, optional (default=0)</p>
<p>Controls the verbosity of the building process.
- <code>verbose=0</code> (default): Prints nothing
- <code>verbose=1</code>: Prints the number &amp; name of the clf being fitted
- <code>verbose=2</code>: Prints info about the parameters of the clf being fitted
- <code>verbose&gt;2</code>: Changes <code>verbose</code> param of the underlying clf to
self.verbose - 2</p>
</li>
<li>
<p><code>use_clones</code> : bool (default: True)</p>
<p>Clones the classifiers for stacking classification if True (default)
or else uses the original ones, which will be refitted on the dataset
upon calling the <code>fit</code> method. Hence, if use_clones=True, the original
input classifiers will remain unmodified upon using the
StackingClassifier's <code>fit</code> method.
Setting <code>use_clones=False</code> is
recommended if you are working with estimators that are supporting
the scikit-learn fit/predict API interface but are not compatible
to scikit-learn's <code>clone</code> function.</p>
</li>
<li>
<p><code>fit_base_estimators</code> : bool (default: True)</p>
<p>Refits classifiers in <code>clfs</code> if True; uses references to the <code>clfs</code>,
otherwise (assumes that the classifiers were already fit).
Note: fit_base_estimators=False will enforce use_clones to be False,
and is incompatible to most scikit-learn wrappers!
For instance, if any form of cross-validation is performed
this would require the re-fitting classifiers to training folds, which
would raise a NotFitterError if fit_base_estimators=False.
(New in mlxtend v0.6.)</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>classes_</code> : array-like, shape = [n_predictions]</p>
</li>
<li>
<p><code>clf</code> : array-like, shape = [n_predictions]</p>
<p>The input classifiers; may be overwritten if <code>use_clones=False</code></p>
</li>
<li>
<p><code>clf_</code> : array-like, shape = [n_predictions]</p>
<p>Fitted input classifiers; clones if <code>use_clones=True</code></p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>```
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.naive_bayes import GaussianNB
&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier
&gt;&gt;&gt; from mlxtend.sklearn import EnsembleVoteClassifier
&gt;&gt;&gt; clf1 = LogisticRegression(random_seed=1)
&gt;&gt;&gt; clf2 = RandomForestClassifier(random_seed=1)
&gt;&gt;&gt; clf3 = GaussianNB()
&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
&gt;&gt;&gt; y = np.array([1, 1, 1, 2, 2, 2])
&gt;&gt;&gt; eclf1 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3],
... voting='hard', verbose=1)
&gt;&gt;&gt; eclf1 = eclf1.fit(X, y)
&gt;&gt;&gt; print(eclf1.predict(X))
[1 1 1 2 2 2]
&gt;&gt;&gt; eclf2 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='soft')
&gt;&gt;&gt; eclf2 = eclf2.fit(X, y)
&gt;&gt;&gt; print(eclf2.predict(X))
[1 1 1 2 2 2]
&gt;&gt;&gt; eclf3 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3],
...                          voting='soft', weights=[2,1,1])
&gt;&gt;&gt; eclf3 = eclf3.fit(X, y)
&gt;&gt;&gt; print(eclf3.predict(X))
[1 1 1 2 2 2]
&gt;&gt;&gt;

For more usage examples, please see
http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/
</code></pre>
<p>```</p>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y, sample_weight=None)</em></p>
<p>Learn weight coefficients from training data for each classifier.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>sample_weight</code> : array-like, shape = [n_samples], optional</p>
<p>Sample weights passed as sample_weights to each regressor
in the regressors list as well as the meta_regressor.
Raises error if some regressor does not support
sample_weight in the fit() method.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<pre><code>Fits transformer to `X` and `y` with optional parameters `fit_params`
and returns a transformed version of `X`.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like of shape (n_samples, n_features)</p>
<p>Input samples.</p>
</li>
<li>
<p><code>y</code> :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None</p>
<p>Target values (None for unsupervised transformations).</p>
</li>
<li>
<p><code>**fit_params</code> : dict</p>
<p>Additional fit parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : ndarray array of shape (n_samples, n_features_new)</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Return estimator parameter names for GridSearch support.</p>
<hr>

<p><em>predict(X)</em></p>
<p>Predict class labels for X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>maj</code> : array-like, shape = [n_samples]</p>
<p>Predicted class labels.</p>
</li>
</ul>
<hr>

<p><em>predict_proba(X)</em></p>
<p>Predict class probabilities for X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>avg</code> : array-like, shape = [n_samples, n_classes]</p>
<p>Weighted average probability for each class per sample.</p>
</li>
</ul>
<hr>

<p><em>score(X, y, sample_weight=None)</em></p>
<p>Return the mean accuracy on the given test data and labels.</p>
<pre><code>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like of shape (n_samples, n_features)</p>
<p>Test samples.</p>
</li>
<li>
<p><code>y</code> : array-like of shape (n_samples,) or (n_samples, n_outputs)</p>
<p>True labels for <code>X</code>.</p>
</li>
<li>
<p><code>sample_weight</code> : array-like of shape (n_samples,), default=None</p>
<p>Sample weights.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>score</code> : float</p>
<p>Mean accuracy of <code>self.predict(X)</code> wrt. <code>y</code>.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<pre><code>The method works on simple estimators as well as on nested objects
(such as :class:`~sklearn.pipeline.Pipeline`). The latter have
parameters of the form ``&lt;component&gt;__&lt;parameter&gt;`` so that it's
possible to update each component of a nested object.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>**params</code> : dict</p>
<p>Estimator parameters.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>self</code> : estimator instance</p>
<p>Estimator instance.</p>
</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Return class labels or probabilities for X for each estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>If</code>voting='soft'`` : array-like = [n_classifiers, n_samples, n_classes]</p>
<p>Class probabilties calculated by each classifier.</p>
</li>
<li>
<p><code>If</code>voting='hard'`` : array-like = [n_classifiers, n_samples]</p>
<p>Class labels predicted by each classifier.</p>
</li>
</ul>
<p>ython</p></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2020 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>
    <script src="../../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
