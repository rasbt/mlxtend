<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Sebastian Raschka">
        <link rel="canonical" href="https://rasbt.github.io/mlxtend/user_guide/feature_extraction/RBFKernelPCA/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>RBFKernelPCA - mlxtend</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/color-brewer.min.css">
        <link href="../../../cinder/css/base.css" rel="stylesheet">
        <link href="../../../cinder/css/bootstrap-custom.css" rel="stylesheet">
        <link href="../../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../../cinder/css/cinder.css" rel="stylesheet">
        <link href="../../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../../../cinder/css/highlight.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', "UA-38457794-2", "rasbt.github.io/mlxtend/");
            ga('send', 'pageview');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../..">mlxtend</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../../.." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../USER_GUIDE_INDEX/" class="dropdown-item">User Guide Index</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">classifier</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../classifier/Adaline/" class="dropdown-item">Adaline: Adaptive Linear Neuron Classifier</a>
</li>
            
<li>
    <a href="../../classifier/EnsembleVoteClassifier/" class="dropdown-item">EnsembleVoteClassifier: A majority voting classifier</a>
</li>
            
<li>
    <a href="../../classifier/LogisticRegression/" class="dropdown-item">LogisticRegression: A binary classifier</a>
</li>
            
<li>
    <a href="../../classifier/MultiLayerPerceptron/" class="dropdown-item">MultilayerPerceptron: A simple multilayer neural network</a>
</li>
            
<li>
    <a href="../../classifier/OneRClassifier/" class="dropdown-item">OneRClassifier: One Rule (OneR) method for classification</a>
</li>
            
<li>
    <a href="../../classifier/Perceptron/" class="dropdown-item">Perceptron: A simple binary classifier</a>
</li>
            
<li>
    <a href="../../classifier/SoftmaxRegression/" class="dropdown-item">SoftmaxRegression: Multiclass version of logistic regression</a>
</li>
            
<li>
    <a href="../../classifier/StackingClassifier/" class="dropdown-item">StackingClassifier: Simple stacking</a>
</li>
            
<li>
    <a href="../../classifier/StackingCVClassifier/" class="dropdown-item">StackingCVClassifier: Stacking with cross-validation</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">cluster</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../cluster/Kmeans/" class="dropdown-item">Kmeans: k-means clustering</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">data</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../data/autompg_data/" class="dropdown-item">autompg_data: The Auto-MPG dataset for regression</a>
</li>
            
<li>
    <a href="../../data/boston_housing_data/" class="dropdown-item">boston_housing_data: The Boston housing dataset for regression</a>
</li>
            
<li>
    <a href="../../data/iris_data/" class="dropdown-item">iris_data: The 3-class iris dataset for classification</a>
</li>
            
<li>
    <a href="../../data/loadlocal_mnist/" class="dropdown-item">loadlocal_mnist: A function for loading MNIST from the original ubyte files</a>
</li>
            
<li>
    <a href="../../data/make_multiplexer_dataset/" class="dropdown-item">make_multiplexer_dataset: A function for creating multiplexer data</a>
</li>
            
<li>
    <a href="../../data/mnist_data/" class="dropdown-item">mnist_data: A subset of the MNIST dataset for classification</a>
</li>
            
<li>
    <a href="../../data/three_blobs_data/" class="dropdown-item">three_blobs_data: The synthetic blobs for classification</a>
</li>
            
<li>
    <a href="../../data/wine_data/" class="dropdown-item">wine_data: A 3-class wine dataset for classification</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">evaluate</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../evaluate/accuracy_score/" class="dropdown-item">accuracy_score: Computing standard, balanced, and per-class accuracy</a>
</li>
            
<li>
    <a href="../../evaluate/bias_variance_decomp/" class="dropdown-item">bias_variance_decomp: Bias-variance decomposition for classification and regression losses</a>
</li>
            
<li>
    <a href="../../evaluate/bootstrap/" class="dropdown-item">bootstrap: The ordinary nonparametric boostrap for arbitrary parameters</a>
</li>
            
<li>
    <a href="../../evaluate/bootstrap_point632_score/" class="dropdown-item">bootstrap_point632_score: The .632 and .632+ boostrap for classifier evaluation</a>
</li>
            
<li>
    <a href="../../evaluate/BootstrapOutOfBag/" class="dropdown-item">BootstrapOutOfBag: A scikit-learn compatible version of the out-of-bag bootstrap</a>
</li>
            
<li>
    <a href="../../evaluate/cochrans_q/" class="dropdown-item">cochrans_q: Cochran's Q test for comparing multiple classifiers</a>
</li>
            
<li>
    <a href="../../evaluate/combined_ftest_5x2cv/" class="dropdown-item">combined_ftest_5x2cv: 5x2cv combined F test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../evaluate/confusion_matrix/" class="dropdown-item">confusion_matrix: creating a confusion matrix for model evaluation</a>
</li>
            
<li>
    <a href="../../evaluate/create_counterfactual/" class="dropdown-item">create_counterfactual: Interpreting models via counterfactuals</a>
</li>
            
<li>
    <a href="../../evaluate/feature_importance_permutation/" class="dropdown-item">feature_importance_permutation: Estimate feature importance via feature permutation.</a>
</li>
            
<li>
    <a href="../../evaluate/ftest/" class="dropdown-item">ftest: F-test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../evaluate/GroupTimeSeriesSplit/" class="dropdown-item">GroupTimeSeriesSplit: A scikit-learn compatible version of the time series validation with groups</a>
</li>
            
<li>
    <a href="../../evaluate/lift_score/" class="dropdown-item">lift_score: Lift score for classification and association rule mining</a>
</li>
            
<li>
    <a href="../../evaluate/mcnemar_table/" class="dropdown-item">mcnemar_table: Contingency table for McNemar's test</a>
</li>
            
<li>
    <a href="../../evaluate/mcnemar_tables/" class="dropdown-item">mcnemar_tables: contingency tables for McNemar's test and Cochran's Q test</a>
</li>
            
<li>
    <a href="../../evaluate/mcnemar/" class="dropdown-item">mcnemar: McNemar's test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../evaluate/paired_ttest_5x2cv/" class="dropdown-item">paired_ttest_5x2cv: 5x2cv paired t test for classifier comparisons</a>
</li>
            
<li>
    <a href="../../evaluate/paired_ttest_kfold_cv/" class="dropdown-item">paired_ttest_kfold_cv: K-fold cross-validated paired t test</a>
</li>
            
<li>
    <a href="../../evaluate/paired_ttest_resampled/" class="dropdown-item">paired_ttest_resample: Resampled paired t test</a>
</li>
            
<li>
    <a href="../../evaluate/permutation_test/" class="dropdown-item">permutation_test: Permutation test for hypothesis testing</a>
</li>
            
<li>
    <a href="../../evaluate/PredefinedHoldoutSplit/" class="dropdown-item">PredefinedHoldoutSplit: Utility for the holdout method compatible with scikit-learn</a>
</li>
            
<li>
    <a href="../../evaluate/RandomHoldoutSplit/" class="dropdown-item">RandomHoldoutSplit: split a dataset into a train and validation subset for validation</a>
</li>
            
<li>
    <a href="../../evaluate/scoring/" class="dropdown-item">scoring: computing various performance metrics</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">feature_extraction</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../LinearDiscriminantAnalysis/" class="dropdown-item">LinearDiscriminantAnalysis: Linear discriminant analysis for dimensionality reduction</a>
</li>
            
<li>
    <a href="../PrincipalComponentAnalysis/" class="dropdown-item">PrincipalComponentAnalysis: Principal component analysis (PCA) for dimensionality reduction</a>
</li>
            
<li>
    <a href="./" class="dropdown-item active">RBFKernelPCA</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">feature_selection</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../feature_selection/ColumnSelector/" class="dropdown-item">ColumnSelector: Scikit-learn utility function to select specific columns in a pipeline</a>
</li>
            
<li>
    <a href="../../feature_selection/ExhaustiveFeatureSelector/" class="dropdown-item">ExhaustiveFeatureSelector: Optimal feature sets by considering all possible feature combinations</a>
</li>
            
<li>
    <a href="../../feature_selection/SequentialFeatureSelector/" class="dropdown-item">SequentialFeatureSelector: The popular forward and backward feature selection approaches (including floating variants)</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">file_io</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../file_io/find_filegroups/" class="dropdown-item">find_filegroups: Find files that only differ via their file extensions</a>
</li>
            
<li>
    <a href="../../file_io/find_files/" class="dropdown-item">find_files: Find files based on substring matches</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">frequent_patterns</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../frequent_patterns/apriori/" class="dropdown-item">Apriori</a>
</li>
            
<li>
    <a href="../../frequent_patterns/association_rules/" class="dropdown-item">Association rules</a>
</li>
            
<li>
    <a href="../../frequent_patterns/fpgrowth/" class="dropdown-item">Fpgrowth</a>
</li>
            
<li>
    <a href="../../frequent_patterns/fpmax/" class="dropdown-item">Fpmax</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">math</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../math/num_combinations/" class="dropdown-item">num_combinations: combinations for creating subsequences of k elements</a>
</li>
            
<li>
    <a href="../../math/num_permutations/" class="dropdown-item">num_permutations: number of permutations for creating subsequences of k elements</a>
</li>
            
<li>
    <a href="../../math/vectorspace_dimensionality/" class="dropdown-item">vectorspace_dimensionality: compute the number of dimensions that a set of vectors spans</a>
</li>
            
<li>
    <a href="../../math/vectorspace_orthonormalization/" class="dropdown-item">vectorspace_orthonormalization: Converts a set of linearly independent vectors to a set of orthonormal basis vectors</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">plotting</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../plotting/category_scatter/" class="dropdown-item">Scategory_scatter: Create a scatterplot with categories in different colors</a>
</li>
            
<li>
    <a href="../../plotting/checkerboard_plot/" class="dropdown-item">checkerboard_plot: Create a checkerboard plot in matplotlib</a>
</li>
            
<li>
    <a href="../../plotting/plot_pca_correlation_graph/" class="dropdown-item">plot_pca_correlation_graph: plot correlations between original features and principal components</a>
</li>
            
<li>
    <a href="../../plotting/ecdf/" class="dropdown-item">ecdf: Create an empirical cumulative distribution function plot</a>
</li>
            
<li>
    <a href="../../plotting/enrichment_plot/" class="dropdown-item">enrichment_plot: create an enrichment plot for cumulative counts</a>
</li>
            
<li>
    <a href="../../plotting/heatmap/" class="dropdown-item">heatmap: Create a heatmap in matplotlib</a>
</li>
            
<li>
    <a href="../../plotting/plot_confusion_matrix/" class="dropdown-item">plot_confusion_matrix: Visualize confusion matrices</a>
</li>
            
<li>
    <a href="../../plotting/plot_decision_regions/" class="dropdown-item">plot_decision_regions: Visualize the decision regions of a classifier</a>
</li>
            
<li>
    <a href="../../plotting/plot_learning_curves/" class="dropdown-item">plot_learning_curves: Plot learning curves from training and test sets</a>
</li>
            
<li>
    <a href="../../plotting/plot_linear_regression/" class="dropdown-item">plot_linear_regression: A quick way for plotting linear regression fits</a>
</li>
            
<li>
    <a href="../../plotting/plot_sequential_feature_selection/" class="dropdown-item">plot_sequential_feature_selection: Visualize selected feature subset performances from the SequentialFeatureSelector</a>
</li>
            
<li>
    <a href="../../plotting/scatterplotmatrix/" class="dropdown-item">scatterplotmatrix: visualize datasets via a scatter plot matrix</a>
</li>
            
<li>
    <a href="../../plotting/scatter_hist/" class="dropdown-item">scatter_hist: create a scatter histogram plot</a>
</li>
            
<li>
    <a href="../../plotting/stacked_barplot/" class="dropdown-item">stacked_barplot: Plot stacked bar plots in matplotlib</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">preprocessing</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../preprocessing/CopyTransformer/" class="dropdown-item">CopyTransformer: A function that creates a copy of the input array in a scikit-learn pipeline</a>
</li>
            
<li>
    <a href="../../preprocessing/DenseTransformer/" class="dropdown-item">DenseTransformer: Transforms a sparse into a dense NumPy array, e.g., in a scikit-learn pipeline</a>
</li>
            
<li>
    <a href="../../preprocessing/MeanCenterer/" class="dropdown-item">MeanCenterer: column-based mean centering on a NumPy array</a>
</li>
            
<li>
    <a href="../../preprocessing/minmax_scaling/" class="dropdown-item">MinMaxScaling: Min-max scaling fpr pandas DataFrames and NumPy arrays</a>
</li>
            
<li>
    <a href="../../preprocessing/one-hot_encoding/" class="dropdown-item">One hot encoding</a>
</li>
            
<li>
    <a href="../../preprocessing/shuffle_arrays_unison/" class="dropdown-item">shuffle_arrays_unison: shuffle arrays in a consistent fashion</a>
</li>
            
<li>
    <a href="../../preprocessing/standardize/" class="dropdown-item">standardize: A function to standardize columns in a 2D NumPy array</a>
</li>
            
<li>
    <a href="../../preprocessing/TransactionEncoder/" class="dropdown-item">TransactionEncoder</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">regressor</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../regressor/LinearRegression/" class="dropdown-item">LinearRegression: An implementation of ordinary least-squares linear regression</a>
</li>
            
<li>
    <a href="../../regressor/StackingCVRegressor/" class="dropdown-item">StackingCVRegressor: stacking with cross-validation for regression</a>
</li>
            
<li>
    <a href="../../regressor/StackingRegressor/" class="dropdown-item">StackingRegressor: a simple stacking implementation for regression</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">text</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../text/generalize_names/" class="dropdown-item">generalize_names: convert names into a generalized format</a>
</li>
            
<li>
    <a href="../../text/generalize_names_duplcheck/" class="dropdown-item">generalize_names_duplcheck: Generalize names while preventing duplicates among different names</a>
</li>
            
<li>
    <a href="../../text/tokenizer/" class="dropdown-item">tokenizer_emoticons: tokenizers for emoticons</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">utils</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../utils/Counter/" class="dropdown-item">Counter: A simple progress counter</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.classifier/" class="dropdown-item">Mlxtend.classifier</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.cluster/" class="dropdown-item">Mlxtend.cluster</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.data/" class="dropdown-item">Mlxtend.data</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.evaluate/" class="dropdown-item">Mlxtend.evaluate</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.feature_extraction/" class="dropdown-item">Mlxtend.feature extraction</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.feature_selection/" class="dropdown-item">Mlxtend.feature selection</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.file_io/" class="dropdown-item">Mlxtend.file io</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.frequent_patterns/" class="dropdown-item">Mlxtend.frequent patterns</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.plotting/" class="dropdown-item">Mlxtend.plotting</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.preprocessing/" class="dropdown-item">Mlxtend.preprocessing</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.regressor/" class="dropdown-item">Mlxtend.regressor</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.text/" class="dropdown-item">Mlxtend.text</a>
</li>
                                    
<li>
    <a href="../../../api_subpackages/mlxtend.utils/" class="dropdown-item">Mlxtend.utils</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="../../../installation/" class="nav-link">Installation</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../CHANGELOG/" class="dropdown-item">Release Notes</a>
</li>
                                    
<li>
    <a href="../../../Code-of-Conduct/" class="dropdown-item">Code of Conduct</a>
</li>
                                    
<li>
    <a href="../../../CONTRIBUTING/" class="dropdown-item">How To Contribute</a>
</li>
                                    
<li>
    <a href="../../../contributors/" class="dropdown-item">Contributors</a>
</li>
                                    
<li>
    <a href="../../../license/" class="dropdown-item">License</a>
</li>
                                    
<li>
    <a href="../../../cite/" class="dropdown-item">Citing Mlxtend</a>
</li>
                                    
<li>
    <a href="../../../discuss/" class="dropdown-item">Discuss</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../PrincipalComponentAnalysis/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../../feature_selection/ColumnSelector/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/rasbt/mlxtend/tree/master/docs/sources/user_guide/feature_extraction/RBFKernelPCA.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#rbfkernelpca-rbf-kernel-principal-component-analysis" class="nav-link">RBFKernelPCA: RBF kernel principal component analysis</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#overview" class="nav-link">Overview</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#example-1-half-moon-shapes" class="nav-link">Example 1 - Half-moon shapes</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#example-2-concentric-circles" class="nav-link">Example 2 - Concentric circles</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#api" class="nav-link">API</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h2 id="rbfkernelpca-rbf-kernel-principal-component-analysis">RBFKernelPCA: RBF kernel principal component analysis</h2>
<p>Implementation of RBF Kernel Principal Component Analysis for non-linear dimensionality reduction</p>
<blockquote>
<p>from mlxtend.feature_extraction import RBFKernelPCA</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p>Most machine learning algorithms have been developed and statistically validated for linearly separable data. Popular examples are linear classifiers like Support Vector Machines (SVMs) or the (standard) Principal Component Analysis (PCA) for dimensionality reduction. However, most real world data requires nonlinear methods in order to perform tasks that involve the analysis and discovery of patterns successfully.</p>
<p>The focus of this overview is to briefly introduce the idea of kernel methods and to implement a Gaussian radius basis function (RBF) kernel that is used to perform nonlinear dimensionality reduction via BF kernel principal component analysis (kPCA).</p>
<h3 id="principal-component-analysis">Principal Component Analysis</h3>
<p>The main purpose of principal component analysis (PCA) is the analysis of data to identify patterns that represent the data “well.” The principal components can be understood as new axes of the dataset that maximize the variance along those axes (the eigenvectors of the covariance matrix). In other words, PCA aims to find the axes with maximum variances along which the data is most spread.</p>
<p><img alt="" src="../RBFKernelPCA_files/pca_1.png" /></p>
<p>For more details, please see the related article on <a href="../PrincipalComponentAnalysis/"><code>mlxtend.feature_extraction.PrincipalComponentAnalysis</code></a>.</p>
<h3 id="nonlinear-dimensionality-reduction">Nonlinear dimensionality reduction</h3>
<p>The “classic” PCA approach described above is a linear projection technique that works well if the data is linearly separable. However, in the case of linearly inseparable data, a nonlinear technique is required if the task is to reduce the dimensionality of a dataset.</p>
<p><img alt="" src="../RBFKernelPCA_files/linear_vs_nonlinear.png" /></p>
<h3 id="kernel-functions-and-the-kernel-trick">Kernel functions and the kernel trick</h3>
<p>The basic idea to deal with linearly inseparable data is to project it onto a higher dimensional space where it becomes linearly separable. Let us call this nonlinear mapping function <script type="math/tex">\phi</script> so that the mapping of a sample <script type="math/tex">\mathbf{x}</script> can be written as <script type="math/tex">\mathbf{x} \rightarrow \phi (\mathbf{x})</script>, which is called "kernel function."</p>
<p>Now, the term "kernel" describes a function that calculates the dot product of the images of the samples <script type="math/tex">\mathbf{x}</script> under <script type="math/tex">\phi</script>.</p>
<p>
<script type="math/tex; mode=display">\kappa(\mathbf{x_i, x_j}) =  \phi (\mathbf{x_i}) \phi (\mathbf{x_j})^T</script>
</p>
<p>More details about the derivation of this equation are provided in this excellent review article by Quan Wang: <a href="https://arxiv.org/abs/1207.3538">Kernel Principal Component Analysis and its Applications in Face Recognition and Active Shape Models</a>.[<a href="#References">1</a>]</p>
<p>In other words, the function <script type="math/tex">\phi</script> maps the original d-dimensional features into a larger, k-dimensional feature space by creating nononlinear combinations of the original features. For example, if <script type="math/tex">\mathbf{x}</script> consists of 2 features:</p>
<p>
<script type="math/tex; mode=display">
\mathbf{x} = \big[x_1 \quad x_2\big]^T \quad \quad \mathbf{x} \in I\!R^d
</script>
</p>
<p>
<script type="math/tex; mode=display">
\Downarrow \phi
</script>
</p>
<p>
<script type="math/tex; mode=display">
\mathbf{x}' = \big[x_1 \quad x_2 \quad x_1 x_2 \quad x_{1}^2 \quad x_1 x_{2}^3 \quad \dots \big]^T \quad \quad \mathbf{x} \in I\!R^k (k >> d)
</script>
</p>
<p>Often, the mathematical definition of the RBF kernel is written and implemented as</p>
<p>
<script type="math/tex; mode=display">
\kappa(\mathbf{x_i, x_j}) = exp\bigg(- \gamma \; \lVert\mathbf{x_i - x_j }\rVert^{2}_{2} \bigg)
</script>
</p>
<p>where <script type="math/tex">\textstyle\gamma = \tfrac{1}{2\sigma^2}</script> is a free parameter that is to be optimized.</p>
<h3 id="gaussian-radial-basis-function-rbf-kernel-pca">Gaussian radial basis function (RBF) Kernel PCA</h3>
<p>In the linear PCA approach, we are interested in the principal components that maximize the variance in the dataset. This is done by extracting the eigenvectors (principle components) that correspond to the largest eigenvalues based on the covariance matrix:</p>
<p>
<script type="math/tex; mode=display">\text{Cov} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{x_i} \mathbf{x_i}^T</script>
</p>
<p>Bernhard Scholkopf (<a href="https://dl.acm.org/citation.cfm?id=299113">Kernel Principal Component Analysis</a> [<a href="#References">2</a>]) generalized this approach for data that was mapped onto the higher dimensional space via a kernel function:</p>
<p>
<script type="math/tex; mode=display">\text{Cov} = \frac{1}{N} \sum_{i=1}^{N} \phi(\mathbf{x_i}) \phi(\mathbf{x_i})^T</script>
</p>
<p>However, in practice the the covariance matrix in the higher dimensional space is not calculated explicitly (kernel trick). Therefore, the implementation of RBF kernel PCA does not yield the principal component axes (in contrast to the standard PCA), but the obtained eigenvectors can be understood as projections of the data onto the principal components.</p>
<h3 id="rbf-kernel-pca-step-by-step">RBF kernel PCA step-by-step</h3>
<h4 id="1-computation-of-the-kernel-similarity-matrix">1. Computation of the kernel (similarity) matrix.</h4>
<p>In this first step, we need to calculate</p>
<p>
<script type="math/tex; mode=display">\kappa(\mathbf{x_i, x_j}) = exp\bigg(- \gamma \; \lVert\mathbf{x_i - x_j }\rVert^{2}_{2} \bigg)</script>
</p>
<p>for every pair of points. E.g., if we have a dataset of 100 samples, this step would result in a symmetric 100x100 kernel matrix.</p>
<h4 id="2-eigendecomposition-of-the-kernel-matrix">2. Eigendecomposition of the kernel matrix.</h4>
<p>Since it is not guaranteed that the kernel matrix is centered, we can apply the following equation to do so:</p>
<p>
<script type="math/tex; mode=display">K' = K - \mathbf{1_N} K - K \mathbf{1_N} + \mathbf{1_N} K \mathbf{1_N}</script>
</p>
<p>where <script type="math/tex">\mathbf{1_N}</script> is (like the kernel matrix) a <script type="math/tex">N\times N</script> matrix with all values equal to <script type="math/tex">\frac{1}{N}</script>. [<a href="#References">3</a>]</p>
<p>Now, we have to obtain the eigenvectors of the centered kernel matrix that correspond to the largest eigenvalues. Those eigenvectors are the data points already projected onto the respective principal components.</p>
<h3 id="projecting-new-data">Projecting new data</h3>
<p>So far, so good, in the sections above, we have been projecting an dataset onto a new feature subspace. However, in a real application, we are usually interested in mapping new data points onto the same new feature subspace (e.g., if are working with a training and a test dataset in pattern classification tasks).</p>
<p>Remember, when we computed the eigenvectors <script type="math/tex">\mathbf{\alpha}</script> of the centered kernel matrix, those values were actually already the projected datapoints onto the principal component axis <script type="math/tex">\mathbf{g}</script>.</p>
<p>If we want to project a new data point <script type="math/tex">\mathbf{x}</script> onto this principal component axis, we'd need to compute <script type="math/tex">\phi(\mathbf{x})^T  \mathbf{g}</script>.</p>
<p>Fortunately, also here, we don't have to compute <script type="math/tex">\phi(\mathbf{x})^T  \mathbf{g}</script> explicitely but use the kernel trick to calculate the RBF kernel between the new data point and every data point <script type="math/tex">j</script> in the training dataset:</p>
<p>
<script type="math/tex; mode=display">\phi(\mathbf{x})^T  \mathbf{g}  = \sum_j \alpha_{i} \; \phi(\mathbf{x}) \; \phi(\mathbf{x_j})^T</script>
</p>
<p>
<script type="math/tex; mode=display">=  \sum_j \alpha_{i} \; \kappa(\mathbf{x}, \mathbf{x_j})</script>
</p>
<p>and the eigenvectors <script type="math/tex">\alpha</script> and eigenvalues <script type="math/tex">\lambda</script> of the Kernel matrix <script type="math/tex">\mathbf{K}</script> satisfy the equation
<script type="math/tex">\mathbf{K} \alpha = \lambda \alpha</script>, we just need to normalize the eigenvector by the corresponding eigenvalue.</p>
<h3 id="references">References</h3>
<p>[1] Q. Wang. <a href="https://arxiv.org/abs/1207.3538">Kernel principal component analysis and its applications in face recognition and active shape models</a>. CoRR, abs/1207.3538, 2012.</p>
<p>[2] B. Scholkopf, A. Smola, and K.-R. Muller. <a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.7613">Kernel principal component analysis</a>. pages 583–588, 1997.</p>
<p>[3] B. Scholkopf, A. Smola, and K.-R. Muller. <a href="https://www.mitpressjournals.org/doi/abs/10.1162/089976698300017467#.VBh9QkuCFHg">Nonlinear component analysis as a kernel eigenvalue problem</a>. Neural computation, 10(5):1299–1319, 1998.</p>
<h2 id="example-1-half-moon-shapes">Example 1 - Half-moon shapes</h2>
<p>We will start with a simple example of 2 half-moon shapes generated by the <code>make_moons</code> function from scikit-learn.</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from sklearn.datasets import make_moons

X, y = make_moons(n_samples=50, random_state=1)

plt.scatter(X[y==0, 0], X[y==0, 1], 
            color='red', marker='o', alpha=0.5)
plt.scatter(X[y==1, 0], X[y==1, 1], 
            color='blue', marker='^', alpha=0.5)
plt.ylabel('y coordinate')
plt.xlabel('x coordinate')

plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_15_0.png" /></p>
<p>Since the two half-moon shapes are linearly inseparable, we expect that the “classic” PCA will fail to give us a “good” representation of the data in 1D space. Let us use <code>PCA</code> class to perform the dimensionality reduction.</p>
<pre><code class="language-python">from mlxtend.feature_extraction import PrincipalComponentAnalysis as PCA

pca = PCA(n_components=2)
X_pca = pca.fit(X).transform(X)

plt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], 
            color='red', marker='o', alpha=0.5)
plt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], 
            color='blue', marker='^', alpha=0.5)

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_17_0.png" /></p>
<p>As we can see, the resulting principal components do not yield a subspace where the data is linearly separated well. Note that PCA is a unsupervised method and does not “consider” class labels in order to maximize the variance in contrast to Linear Discriminant Analysis. Here, the colors blue and red are just added for visualization purposes to indicate the degree of separation.</p>
<p>Next, we will perform dimensionality reduction via RBF kernel PCA on our half-moon data. The choice of <script type="math/tex">\gamma</script>
depends on the dataset and can be obtained via hyperparameter tuning techniques like Grid Search. Hyperparameter tuning is a broad topic itself, and here I will just use a <script type="math/tex">\gamma</script>-value that I found to produce “good” results.</p>
<pre><code class="language-python">from mlxtend.data import iris_data
from mlxtend.preprocessing import standardize
from mlxtend.feature_extraction import RBFKernelPCA as KPCA

kpca = KPCA(gamma=15.0, n_components=2)
kpca.fit(X)
X_kpca = kpca.X_projected_
</code></pre>
<p>Please note that the components of kernel methods such as RBF kernel PCA already represent the projected data points (in contrast to PCA, where the component axis are the "top k" eigenvectors thar are used to contruct a projection matrix, which is then used to transform the training samples). Thus, the projected training set is available after fitting via the <code>.X_projected_</code> attribute.</p>
<pre><code class="language-python">plt.scatter(X_kpca[y==0, 0], X_kpca[y==0, 1], 
            color='red', marker='o', alpha=0.5)
plt.scatter(X_kpca[y==1, 0], X_kpca[y==1, 1], 
            color='blue', marker='^', alpha=0.5)

plt.title('First 2 principal components after RBF Kernel PCA')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_22_0.png" /></p>
<p>The new feature space is linearly separable now. Since we are often interested in dimensionality reduction, let's have a look at the first component only.</p>
<pre><code class="language-python">import numpy as np

plt.scatter(X_kpca[y==0, 0], np.zeros((25, 1)), 
            color='red', marker='o', alpha=0.5)
plt.scatter(X_kpca[y==1, 0], np.zeros((25, 1)), 
            color='blue', marker='^', alpha=0.5)

plt.title('First principal component after RBF Kernel PCA')
plt.xlabel('PC1')
plt.yticks([])
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_24_0.png" /></p>
<p>We can clearly see that the projection via RBF kernel PCA yielded a subspace where the classes are separated well. Such a subspace can then be used as input for generalized linear classification models, e.g.,  logistic regression.</p>
<h4 id="projecting-new-data_1">Projecting new data</h4>
<p>Finally, via the transform method, we can project new data onto the new component axes.</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from sklearn.datasets import make_moons

X2, y2 = make_moons(n_samples=200, random_state=5)
X2_kpca = kpca.transform(X2)

plt.scatter(X_kpca[y==0, 0], X_kpca[y==0, 1], 
            color='red', marker='o', alpha=0.5, label='fit data')
plt.scatter(X_kpca[y==1, 0], X_kpca[y==1, 1], 
            color='blue', marker='^', alpha=0.5, label='fit data')

plt.scatter(X2_kpca[y2==0, 0], X2_kpca[y2==0, 1], 
            color='orange', marker='v', 
            alpha=0.2, label='new data')
plt.scatter(X2_kpca[y2==1, 0], X2_kpca[y2==1, 1], 
            color='cyan', marker='s', 
            alpha=0.2, label='new data')

plt.legend()
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_28_0.png" /></p>
<h2 id="example-2-concentric-circles">Example 2 - Concentric circles</h2>
<p>Following the concepts explained in example 1, let's have a look at another classic case: 2 concentric circles with random noise produced by scikit-learn’s <code>make_circles</code>.</p>
<pre><code class="language-python">from sklearn.datasets import make_circles

X, y = make_circles(n_samples=1000, random_state=123, 
                    noise=0.1, factor=0.2)

plt.figure(figsize=(8,6))

plt.scatter(X[y==0, 0], X[y==0, 1], color='red', alpha=0.5)
plt.scatter(X[y==1, 0], X[y==1, 1], color='blue', alpha=0.5)
plt.title('Concentric circles')
plt.ylabel('y coordinate')
plt.xlabel('x coordinate')
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_31_0.png" /></p>
<pre><code class="language-python">from mlxtend.data import iris_data
from mlxtend.preprocessing import standardize
from mlxtend.feature_extraction import RBFKernelPCA as KPCA

kpca = KPCA(gamma=15.0, n_components=2)
kpca.fit(X)
X_kpca = kpca.X_projected_
</code></pre>
<pre><code class="language-python">plt.scatter(X_kpca[y==0, 0], X_kpca[y==0, 1], 
            color='red', marker='o', alpha=0.5)
plt.scatter(X_kpca[y==1, 0], X_kpca[y==1, 1], 
            color='blue', marker='^', alpha=0.5)

plt.title('First 2 principal components after RBF Kernel PCA')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_33_0.png" /></p>
<pre><code class="language-python">plt.scatter(X_kpca[y==0, 0], np.zeros((500, 1)), 
            color='red', marker='o', alpha=0.5)
plt.scatter(X_kpca[y==1, 0], np.zeros((500, 1)), 
            color='blue', marker='^', alpha=0.5)

plt.title('First principal component after RBF Kernel PCA')
plt.xlabel('PC1')
plt.yticks([])
plt.show()
</code></pre>
<p><img alt="png" src="../RBFKernelPCA_files/RBFKernelPCA_34_0.png" /></p>
<h2 id="api">API</h2>
<p><em>RBFKernelPCA(gamma=15.0, n_components=None, copy_X=True)</em></p>
<p>RBF Kernel Principal Component Analysis for dimensionality reduction.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>gamma</code> : float (default: 15.0)</p>
<p>Free parameter (coefficient) of the RBF kernel.</p>
</li>
<li>
<p><code>n_components</code> : int (default: None)</p>
<p>The number of principal components for transformation.
Keeps the original dimensions of the dataset if <code>None</code>.</p>
</li>
<li>
<p><code>copy_X</code> : bool (default: True)</p>
<p>Copies training data, which is required to compute the projection
of new data via the transform method. Uses a reference to X if False.</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>e_vals_</code> : array-like, shape=[n_features]</p>
<p>Eigenvalues in sorted order.</p>
</li>
<li>
<p><code>e_vecs_</code> : array-like, shape=[n_features]</p>
<p>Eigenvectors in sorted order.</p>
</li>
<li>
<p><code>X_projected_</code> : array-like, shape=[n_samples, n_components]</p>
<p>Training samples projected along the component axes.</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="https://rasbt.github.io/mlxtend/user_guide/feature_extraction/RBFKernelPCA/">https://rasbt.github.io/mlxtend/user_guide/feature_extraction/RBFKernelPCA/</a></p>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X)</em></p>
<p>Learn model from training data.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>transform(X)</em></p>
<p>Apply the non-linear transformation on X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_projected</code> : np.ndarray, shape = [n_samples, n_components]</p>
<p>Projected training vectors.</p>
</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2014-2023 <a href="https://sebastianraschka.com">Sebastian Raschka</a></p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../js/jquery-3.6.0.min.js"></script>
        <script src="../../../js/bootstrap.min.js"></script>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js"></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
        <script src="../../../mathjaxhelper.js"></script>
        <script src="../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
