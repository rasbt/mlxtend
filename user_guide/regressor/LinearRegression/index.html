<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A library consisting of useful tools and extensions for the day-to-day data science tasks."> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression/">
    <link rel="shortcut icon" href="../../../img/favicon.ico">

    <title>LinearRegression: An implementation of ordinary least-squares linear regression - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../cinder/css/base.css" rel="stylesheet">


    <link href="../../../cinder/css/bootstrap-custom.css" rel="stylesheet">


    <link href="../../../cinder/css/bootstrap-custom.min.css" rel="stylesheet">


    <link href="../../../cinder/css/cinder.css" rel="stylesheet">


    <link href="../../../cinder/css/font-awesome-4.0.3.css" rel="stylesheet">


    <link href="../../../cinder/css/highlight.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../USER_GUIDE_INDEX/">User Guide Index</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../classifier/Adaline/">Adaline: Adaptive Linear Neuron Classifier</a>
</li>

        
            
<li >
    <a href="../../classifier/EnsembleVoteClassifier/">EnsembleVoteClassifier: A majority voting classifier</a>
</li>

        
            
<li >
    <a href="../../classifier/LogisticRegression/">LogisticRegression: A binary classifier</a>
</li>

        
            
<li >
    <a href="../../classifier/MultiLayerPerceptron/">MultilayerPerceptron: A simple multilayer neural network</a>
</li>

        
            
<li >
    <a href="../../classifier/OneRClassifier/">OneRClassifier: One Rule (OneR) method for classfication</a>
</li>

        
            
<li >
    <a href="../../classifier/Perceptron/">Perceptron: A simple binary classifier</a>
</li>

        
            
<li >
    <a href="../../classifier/SoftmaxRegression/">SoftmaxRegression: Multiclass version of logistic regression</a>
</li>

        
            
<li >
    <a href="../../classifier/StackingClassifier/">StackingClassifier: Simple stacking</a>
</li>

        
            
<li >
    <a href="../../classifier/StackingCVClassifier/">StackingCVClassifier: Stacking with cross-validation</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">cluster</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../cluster/Kmeans/">Kmeans: k-means clustering</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">autompg_data: The Auto-MPG dataset for regression</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">boston_housing_data: The Boston housing dataset for regression</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">iris_data: The 3-class iris dataset for classification</a>
</li>

        
            
<li >
    <a href="../../data/loadlocal_mnist/">loadlocal_mnist: A function for loading MNIST from the original ubyte files</a>
</li>

        
            
<li >
    <a href="../../data/make_multiplexer_dataset/">make_multiplexer_dataset: A function for creating multiplexer data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">mnist_data: A subset of the MNIST dataset for classification</a>
</li>

        
            
<li >
    <a href="../../data/three_blobs_data/">three_blobs_data: The synthetic blobs for classification</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">wine_data: A 3-class wine dataset for classification</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/accuracy_score/">accuracy_score: Computing standard, balanced, and per-class accuracy</a>
</li>

        
            
<li >
    <a href="../../evaluate/bias_variance_decomp/">bias_variance_decomp: Bias-variance decomposition for classification and regression losses</a>
</li>

        
            
<li >
    <a href="../../evaluate/bootstrap/">bootstrap: The ordinary nonparametric boostrap for arbitrary parameters</a>
</li>

        
            
<li >
    <a href="../../evaluate/bootstrap_point632_score/">bootstrap_point632_score: The .632 and .632+ boostrap for classifier evaluation</a>
</li>

        
            
<li >
    <a href="../../evaluate/BootstrapOutOfBag/">BootstrapOutOfBag: A scikit-learn compatible version of the out-of-bag bootstrap</a>
</li>

        
            
<li >
    <a href="../../evaluate/cochrans_q/">cochrans_q: Cochran's Q test for comparing multiple classifiers</a>
</li>

        
            
<li >
    <a href="../../evaluate/combined_ftest_5x2cv/">combined_ftest_5x2cv: 5x2cv combined *F* test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/confusion_matrix/">confusion_matrix: creating a confusion matrix for model evaluation</a>
</li>

        
            
<li >
    <a href="../../evaluate/create_counterfactual/">create_counterfactual: Interpreting models via counterfactuals</a>
</li>

        
            
<li >
    <a href="../../evaluate/feature_importance_permutation/">feature_importance_permutation: Estimate feature importance via feature permutation.</a>
</li>

        
            
<li >
    <a href="../../evaluate/ftest/">ftest: F-test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/GroupTimeSeriesSplit/">GroupTimeSeriesSplit: A scikit-learn compatible version of the time series validation with groups</a>
</li>

        
            
<li >
    <a href="../../evaluate/lift_score/">lift_score: Lift score for classification and association rule mining</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar_table/">mcnemar_table: Ccontingency table for McNemar's test</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar_tables/">mcnemar_tables: contingency tables for McNemar's test and Cochran's Q test</a>
</li>

        
            
<li >
    <a href="../../evaluate/mcnemar/">mcnemar: McNemar's test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_5x2cv/">paired_ttest_5x2cv: 5x2cv paired *t* test for classifier comparisons</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_kfold_cv/">paired_ttest_kfold_cv: K-fold cross-validated paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/paired_ttest_resampled/">paired_ttest_resample: Resampled paired *t* test</a>
</li>

        
            
<li >
    <a href="../../evaluate/permutation_test/">permutation_test: Permutation test for hypothesis testing</a>
</li>

        
            
<li >
    <a href="../../evaluate/PredefinedHoldoutSplit/">PredefinedHoldoutSplit: Utility for the holdout method compatible with scikit-learn</a>
</li>

        
            
<li >
    <a href="../../evaluate/RandomHoldoutSplit/">RandomHoldoutSplit: split a dataset into a train and validation subset for validation</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">scoring: computing various performance metrics</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_extraction</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_extraction/LinearDiscriminantAnalysis/">LinearDiscriminantAnalysis: Linear discriminant analysis for dimensionality reduction</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/PrincipalComponentAnalysis/">PrincipalComponentAnalysis: Principal component analysis (PCA) for dimensionality reduction</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/RBFKernelPCA/">RBFKernelPCA</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/ColumnSelector/">ColumnSelector: Scikit-learn utility function to select specific columns in a pipeline</a>
</li>

        
            
<li >
    <a href="../../feature_selection/ExhaustiveFeatureSelector/">ExhaustiveFeatureSelector: Optimal feature sets by considering all possible feature combinations</a>
</li>

        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector: The popular forward and backward feature selection approaches incl. floating variants</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">find_filegroups: Find files that only differ via their file extensions</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">find_files: Find files based on substring matches</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">frequent_patterns</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../frequent_patterns/apriori/">Apriori</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/association_rules/">Association rules</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/fpgrowth/">Fpgrowth</a>
</li>

        
            
<li >
    <a href="../../frequent_patterns/fpmax/">Fpmax</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">image</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../image/extract_face_landmarks/">extract_face_landmarks: extract 68 landmark features from face images</a>
</li>

        
            
<li >
    <a href="../../image/eyepad_align/">EyepadAlign:  align face images based on eye location</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">num_combinations: combinations for creating subsequences of *k* elements</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">num_permutations: number of permutations for creating subsequences of *k* elements</a>
</li>

        
            
<li >
    <a href="../../math/vectorspace_dimensionality/">vectorspace_dimensionality: compute the number of dimensions that a set of vectors spans</a>
</li>

        
            
<li >
    <a href="../../math/vectorspace_orthonormalization/">vectorspace_orthonormalization: Converts a set of linearly independent vectors to a set of orthonormal basis vectors</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../plotting/category_scatter/">Scategory_scatter: Create a scatterplot with categories in different colors</a>
</li>

        
            
<li >
    <a href="../../plotting/checkerboard_plot/">checkerboard_plot: Create a checkerboard plot in matplotlib</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_pca_correlation_graph/">plot_pca_correlation_graph: plot correlations between original features and principal components</a>
</li>

        
            
<li >
    <a href="../../plotting/ecdf/">ecdf: Create an empirical cumulative distribution function plot</a>
</li>

        
            
<li >
    <a href="../../plotting/enrichment_plot/">enrichment_plot: create an enrichment plot for cumulative counts</a>
</li>

        
            
<li >
    <a href="../../plotting/heatmap/">heatmap: Create a heatmap in matplotlib</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_confusion_matrix/">plot_confusion_matrix: Visualize confusion matrices</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_decision_regions/">plot_decision_regions: Visualize the decision regions of a classifier</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_learning_curves/">plot_learning_curves: Plot learning curves from training and test sets</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_linear_regression/">plot_linear_regression: A quick way for plotting linear regression fits</a>
</li>

        
            
<li >
    <a href="../../plotting/plot_sequential_feature_selection/">plot_sequential_feature_selection: Visualize selected feature subset performances from the SequentialFeatureSelector</a>
</li>

        
            
<li >
    <a href="../../plotting/scatterplotmatrix/">scatterplotmatrix: visualize datasets via a scatter plot matrix</a>
</li>

        
            
<li >
    <a href="../../plotting/scatter_hist/">scatter_hist: create a scatter histogram plot</a>
</li>

        
            
<li >
    <a href="../../plotting/stacked_barplot/">stacked_barplot: Plot stacked bar plots in matplotlib</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/CopyTransformer/">CopyTransformer: A function that creates a copy of the input array in a scikit-learn pipeline</a>
</li>

        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer: Transforms a sparse into a dense NumPy array, e.g., in a scikit-learn pipeline</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer: column-based mean centering on a NumPy array</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">MinMaxScaling: Min-max scaling fpr pandas DataFrames and NumPy arrays</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">shuffle_arrays_unison: shuffle arrays in a consistent fashion</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">standardize: A function to standardize columns in a 2D NumPy array</a>
</li>

        
            
<li >
    <a href="../../preprocessing/TransactionEncoder/">TransactionEncoder</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li class="active">
    <a href="./">LinearRegression: An implementation of ordinary least-squares linear regression</a>
</li>

        
            
<li >
    <a href="../StackingCVRegressor/">StackingCVRegressor: stacking with cross-validation for regression</a>
</li>

        
            
<li >
    <a href="../StackingRegressor/">StackingRegressor: a simple stacking implementation for regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">generalize_names: convert names into a generalized format</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">generalize_names_duplcheck: Generalize names while preventing duplicates among different names</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">tokenizer_emoticons: tokenizers for emoticons</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter: A simple progress counter</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.cluster/">Mlxtend.cluster</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_extraction/">Mlxtend.feature extraction</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.frequent_patterns/">Mlxtend.frequent patterns</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.image/">Mlxtend.image</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.plotting/">Mlxtend.plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../CHANGELOG/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../Code-of-Conduct/">Code of Conduct</a>
</li>

                        
                            
<li >
    <a href="../../../CONTRIBUTING/">How To Contribute</a>
</li>

                        
                            
<li >
    <a href="../../../contributors/">Contributors</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                            
<li >
    <a href="../../../cite/">Citing Mlxtend</a>
</li>

                        
                            
<li >
    <a href="../../../discuss/">Discuss</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fa fa-search"></i> Search
                        </a>
                    </li>

                <!--
                    <li >
                        <a rel="next" href="../../preprocessing/TransactionEncoder/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../StackingCVRegressor/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>-->
                    <li>
                        <a href="https://github.com/rasbt/mlxtend"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#linearregression-an-implementation-of-ordinary-least-squares-linear-regression">LinearRegression: An implementation of ordinary least-squares linear regression</a></li>
            <li class="second-level"><a href="#overview">Overview</a></li>
                 <!-- 
                <li class="third-level"><a href="#normal-equations-closed-form-solution">Normal Equations (closed-form solution)</a></li>
                <li class="third-level"><a href="#stable-ols-via-qr-factorization">Stable OLS via QR Factorization</a></li>
                <li class="third-level"><a href="#stable-ols-via-singular-value-decomposition">Stable OLS via Singular Value Decomposition</a></li>
                <li class="third-level"><a href="#gradient-descent-gd-and-stochastic-gradient-descent-sgd">Gradient Descent (GD)  and Stochastic Gradient Descent (SGD)</a></li>
                <li class="third-level"><a href="#references">References</a></li>  -->
            <li class="second-level"><a href="#example-1-closed-form-solution">Example 1 - Closed Form Solution</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-2-qr-decomposition-method">Example 2 - QR decomposition method</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-3-svd-method">Example 3 - SVD method</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-4-gradient-descent">Example 4 - Gradient Descent</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-5-stochastic-gradient-descent">Example 5 - Stochastic Gradient Descent</a></li>
                 <!--   -->
            <li class="second-level"><a href="#example-6-stochastic-gradient-descent-with-minibatches">Example 6 - Stochastic Gradient Descent with Minibatches</a></li>
                 <!--   -->
            <li class="second-level"><a href="#api">API</a></li>
                 <!-- 
                <li class="third-level"><a href="#methods">Methods</a></li>  -->
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="linearregression-an-implementation-of-ordinary-least-squares-linear-regression">LinearRegression: An implementation of ordinary least-squares linear regression</h1>
<p>A implementation of Ordinary Least Squares simple and multiple linear regression.</p>
<blockquote>
<p>from mlxtend.regressor import LinearRegression</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p>Illustration of a simple linear regression model:</p>
<p><img alt="" src="../LinearRegression_files/simple_regression.png" /></p>
<p>In Ordinary Least Squares (OLS) Linear Regression, our goal is to find the line (or hyperplane) that minimizes the vertical offsets. Or in other words, we define the best-fitting line as the line that minimizes the sum of squared errors (SSE) or mean squared error (MSE) between our target variable (y) and our predicted output over all samples <script type="math/tex">i</script> in our dataset of size <script type="math/tex">n</script>.</p>
<p>
<script type="math/tex; mode=display">SSE =  \sum_i \big(\text{target}^{(i)} - \text{output}^{(i)}\big)^2</script>
</p>
<p>
<script type="math/tex; mode=display">MSE = \frac{1}{n} \times SSE</script>
</p>
<p>Now, <code>LinearRegression</code> implements a linear regression model for performing ordinary least squares regression using one of the following five approaches:</p>
<ul>
<li>Normal Equations</li>
<li>QR Decomposition Method</li>
<li>SVD (Singular Value Decomposition) method</li>
<li>Gradient Descent</li>
<li>Stochastic Gradient Descent</li>
</ul>
<h3 id="normal-equations-closed-form-solution">Normal Equations (closed-form solution)</h3>
<p>The closed-form solution should be preferred for "smaller" datasets where calculating (a "costly") matrix inverse is not a concern. For very large datasets, or datasets where the inverse of <script type="math/tex">[X^T X]</script> may not exist (the matrix is non-invertible or singular, e.g., in case of perfect multicollinearity), the QR, SVD or gradient descent approaches are to be preferred.</p>
<p>The linear function (linear regression model) is defined as:</p>
<p>
<script type="math/tex; mode=display">y = w_0x_0 + w_1x_1 + ... + w_mx_m = \sum_{i=0}^{m} = \mathbf{w}^T\mathbf{x}</script>
</p>
<p>where <script type="math/tex">y</script> is the response variable, <script type="math/tex">\mathbf{x}</script> is an <script type="math/tex">m</script>-dimensional sample vector, and <script type="math/tex">\mathbf{w}</script> is the weight vector (vector of coefficients). Note that <script type="math/tex">w_0</script> represents the y-axis intercept of the model and therefore <script type="math/tex">x_0=1</script>.  </p>
<p>Using the closed-form solution (normal equation), we compute the weights of the model as follows:</p>
<p>
<script type="math/tex; mode=display"> \mathbf{w} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^Ty</script>
</p>
<h3 id="stable-ols-via-qr-factorization">Stable OLS via QR Factorization</h3>
<p>The QR decomposition method offers a more numerically stable alternative to the closed-form, analytical solution based on the "normal equations," and it can be used to compute the inverse of large matrices more efficiently.</p>
<p>QR decomposition method decomposes given matrix into two matrices for which an inverse can be easily obtained. For instance, a given matrix <script type="math/tex">X \in \mathbb{R}^{n \times m}</script>, the QR decomposition into two matrices is:</p>
<p>
<script type="math/tex; mode=display">\mathbf{X = QR},</script>
</p>
<p>where</p>
<p>
<script type="math/tex">Q \in \mathbb{R}^{n \times m}</script> is an orthonormal matrix, such that <script type="math/tex">Q^\top Q = QQ^\top = I</script>. 
The second matrix <script type="math/tex">R \in \mathbf{R}^{m \times m}</script> is an upper triangular matrix.</p>
<p>The weight parameters of the ordinary least squares regression model can then be computed as follows [1]:</p>
<p>
<script type="math/tex; mode=display">\mathbf{w} = \mathbf{R}^{-1}\mathbf{Q}^\top y.</script>
</p>
<h3 id="stable-ols-via-singular-value-decomposition">Stable OLS via Singular Value Decomposition</h3>
<p>Another alternative way for obtaining the OLS model weights in a numerically stable fashion is by Singular Value Decomposition (SVD), which is defined as:</p>
<p>
<script type="math/tex; mode=display">\mathbf{X}=\mathbf{U}\Sigma \mathbf{V}^\top,</script>
</p>
<p>for a given matrix <script type="math/tex">\mathbf{X}</script>.</p>
<p>Then, it can be shown that the pseudo-inverse of <script type="math/tex">X</script>, <script type="math/tex">X^+</script>, can be obtained as follows [1]:</p>
<p>
<script type="math/tex; mode=display"> X^+ = \mathbf{U} \mathbf{\Sigma}^+  V^{\top}.</script>
</p>
<p>Note that while <script type="math/tex">\Sigma</script> is the diagonal matrix consisting of singular values of <script type="math/tex">\mathbf{X}</script>, <script type="math/tex">\Sigma^{+}</script> is the diagonal matrix consisting of the reciprocals of the singular values.</p>
<p>The model weights can then be computed as follows:</p>
<p>
<script type="math/tex; mode=display">\mathbf{w} = \mathbf{X}^+  \mathbf{y}.</script>
</p>
<p>Please note that this OLS method is computationally most inefficient. However, it is a useful approach when the direct method (normal equations) or QR factorization cannot be applied or the normal equations (via <script type="math/tex">\mathbf{X}^T \mathbf{X}</script>) are ill-conditioned [3].</p>
<h3 id="gradient-descent-gd-and-stochastic-gradient-descent-sgd">Gradient Descent (GD)  and Stochastic Gradient Descent (SGD)</h3>
<p>See <a href="https://sebastianraschka.com/faq/docs/gradient-optimization.html">Gradient Descent and Stochastic Gradient Descent</a> and <a href="https://sebastianraschka.com/faq/docs/linear-gradient-derivative.html">Deriving the Gradient Descent Rule for Linear Regression and Adaline</a> for details.</p>
<p>Random shuffling is implemented as:</p>
<ul>
<li>for one or more epochs<ul>
<li>randomly shuffle samples in the training set<ul>
<li>for training sample <em>i</em><ul>
<li>compute gradients and perform weight updates</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li>[1] Chapter 3, page 55, Linear Methods for Regression. Trevor Hastie; Robert Tibshirani; Jerome Friedman (2009). <a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/download.html">The Elements of Statistical Learning: Data Mining, Inference, and Prediction (2nd ed.)</a>. New York: Springer. (ISBN 978–0–387–84858–7)</li>
<li>[2] G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pp. 139-142.</li>
<li>[3] Douglas Wilhelm Harder. Numerical Analysis for Engineering. Section 4.8, <a href="https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/04LinearAlgebra/illconditioned/">ill-conditioned Matrices</a></li>
</ul>
<h2 id="example-1-closed-form-solution">Example 1 - Closed Form Solution</h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from mlxtend.regressor import LinearRegression

X = np.array([ 1.0, 2.1, 3.6, 4.2, 6])[:, np.newaxis]
y = np.array([ 1.0, 2.0, 3.0, 4.0, 5.0])

ne_lr = LinearRegression()
ne_lr.fit(X, y)

print('Intercept: %.2f' % ne_lr.b_)
print('Slope: %.2f' % ne_lr.w_[0])

def lin_regplot(X, y, model):
    plt.scatter(X, y, c='blue')
    plt.plot(X, model.predict(X), color='red')    
    return

lin_regplot(X, y, ne_lr)
plt.show()
</code></pre>
<pre><code>Intercept: 0.25
Slope: 0.81
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_16_1.png" /></p>
<h2 id="example-2-qr-decomposition-method">Example 2 - QR decomposition method</h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from mlxtend.regressor import LinearRegression

X = np.array([ 1.0, 2.1, 3.6, 4.2, 6])[:, np.newaxis]
y = np.array([ 1.0, 2.0, 3.0, 4.0, 5.0])

qr_lr = LinearRegression(method='qr')
qr_lr.fit(X, y)

print('Intercept: %.2f' % qr_lr.b_)
print('Slope: %.2f' % qr_lr.w_[0])

def lin_regplot(X, y, model):
    plt.scatter(X, y, c='blue')
    plt.plot(X, model.predict(X), color='red')    
    return

lin_regplot(X, y, qr_lr)
plt.show()
</code></pre>
<pre><code>Intercept: 0.25
Slope: 0.81
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_18_1.png" /></p>
<h2 id="example-3-svd-method">Example 3 - SVD method</h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from mlxtend.regressor import LinearRegression

X = np.array([ 1.0, 2.1, 3.6, 4.2, 6])[:, np.newaxis]
y = np.array([ 1.0, 2.0, 3.0, 4.0, 5.0])

svd_lr = LinearRegression(method='svd')
svd_lr.fit(X, y)

print('Intercept: %.2f' %svd_lr.b_)
print('Slope: %.2f' % svd_lr.w_[0])

def lin_regplot(X, y, model):
    plt.scatter(X, y, c='blue')
    plt.plot(X, model.predict(X), color='red')    
    return

lin_regplot(X, y, svd_lr)
plt.show()
</code></pre>
<pre><code>Intercept: 0.25
Slope: 0.81
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_20_1.png" /></p>
<h2 id="example-4-gradient-descent">Example 4 - Gradient Descent</h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from mlxtend.regressor import LinearRegression

X = np.array([ 1.0, 2.1, 3.6, 4.2, 6])[:, np.newaxis]
y = np.array([ 1.0, 2.0, 3.0, 4.0, 5.0])

gd_lr = LinearRegression(method='sgd',
                         eta=0.005, 
                         epochs=100,
                         minibatches=1,
                         random_seed=123,
                         print_progress=3)
gd_lr.fit(X, y)

print('Intercept: %.2f' % gd_lr.b_)
print('Slope: %.2f' % gd_lr.w_)

def lin_regplot(X, y, model):
    plt.scatter(X, y, c='blue')
    plt.plot(X, model.predict(X), color='red')    
    return

lin_regplot(X, y, gd_lr)
plt.show()
</code></pre>
<pre><code>Iteration: 100/100 | Cost 0.08 | Elapsed: 0:00:00 | ETA: 0:00:00

Intercept: 0.22
Slope: 0.82
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_22_2.png" /></p>
<pre><code class="language-python"># Visualizing the cost to check for convergence and plotting the linear model:

plt.plot(range(1, gd_lr.epochs+1), gd_lr.cost_)
plt.xlabel('Epochs')
plt.ylabel('Cost')
plt.ylim([0, 0.2])
plt.tight_layout()
plt.show()    
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_23_0.png" /></p>
<h2 id="example-5-stochastic-gradient-descent">Example 5 - Stochastic Gradient Descent</h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from mlxtend.regressor import LinearRegression

X = np.array([ 1.0, 2.1, 3.6, 4.2, 6])[:, np.newaxis]
y = np.array([ 1.0, 2.0, 3.0, 4.0, 5.0])

sgd_lr = LinearRegression(method='sgd',
                          eta=0.01, 
                          epochs=100, 
                          random_seed=0, 
                          minibatches=len(y))
sgd_lr.fit(X, y)

print('Intercept: %.2f' % sgd_lr.w_)
print('Slope: %.2f' % sgd_lr.b_)

def lin_regplot(X, y, model):
    plt.scatter(X, y, c='blue')
    plt.plot(X, model.predict(X), color='red')    
    return

lin_regplot(X, y, sgd_lr)
plt.show()
</code></pre>
<pre><code>Intercept: 0.82
Slope: 0.24
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_25_1.png" /></p>
<pre><code class="language-python">plt.plot(range(1, sgd_lr.epochs+1), sgd_lr.cost_)
plt.xlabel('Epochs')
plt.ylabel('Cost')
plt.ylim([0, 0.2])
plt.tight_layout()
plt.show()  
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_26_0.png" /></p>
<h2 id="example-6-stochastic-gradient-descent-with-minibatches">Example 6 - Stochastic Gradient Descent with Minibatches</h2>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from mlxtend.regressor import LinearRegression

X = np.array([ 1.0, 2.1, 3.6, 4.2, 6])[:, np.newaxis]
y = np.array([ 1.0, 2.0, 3.0, 4.0, 5.0])

sgd_lr = LinearRegression(method='sgd',
                          eta=0.01, 
                          epochs=100, 
                          random_seed=0, 
                          minibatches=3)
sgd_lr.fit(X, y)

print('Intercept: %.2f' % sgd_lr.b_)
print('Slope: %.2f' % sgd_lr.w_)

def lin_regplot(X, y, model):
    plt.scatter(X, y, c='blue')
    plt.plot(X, model.predict(X), color='red')    
    return

lin_regplot(X, y, sgd_lr)
plt.show()
</code></pre>
<pre><code>Intercept: 0.24
Slope: 0.82
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_28_1.png" /></p>
<pre><code class="language-python">plt.plot(range(1, sgd_lr.epochs+1), sgd_lr.cost_)
plt.xlabel('Epochs')
plt.ylabel('Cost')
plt.ylim([0, 0.2])
plt.tight_layout()
plt.show()  
</code></pre>
<p><img alt="png" src="../LinearRegression_files/LinearRegression_29_0.png" /></p>
<h2 id="api">API</h2>
<p><em>LinearRegression(method='direct', eta=0.01, epochs=50, minibatches=None, random_seed=None, print_progress=0)</em></p>
<p>Ordinary least squares linear regression.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>method</code> : string (default: 'direct')</p>
<p>For gradient descent-based optimization, use <code>sgd</code> (see <code>minibatch</code>
parameter for further options). Otherwise, if <code>direct</code> (default),
the analytical method is used. For alternative, numerically more
stable solutions, use either <code>qr</code> (QR decomopisition) or <code>svd</code>
(Singular Value Decomposition).</p>
</li>
<li>
<p><code>eta</code> : float (default: 0.01)</p>
<p>solver learning rate (between 0.0 and 1.0). Used with <code>method =</code>
<code>'sgd'</code>. (See <code>methods</code> parameter for details)</p>
</li>
<li>
<p><code>epochs</code> : int (default: 50)</p>
<p>Passes over the training dataset.
Prior to each epoch, the dataset is shuffled
if <code>minibatches &gt; 1</code> to prevent cycles in stochastic gradient descent.
Used with <code>method = 'sgd'</code>. (See <code>methods</code> parameter for details)</p>
</li>
<li>
<p><code>minibatches</code> : int (default: None)</p>
<p>The number of minibatches for gradient-based optimization.
If None: Direct method, QR, or SVD method (see <code>method</code> parameter
for details)
If 1: Gradient Descent learning
If len(y): Stochastic Gradient Descent learning
If 1 &lt; minibatches &lt; len(y): Minibatch learning</p>
</li>
<li>
<p><code>random_seed</code> : int (default: None)</p>
<p>Set random state for shuffling and initializing the weights. Used in
<code>method = 'sgd'</code>. (See <code>methods</code> parameter for details)</p>
</li>
<li>
<p><code>print_progress</code> : int (default: 0)</p>
<p>Prints progress in fitting to stderr if <code>method = 'sgd'</code>.
0: No output
1: Epochs elapsed and cost
2: 1 plus time elapsed
3: 2 plus estimated time until completion</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>w_</code> : 2d-array, shape={n_features, 1}</p>
<p>Model weights after fitting.</p>
</li>
<li>
<p><code>b_</code> : 1d-array, shape={1,}</p>
<p>Bias unit after fitting.</p>
</li>
<li>
<p><code>cost_</code> : list</p>
<p>Sum of squared errors after each epoch;
ignored if solver='normal equation'</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<p>For usage examples, please see
    <a href="http://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression/">http://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression/</a></p>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y, init_params=True)</em></p>
<p>Learn model from training data.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>init_params</code> : bool (default: True)</p>
<p>Re-initializes model parameters prior to fitting.
Set False to continue training with weights from
a previous model fitting.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Get parameters for this estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>deep</code> : boolean, optional</p>
<p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>params</code> : mapping of string to any</p>
<p>Parameter names mapped to their values.'</p>
<p>adapted from
https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py
Author: Gael Varoquaux <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#103;&#97;&#101;&#108;&#46;&#118;&#97;&#114;&#111;&#113;&#117;&#97;&#117;&#120;&#64;&#110;&#111;&#114;&#109;&#97;&#108;&#101;&#115;&#117;&#112;&#46;&#111;&#114;&#103;">&#103;&#97;&#101;&#108;&#46;&#118;&#97;&#114;&#111;&#113;&#117;&#97;&#117;&#120;&#64;&#110;&#111;&#114;&#109;&#97;&#108;&#101;&#115;&#117;&#112;&#46;&#111;&#114;&#103;</a>
License: BSD 3 clause</p>
</li>
</ul>
<hr>

<p><em>predict(X)</em></p>
<p>Predict targets from X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>target_values</code> : array-like, shape = [n_samples]</p>
<p>Predicted target values.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.
The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<p><strong>Returns</strong></p>
<p>self</p>
<p>adapted from
https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py
Author: Gael Varoquaux <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#103;&#97;&#101;&#108;&#46;&#118;&#97;&#114;&#111;&#113;&#117;&#97;&#117;&#120;&#64;&#110;&#111;&#114;&#109;&#97;&#108;&#101;&#115;&#117;&#112;&#46;&#111;&#114;&#103;">&#103;&#97;&#101;&#108;&#46;&#118;&#97;&#114;&#111;&#113;&#117;&#97;&#117;&#120;&#64;&#110;&#111;&#114;&#109;&#97;&#108;&#101;&#115;&#117;&#112;&#46;&#111;&#114;&#103;</a>
License: BSD 3 clause</p>
<p>ython</p></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2020 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>
    <script src="../../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
